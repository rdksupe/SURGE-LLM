{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jivnesh/anaconda3/envs/RishiSurge/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU count: 4\n",
      "GPU 0: NVIDIA TITAN RTX\n",
      "GPU 1: NVIDIA TITAN RTX\n",
      "GPU 2: NVIDIA TITAN RTX\n",
      "GPU 3: NVIDIA TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_sample_raid_data(target,samples_per_class=75000, seed=42):\n",
    "    \"\"\"Loads RAID from HF, creates a balanced sample of human and gpt-4 texts.\"\"\"\n",
    "    print(\"Loading 'liamdugan/raid' dataset from Hugging Face Hub...\")\n",
    "    dataset = load_dataset(\"liamdugan/raid\", split=\"train\") \n",
    "    \n",
    "    # Filter by model type\n",
    "    human_ds = dataset.filter(lambda x: x['model'] == 'human').shuffle(seed=seed)\n",
    "    gpt4_ds = dataset.filter(lambda x: x['model'] == target).shuffle(seed=seed)\n",
    "    \n",
    "    num_human = min(samples_per_class, len(human_ds))\n",
    "    num_gpt4 = min(samples_per_class, len(gpt4_ds))\n",
    "    \n",
    "    print(f\"Available samples - Human: {len(human_ds)}, GPT-4: {len(gpt4_ds)}\")\n",
    "    print(f\"Selecting {num_human} human samples and {num_gpt4} gpt-4 samples...\")\n",
    "    \n",
    "    human_samples = human_ds.select(range(num_human))\n",
    "    gpt4_samples = gpt4_ds.select(range(num_gpt4))\n",
    "\n",
    "    # Combine and shuffle\n",
    "    combined_ds = concatenate_datasets([human_samples, gpt4_samples])\n",
    "    return combined_ds.shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading RAID dataset...\")\n",
    "dataset = load_and_sample_raid_data(samples_per_class=20000)  # 150k total samples\n",
    "print(f\"Total samples loaded: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset structure:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDataset structure:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataset\u001b[49m.features)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSample columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset.column_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFirst example keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset[\u001b[32m0\u001b[39m].keys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset structure:\")\n",
    "print(dataset.features)\n",
    "print(f\"\\nSample columns: {dataset.column_names}\")\n",
    "print(f\"\\nFirst example keys: {dataset[0].keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, texts, labels, topics, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels  # 0 for human, 1 for gpt4\n",
    "        self.topics = topics\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Group by topic and label for efficient sampling\n",
    "        self.topic_groups = {}\n",
    "        for idx, (topic, label) in enumerate(zip(topics, labels)):\n",
    "            if topic not in self.topic_groups:\n",
    "                self.topic_groups[topic] = {'human': [], 'gpt4': []}\n",
    "            \n",
    "            label_name = 'human' if label == 0 else 'gpt4'\n",
    "            self.topic_groups[topic][label_name].append(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def create_contrastive_triplet(self, anchor_idx):\n",
    "        \"\"\"Create anchor, positive, negative triplet\"\"\"\n",
    "        anchor_topic = self.topics[anchor_idx]\n",
    "        anchor_label = self.labels[anchor_idx]\n",
    "        anchor_label_name = 'human' if anchor_label == 0 else 'gpt4'\n",
    "        opposite_label_name = 'gpt4' if anchor_label == 0 else 'human'\n",
    "        \n",
    "        # Strategy selection (as discussed earlier)\n",
    "        strategy = np.random.choice([\n",
    "            'content_matched',    # 40% - Same topic, different styles\n",
    "            'topic_matched',      # 30% - Same topic, same style\n",
    "            'cross_topic',        # 20% - Different topics, same style\n",
    "            'hard_negative'       # 10% - Different topics, different styles\n",
    "        ], p=[0.4, 0.3, 0.2, 0.1])\n",
    "        \n",
    "        if strategy == 'content_matched' and len(self.topic_groups[anchor_topic][opposite_label_name]) > 0:\n",
    "            # Same topic, different style (best for style learning)\n",
    "            positive_idx = np.random.choice(self.topic_groups[anchor_topic][anchor_label_name])\n",
    "            while positive_idx == anchor_idx:\n",
    "                positive_idx = np.random.choice(self.topic_groups[anchor_topic][anchor_label_name])\n",
    "            negative_idx = np.random.choice(self.topic_groups[anchor_topic][opposite_label_name])\n",
    "            \n",
    "        elif strategy == 'topic_matched':\n",
    "            # Same topic, random pairing\n",
    "            positive_idx = np.random.choice(self.topic_groups[anchor_topic][anchor_label_name])\n",
    "            while positive_idx == anchor_idx:\n",
    "                positive_idx = np.random.choice(self.topic_groups[anchor_topic][anchor_label_name])\n",
    "            negative_idx = np.random.choice(self.topic_groups[anchor_topic][opposite_label_name]) if len(self.topic_groups[anchor_topic][opposite_label_name]) > 0 else np.random.choice([i for i, l in enumerate(self.labels) if l != anchor_label])\n",
    "            \n",
    "        elif strategy == 'cross_topic':\n",
    "            # Different topics, same style\n",
    "            other_topics = [t for t in self.topic_groups.keys() if t != anchor_topic]\n",
    "            if other_topics:\n",
    "                pos_topic = np.random.choice(other_topics)\n",
    "                positive_idx = np.random.choice(self.topic_groups[pos_topic][anchor_label_name]) if len(self.topic_groups[pos_topic][anchor_label_name]) > 0 else np.random.choice([i for i, l in enumerate(self.labels) if l == anchor_label])\n",
    "            else:\n",
    "                positive_idx = np.random.choice([i for i, l in enumerate(self.labels) if l == anchor_label and i != anchor_idx])\n",
    "            negative_idx = np.random.choice([i for i, l in enumerate(self.labels) if l != anchor_label])\n",
    "            \n",
    "        else:  # hard_negative\n",
    "            # Random pairing\n",
    "            positive_idx = np.random.choice([i for i, l in enumerate(self.labels) if l == anchor_label and i != anchor_idx])\n",
    "            negative_idx = np.random.choice([i for i, l in enumerate(self.labels) if l != anchor_label])\n",
    "        \n",
    "        return {\n",
    "            'anchor': self.texts[anchor_idx],\n",
    "            'positive': self.texts[positive_idx],\n",
    "            'negative': self.texts[negative_idx],\n",
    "            'anchor_label': anchor_label\n",
    "        }\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        triplet = self.create_contrastive_triplet(idx)\n",
    "        \n",
    "        # Tokenize all three texts\n",
    "        anchor_tokens = self.tokenizer(\n",
    "            triplet['anchor'], \n",
    "            max_length=self.max_length, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        positive_tokens = self.tokenizer(\n",
    "            triplet['positive'], \n",
    "            max_length=self.max_length, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        negative_tokens = self.tokenizer(\n",
    "            triplet['negative'], \n",
    "            max_length=self.max_length, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'anchor_input_ids': anchor_tokens['input_ids'].squeeze(),\n",
    "            'anchor_attention_mask': anchor_tokens['attention_mask'].squeeze(),\n",
    "            'positive_input_ids': positive_tokens['input_ids'].squeeze(),\n",
    "            'positive_attention_mask': positive_tokens['attention_mask'].squeeze(),\n",
    "            'negative_input_ids': negative_tokens['input_ids'].squeeze(),\n",
    "            'negative_attention_mask': negative_tokens['attention_mask'].squeeze(),\n",
    "            'anchor_label': triplet['anchor_label']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_contrastive_data(dataset):\n",
    "    \"\"\"Convert RAID dataset to contrastive learning format\"\"\"\n",
    "    texts = []\n",
    "    labels = []\n",
    "    topics = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        texts.append(example['generation'])\n",
    "        labels.append(0 if example['model'] == 'human' else 1)\n",
    "        topics.append(example.get('domain', 'general'))  # Use domain as topic\n",
    "    \n",
    "    return texts, labels, topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Preparing contrastive learning data...\")\n",
    "texts, labels, topics = prepare_contrastive_data(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data summary:\")\n",
    "print(f\"Total texts: {len(texts)}\")\n",
    "print(f\"Human samples: {sum(1 for l in labels if l == 0)}\")\n",
    "print(f\"GPT-4 samples: {sum(1 for l in labels if l == 1)}\")\n",
    "print(f\"Unique topics: {len(set(topics))}\")\n",
    "print(f\"Topics: {set(topics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleContrastiveEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 base_model=\"microsoft/deberta-v3-base\",\n",
    "                 embedding_dim=256,\n",
    "                 dropout=0.1,\n",
    "                 freeze_backbone=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained backbone\n",
    "        self.backbone = AutoModel.from_pretrained(base_model)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "        \n",
    "        # Optionally freeze backbone for faster training\n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Projection head for contrastive learning\n",
    "        backbone_dim = self.backbone.config.hidden_size\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(backbone_dim, backbone_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(backbone_dim // 2, embedding_dim),\n",
    "            nn.LayerNorm(embedding_dim)\n",
    "        )\n",
    "        \n",
    "        print(f\"Model initialized with {backbone_dim} -> {embedding_dim} projection\")\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get contextual embeddings from backbone\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Attention-weighted pooling\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        attention_weights = attention_mask.unsqueeze(-1).float()\n",
    "        pooled = (hidden_states * attention_weights).sum(1) / attention_weights.sum(1)\n",
    "        \n",
    "        # Project to contrastive space\n",
    "        style_embedding = self.projection_head(pooled)\n",
    "        \n",
    "        # L2 normalize for cosine similarity\n",
    "        style_embedding = F.normalize(style_embedding, p=2, dim=1)\n",
    "        \n",
    "        return style_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoNCELoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        \"\"\"\n",
    "        anchor: [batch_size, embedding_dim]\n",
    "        positive: [batch_size, embedding_dim] \n",
    "        negative: [batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        batch_size = anchor.size(0)\n",
    "        \n",
    "        # Compute similarities\n",
    "        pos_sim = torch.sum(anchor * positive, dim=1) / self.temperature  # [batch_size]\n",
    "        neg_sim = torch.sum(anchor * negative, dim=1) / self.temperature  # [batch_size]\n",
    "        \n",
    "        # InfoNCE loss - positive should be more similar than negative\n",
    "        logits = torch.stack([pos_sim, neg_sim], dim=1)  # [batch_size, 2]\n",
    "        labels = torch.zeros(batch_size, dtype=torch.long, device=anchor.device)  # Positive is index 0\n",
    "        \n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        # Additional metrics\n",
    "        with torch.no_grad():\n",
    "            accuracy = (pos_sim > neg_sim).float().mean()\n",
    "            \n",
    "        return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(texts, labels, topics, tokenizer, batch_size=32, test_size=0.2):\n",
    "    \"\"\"Create train/validation data loaders\"\"\"\n",
    "    \n",
    "    # Split data\n",
    "    train_texts, val_texts, train_labels, val_labels, train_topics, val_topics = train_test_split(\n",
    "        texts, labels, topics, test_size=test_size, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(train_texts)}\")\n",
    "    print(f\"Validation samples: {len(val_texts)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ContrastiveDataset(train_texts, train_labels, train_topics, tokenizer)\n",
    "    val_dataset = ContrastiveDataset(val_texts, val_labels, val_topics, tokenizer)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader, (val_texts, val_labels, val_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 768 -> 256 projection\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing model...\")\n",
    "model = StyleContrastiveEncoder(\n",
    "    base_model=\"microsoft/deberta-v3-base\",\n",
    "    embedding_dim=256,\n",
    "    dropout=0.1,\n",
    "    freeze_backbone=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(\n",
    "#     # Set the project name, this helps you group runs\n",
    "#     project=\"style-detection-contrastive\", \n",
    "    \n",
    "#     # Track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 2e-5,\n",
    "#     \"architecture\": \"DeBERTa-v3-base\",\n",
    "#     \"dataset\": \"RAID-150k\",\n",
    "#     \"epochs\": 3,\n",
    "#     })\n",
    "print(\"Creating data loaders...\")\n",
    "train_loader, val_loader, val_data = create_data_loaders(\n",
    "    texts, labels, topics, model.module.tokenizer if hasattr(model, 'module') else model.tokenizer,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, device, lr=2e-5):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        \n",
    "        # Optimizer and scheduler\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=50)\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = InfoNCELoss(temperature=0.1)\n",
    "        \n",
    "        # Tracking\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
    "        for batch in pbar:\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Move batch to device\n",
    "            batch = {k: v.to(self.device,non_blocking=True) for k, v in batch.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            anchor_emb = self.model(batch['anchor_input_ids'], batch['anchor_attention_mask'])\n",
    "            positive_emb = self.model(batch['positive_input_ids'], batch['positive_attention_mask'])\n",
    "            negative_emb = self.model(batch['negative_input_ids'], batch['negative_attention_mask'])\n",
    "            \n",
    "            # Compute loss\n",
    "            loss, accuracy = self.criterion(anchor_emb, positive_emb, negative_emb)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{accuracy.item():.4f}'\n",
    "            })\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        avg_accuracy = total_accuracy / num_batches\n",
    "        \n",
    "        self.train_losses.append(avg_loss)\n",
    "        self.train_accuracies.append(avg_accuracy)\n",
    "        \n",
    "        return avg_loss, avg_accuracy\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_accuracy = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(self.device,non_blocking=True) for k, v in batch.items()}\n",
    "                \n",
    "                # Forward pass\n",
    "                anchor_emb = self.model(batch['anchor_input_ids'], batch['anchor_attention_mask'])\n",
    "                positive_emb = self.model(batch['positive_input_ids'], batch['positive_attention_mask'])\n",
    "                negative_emb = self.model(batch['negative_input_ids'], batch['negative_attention_mask'])\n",
    "                \n",
    "                # Compute loss\n",
    "                loss, accuracy = self.criterion(anchor_emb, positive_emb, negative_emb)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_accuracy += accuracy.item()\n",
    "                num_batches += 1\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        avg_accuracy = total_accuracy / num_batches\n",
    "        \n",
    "        self.val_losses.append(avg_loss)\n",
    "        self.val_accuracies.append(avg_accuracy)\n",
    "        \n",
    "        return avg_loss, avg_accuracy\n",
    "    \n",
    "    def train(self, num_epochs=10):\n",
    "        best_val_acc = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            \n",
    "            # Training\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc = self.validate_epoch()\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            print(f\"Learning Rate: {self.optimizer.param_groups[0]['lr']:.6f}\")\n",
    "            wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"validation_loss\": val_loss,\n",
    "            \"validation_accuracy\": val_acc})\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                }, 'best_style_model.pt')\n",
    "                print(f\"New best model saved with validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        \n",
    "        return best_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = StyleTrainer(model, train_loader, val_loader, device, lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "best_accuracy = trainer.train(num_epochs=3)\n",
    "print(f\"\\nTraining completed! Best validation accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(trainer.train_losses, label='Train Loss')\n",
    "plt.plot(trainer.val_losses, label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(trainer.train_accuracies, label='Train Accuracy')\n",
    "plt.plot(trainer.val_accuracies, label='Val Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(trainer.train_losses, label='Train Loss')\n",
    "plt.plot(trainer.val_losses, label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(trainer.train_accuracies, label='Train Accuracy')\n",
    "plt.plot(trainer.val_accuracies, label='Val Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png')\n",
    "plt.show()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(model, texts, labels, tokenizer, device, batch_size=64):\n",
    "    \"\"\"Compute class centroids for O(1) inference\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    human_embeddings = []\n",
    "    gpt4_embeddings = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Computing centroids\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        \n",
    "        # Tokenize batch\n",
    "        tokens = tokenizer(\n",
    "            batch_texts,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(tokens['input_ids'], tokens['attention_mask'])\n",
    "        \n",
    "        # Separate by class\n",
    "        for j, label in enumerate(batch_labels):\n",
    "            if label == 0:  # human\n",
    "                human_embeddings.append(embeddings[j].cpu())\n",
    "            else:  # gpt4\n",
    "                gpt4_embeddings.append(embeddings[j].cpu())\n",
    "    \n",
    "    # Compute centroids\n",
    "    human_embeddings = torch.stack(human_embeddings)\n",
    "    gpt4_embeddings = torch.stack(gpt4_embeddings)\n",
    "    \n",
    "    human_centroid = human_embeddings.mean(dim=0)\n",
    "    gpt4_centroid = gpt4_embeddings.mean(dim=0)\n",
    "    \n",
    "    # Normalize centroids\n",
    "    human_centroid = F.normalize(human_centroid, p=2, dim=0)\n",
    "    gpt4_centroid = F.normalize(gpt4_centroid, p=2, dim=0)\n",
    "    \n",
    "    print(f\"Computed centroids from {len(human_embeddings)} human and {len(gpt4_embeddings)} GPT-4 samples\")\n",
    "    \n",
    "    return human_centroid, gpt4_centroid\n",
    "\n",
    "# Load best model\n",
    "print(\"Loading best model...\")\n",
    "checkpoint = torch.load('best_style_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Compute centroids using validation data\n",
    "print(\"Computing class centroids...\")\n",
    "val_texts, val_labels, val_topics = val_data\n",
    "tokenizer = model.module.tokenizer if hasattr(model, 'module') else model.tokenizer\n",
    "\n",
    "human_centroid, gpt4_centroid = compute_centroids(\n",
    "    model, val_texts, val_labels, tokenizer, device\n",
    ")\n",
    "\n",
    "# Save centroids\n",
    "torch.save({\n",
    "    'human_centroid': human_centroid,\n",
    "    'gpt4_centroid': gpt4_centroid\n",
    "}, 'centroids.pt')\n",
    "\n",
    "print(\"Centroids saved to centroids.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts, val_labels, val_topics = val_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 768 -> 256 projection\n",
      "Style detector initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class StyleDetector:\n",
    "    def __init__(self, model_path, centroids_path, device='cuda'):\n",
    "        self.device = device\n",
    "        \n",
    "        # Load model\n",
    "        self.model = StyleContrastiveEncoder()\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        \n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model = self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = self.model.module.tokenizer if hasattr(self.model, 'module') else self.model.tokenizer\n",
    "        \n",
    "        # Load centroids\n",
    "        centroids = torch.load(centroids_path, map_location=device)\n",
    "        self.human_centroid = centroids['human_centroid'].to(device)\n",
    "        self.gpt4_centroid = centroids['gpt4_centroid'].to(device)\n",
    "        \n",
    "        print(\"Style detector initialized successfully!\")\n",
    "    \n",
    "    def detect(self, text):\n",
    "        \"\"\"Single text inference\"\"\"\n",
    "        # Tokenize\n",
    "        tokens = self.tokenizer(\n",
    "            text,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Get embedding\n",
    "        with torch.no_grad():\n",
    "            embedding = self.model(tokens['input_ids'], tokens['attention_mask'])\n",
    "        \n",
    "        # Compute similarities\n",
    "        human_sim = F.cosine_similarity(embedding, self.human_centroid.unsqueeze(0)).item()\n",
    "        gpt4_sim = F.cosine_similarity(embedding, self.gpt4_centroid.unsqueeze(0)).item()\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = \"human\" if human_sim > gpt4_sim else \"gpt4\"\n",
    "        confidence = abs(human_sim - gpt4_sim)\n",
    "        \n",
    "        return {\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence,\n",
    "            'human_similarity': human_sim,\n",
    "            'gpt4_similarity': gpt4_sim\n",
    "        }\n",
    "    \n",
    "    def batch_detect(self, texts, batch_size=32):\n",
    "        \"\"\"Batch inference for multiple texts\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            \n",
    "            # Tokenize batch\n",
    "            tokens = self.tokenizer(\n",
    "                batch_texts,\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                return_tensors='pt'\n",
    "            ).to(self.device)\n",
    "            \n",
    "            # Get embeddings\n",
    "            with torch.no_grad():\n",
    "                embeddings = self.model(tokens['input_ids'], tokens['attention_mask'])\n",
    "            \n",
    "            # Compute similarities\n",
    "            human_sims = F.cosine_similarity(embeddings, self.human_centroid.unsqueeze(0))\n",
    "            gpt4_sims = F.cosine_similarity(embeddings, self.gpt4_centroid.unsqueeze(0))\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = (human_sims > gpt4_sims).long()\n",
    "            confidences = torch.abs(human_sims - gpt4_sims)\n",
    "            \n",
    "            # Convert to results\n",
    "            for j in range(len(batch_texts)):\n",
    "                results.append({\n",
    "                    'text': batch_texts[j],\n",
    "                    'prediction': \"human\" if predictions[j] == 1 else \"gpt4\",\n",
    "                    'confidence': confidences[j].item(),\n",
    "                    'human_similarity': human_sims[j].item(),\n",
    "                    'gpt4_similarity': gpt4_sims[j].item()\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize detector\n",
    "detector = StyleDetector('best_style_model.pt', 'centroids.pt', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Load a new, large, and balanced test set\n",
    "# ==============================================================================\n",
    "print(\"Loading a new, larger test set for final evaluation...\")\n",
    "# Load 20k human and 20k GPT-4 samples from the RAID dataset.\n",
    "# We use a different seed (e.g., 123) to ensure we get a different random sample\n",
    "# from the one used for training and validation.\n",
    "try:\n",
    "    test_dataset = load_and_sample_raid_data(target='cohere-chat',samples_per_class=5000, seed=123)\n",
    "    print(f\"Total samples loaded for testing: {len(test_dataset)}\")\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 2. Prepare the data for evaluation\n",
    "    # ==============================================================================\n",
    "    print(\"\\nPreparing the new test data...\")\n",
    "    test_texts = [example['generation'] for example in test_dataset]\n",
    "    test_labels = [0 if example['model'] == 'human' else 1 for example in test_dataset]\n",
    "\n",
    "    print(f\"Test set summary:\")\n",
    "    print(f\"Total texts: {len(test_texts)}\")\n",
    "    print(f\"Human samples: {test_labels.count(0)}\")\n",
    "    print(f\"AI samples: {test_labels.count(1)}\")\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 3. Evaluate the model on the new test set\n",
    "    # ==============================================================================\n",
    "    # The `evaluate_model` function is already defined and includes the confusion matrix.\n",
    "    # We can use a larger batch size here to speed up evaluation on this bigger dataset.\n",
    "    print(\"\\nEvaluating model on the 40k balanced test set...\")\n",
    "    test_metrics = evaluate_model(detector, test_texts, test_labels, batch_size=64)\n",
    "\n",
    "    # ==============================================================================\n",
    "    # 4. Print the final results in detail\n",
    "    # ==============================================================================\n",
    "    print(\"\\n=== Final Test Set Results (40k samples) ===\")\n",
    "    print(f\"Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:    {test_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score:  {test_metrics['f1']:.4f}\")\n",
    "    print(f\"AUC:       {test_metrics['auc']:.4f}\")\n",
    "\n",
    "    # Print the formatted confusion matrix\n",
    "    print(\"\\n=== Confusion Matrix (40k Test Set) ===\")\n",
    "    cm = test_metrics['confusion_matrix']\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Print a formatted table for clarity\n",
    "    print(f\"                  | Predicted Human | Predicted AI\")\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    print(f\"Actual Human      | {tn:<15} | {fp:<12}\")\n",
    "    print(f\"Actual AI         | {fn:<15} | {tp:<12}\")\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    print(f\"\\nTrue Negatives (Human correctly identified): {tn}\")\n",
    "    print(f\"False Positives (Human mistaken for AI):   {fp}\")\n",
    "    print(f\"False Negatives (AI mistaken for Human):   {fn}\")\n",
    "    print(f\"True Positives (AI correctly identified):    {tp}\")\n",
    "\n",
    "    # Calculate and print the False Positive Rate (FPR)\n",
    "    if (fp + tn) > 0:\n",
    "        fpr = fp / (fp + tn)\n",
    "        print(f\"\\nFalse Positive Rate (FPR): {fpr:.4f}\")\n",
    "        print(f\"(This means {fpr:.2%} of human texts were incorrectly flagged as AI)\")\n",
    "    else:\n",
    "        print(\"\\nFalse Positive Rate (FPR): N/A (No actual human samples to calculate)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during the new evaluation: {e}\")\n",
    "    print(\"This might happen if the dataset is unavailable or due to memory constraints.\")\n",
    "\n",
    "finally:\n",
    "    # Clean up memory as the test set is large\n",
    "    print(\"\\nCleaning up memory...\")\n",
    "    del test_dataset, test_texts, test_labels, test_metrics\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(detector, texts, labels, batch_size=32):\n",
    "    \"\"\"Comprehensive model evaluation that now includes the confusion matrix.\"\"\"\n",
    "    \n",
    "    # Get predictions\n",
    "    results = detector.batch_detect(texts, batch_size)\n",
    "    \n",
    "    # Extract predictions and confidences\n",
    "    predictions = [1 if r['prediction'] == 'gpt4' else 0 for r in results]\n",
    "    confidences = [r['confidence'] for r in results]\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    \n",
    "    # For AUC, we need to convert confidences to probabilities\n",
    "    probs = []\n",
    "    for i, r in enumerate(results):\n",
    "        if r['prediction'] == 'gpt4':\n",
    "            probs.append(0.5 + r['confidence'] / 2)  # Scale to [0.5, 1]\n",
    "        else:\n",
    "            probs.append(0.5 - r['confidence'] / 2)  # Scale to [0, 0.5]\n",
    "    \n",
    "    auc = roc_auc_score(labels, probs)\n",
    "    \n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"Evaluating model on validation set...\")\n",
    "val_metrics = evaluate_model(detector, val_texts, val_labels)\n",
    "\n",
    "print(\"\\n=== Validation Results ===\")\n",
    "print(f\"Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {val_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {val_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {val_metrics['f1']:.4f}\")\n",
    "print(f\"AUC: {val_metrics['auc']:.4f}\")\n",
    "\n",
    "# Print the formatted confusion matrix\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "cm = val_metrics['confusion_matrix']\n",
    "# The ravel() function flattens the 2x2 matrix into a 1D array [TN, FP, FN, TP]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Print a formatted table\n",
    "print(f\"                 Predicted Human | Predicted AI\")\n",
    "print(f\"-------------------------------------------------\")\n",
    "print(f\"Actual Human    | {tn:<15} | {fp:<12}\")\n",
    "print(f\"Actual AI       | {fn:<15} | {tp:<12}\")\n",
    "print(f\"-------------------------------------------------\")\n",
    "print(f\"\\nTrue Negatives (Human correctly identified): {tn}\")\n",
    "print(f\"False Positives (Human mistaken for AI):   {fp}\")\n",
    "print(f\"False Negatives (AI mistaken for Human):   {fn}\")\n",
    "print(f\"True Positives (AI correctly identified):    {tp}\")\n",
    "\n",
    "# --- NEW: Calculate and print the False Positive Rate (FPR) ---\n",
    "# FPR = False Positives / (False Positives + True Negatives)\n",
    "if (fp + tn) > 0:\n",
    "    fpr = fp / (fp + tn)\n",
    "    print(f\"\\nFalse Positive Rate (FPR): {fpr:.4f}\")\n",
    "    print(f\"(This means {fpr:.2%} of human texts were incorrectly flagged as AI)\")\n",
    "else:\n",
    "    print(\"\\nFalse Positive Rate (FPR): N/A (No actual human samples to calculate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_metrics['predictions']), len(val_metrics['confidences']), len(val_texts), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 'human',\n",
       " 'confidence': 0.1785283088684082,\n",
       " 'human_similarity': 0.5264617204666138,\n",
       " 'gpt4_similarity': 0.34793341159820557}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.detect(text=\"We propose a novel methodology aimed at enhancing the interpretability and refinement of learned representations in machine learning models. Our approach centers on the conceptualization and visualization of geodesics within the manifold of learned representations. Through the extensive examination of these geodesics, our method enables a deeper understanding of the invariances encoded by the model. This newfound insight allows for the targeted refinement of learned representations, leading to improved performance and generalizability of the model. Experimental results across various datasets demonstrate the efficacy of our approach in uncovering subtle invariances and significantly boosting model robustness.\",\"Title: A Group Theoretic Perspective on Unsupervised Deep Learning\\n\\nAbstract:\\n\\nDeep Learning has demonstrated remarkable success across various domains, yet the theoretical underpinnings of its effectiveness remain a topic of ongoing investigation. This work explores the foundation of Deep Learning's success from a group theoretic standpoint, particularly in the context of unsupervised learning environments. We examine the core question of why Deep Learning excels by delving into the nature of the representations it captures and the mechanism through which higher-order representations emerge. Our analysis reveals that the intrinsic structure within data can be conceptualized as comprising symmetries and group actions, which Deep Learning models implicitly leverage to extract hierarchical features. By formalizing the learning process as the identification and exploitation of these underlying group structures, our study illuminates the pathway through which Deep Learning algorithms autonomously evolve complex representations from simple, primitive patterns. This group theoretic perspective not only provides a deeper understanding of the representational capabilities of unsupervised Deep Learning but also offers a principled framework to guide the development of more robust and interpretable models. Through this lens, we propose new insights into the mechanisms enabling the emergence of higher-order features, thereby contributing to a more comprehensive theoretical foundation for the continued advancement of Deep Learning methodologies.In this paper, we introduce the stacked what-where auto-encoders (SWWAE), a novel architectural framework designed to seamlessly integrate discriminative and generative models. SWWAE stacks multiple layers of what-where auto-encoders to efficiently learn hierarchical representations of input data, capturing both the content (what) and spatial (where) information. By combining the strengths of discriminative learning for accurate prediction with the generative capability of reconstructing inputs, SWWAE achieves superior performance in unsupervised, semi-supervised, and supervised learning tasks. Our experiments demonstrate the model's effectiveness in capturing complex data distributions and its superiority in various applications, including image recognition, object localization, and data generation. SWWAE represents a significant step forward in developing more powerful and versatile neural networks that leverage the best of both generative and discriminative learning paradigms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the already loaded detector...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Use the already loaded detector and model\n",
    "# ==============================================================================\n",
    "print(\"Using the already loaded detector...\")\n",
    "\n",
    "# The detector already has the model and tokenizer loaded\n",
    "model = detector.model\n",
    "tokenizer = detector.tokenizer\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Function to generate embeddings for a list of texts\n",
    "# ==============================================================================\n",
    "def get_embeddings(texts, model, tokenizer, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            embeddings = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Prepare a sample of your data for visualization\n",
    "# ==============================================================================\n",
    "# val_data is the tuple (val_texts, val_labels, val_topics) from your earlier code\n",
    "# val_texts, val_labels, _ = val_data\n",
    "\n",
    "# # Let's take a random sample to make the plot cleaner (e.g., 2000 points total)\n",
    "# num_samples = min(2000, len(val_texts))  # Don't exceed available data\n",
    "# random_indices = np.random.choice(len(val_texts), size=num_samples, replace=False)\n",
    "\n",
    "# sample_texts = [val_texts[i] for i in random_indices]\n",
    "# sample_labels = [val_labels[i] for i in random_indices]\n",
    "# label_names = ['Human' if l == 0 else 'GPT-4' for l in sample_labels]\n",
    "\n",
    "# # Generate embeddings for the sample\n",
    "# print(f\"Generating embeddings for {num_samples} samples...\")\n",
    "# embeddings = get_embeddings(sample_texts, model, tokenizer)\n",
    "\n",
    "# # ==============================================================================\n",
    "# # 4. Apply dimensionality reduction (t-SNE)\n",
    "# # ==============================================================================\n",
    "# print(\"Running t-SNE... (this may take a minute)\")\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42, max_iter=1000)\n",
    "# embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "# # ==============================================================================\n",
    "# # 5. Plot the results\n",
    "# # ==============================================================================\n",
    "# print(\"Plotting results...\")\n",
    "# plt.style.use('default')  # Use default style for better visibility\n",
    "# plt.figure(figsize=(14, 10))\n",
    "\n",
    "# # Create the scatter plot\n",
    "# scatter = plt.scatter(\n",
    "#     embeddings_2d[:, 0],\n",
    "#     embeddings_2d[:, 1],\n",
    "#     c=[0 if label == 'Human' else 1 for label in label_names],\n",
    "#     cmap='viridis',\n",
    "#     s=50,\n",
    "#     alpha=0.7\n",
    "# )\n",
    "\n",
    "# plt.title('t-SNE Visualization of Human vs. GPT-4 Text Style Embeddings', fontsize=16)\n",
    "# plt.xlabel('t-SNE Dimension 1')\n",
    "# plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "# # Create custom legend\n",
    "# import matplotlib.patches as mpatches\n",
    "# human_patch = mpatches.Patch(color='purple', label='Human')\n",
    "# gpt4_patch = mpatches.Patch(color='yellow', label='GPT-4')\n",
    "# plt.legend(handles=[human_patch, gpt4_patch], title='Author Style')\n",
    "\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.savefig('style_embedding_visualization.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "# # Print some statistics\n",
    "# print(f\"\\nVisualization Statistics:\")\n",
    "# print(f\"Total samples visualized: {num_samples}\")\n",
    "# print(f\"Human samples: {sum(1 for l in label_names if l == 'Human')}\")\n",
    "# print(f\"GPT-4 samples: {sum(1 for l in label_names if l == 'GPT-4')}\")\n",
    "# print(f\"Embedding dimension: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def extract_assistant_response(conversation_str: str):\n",
    "    \"\"\"\n",
    "    Parses the conversation list and returns the content of the first 'assistant' role.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The data is a string representation of a list of dicts, so we parse it.\n",
    "        # Note: In some Hugging Face viewers it's pre-parsed, but in `load_dataset` it's often a string.\n",
    "        # We'll handle both cases.\n",
    "        if isinstance(conversation_str, str):\n",
    "            conversation = json.loads(conversation_str)\n",
    "        else:\n",
    "            conversation = conversation_str # Already a list\n",
    "\n",
    "        for turn in conversation:\n",
    "            if turn.get(\"role\") == \"assistant\":\n",
    "                return turn.get(\"content\", \"\")\n",
    "        return \"\" # Return empty string if no assistant response found\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return \"\" # Handle malformed or empty data\n",
    "\n",
    "def process_arena_data(dataset):\n",
    "    \"\"\"\n",
    "    Processes the Arena dataset to create a flat list of (model_name, response_text).\n",
    "    \"\"\"\n",
    "    print(\"Processing Arena dataset...\")\n",
    "    processed_data = []\n",
    "    \n",
    "    for row in tqdm(dataset):\n",
    "        # Extract response for model_a\n",
    "        response_a = extract_assistant_response(row['conversation_a'])\n",
    "        if response_a: # Only add if response is not empty\n",
    "            processed_data.append({'model': row['model_a'], 'text': response_a})\n",
    "            \n",
    "        # Extract response for model_b\n",
    "        response_b = extract_assistant_response(row['conversation_b'])\n",
    "        if response_b: # Only add if response is not empty\n",
    "            processed_data.append({'model': row['model_b'], 'text': response_b})\n",
    "            \n",
    "    df = pd.DataFrame(processed_data)\n",
    "    unique_models = df['model'].unique()\n",
    "    print(f\"\\nProcessed {len(df)} total responses.\")\n",
    "    print(f\"Found {len(unique_models)} unique models.\")\n",
    "    return df, unique_models\n",
    "\n",
    "# --- Main Data Loading ---\n",
    "print(\"Loading lmsys/lmsys-arena-100k dataset...\")\n",
    "# Note: This dataset is large, this might take some time.\n",
    "arena_dataset = load_dataset(\"lmarena-ai/arena-human-preference-100k\", split='train')\n",
    "\n",
    "print(\"Filtering for English conversations...\")\n",
    "english_arena = arena_dataset.filter(lambda x: x.get('language') == 'English')\n",
    "\n",
    "# Process the dataset to get our clean data\n",
    "arena_df, unique_arena_models = process_arena_data(english_arena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>models</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>My mom is shaming me for wanting to get off of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ai</td>\n",
       "      <td>DAE feel like their dreams make up memories? A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ai</td>\n",
       "      <td>FBI agent colludes with analyst An FBI agent s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>human</td>\n",
       "      <td>Towards the effectiveness of Deep Convolutiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>human</td>\n",
       "      <td>Helen  Helen tells the story of a young orphan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 models                                               text\n",
       "0           0  human  My mom is shaming me for wanting to get off of...\n",
       "1           1     ai  DAE feel like their dreams make up memories? A...\n",
       "2           2     ai  FBI agent colludes with analyst An FBI agent s...\n",
       "3           3  human  Towards the effectiveness of Deep Convolutiona...\n",
       "4           4  human  Helen  Helen tells the story of a young orphan..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('/home/jivnesh/Rishi_Surge/data_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def run_full_evaluation(classifier, arena_df):\n",
    "    \"\"\"\n",
    "    Runs a comprehensive evaluation on the Arena dataset.\n",
    "    This version correctly calculates the AI Detection Rate for each model.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*35)\n",
    "    print(\"Per-Model AI Detection Performance\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    unique_models = arena_df['model'].unique()\n",
    "    for model_name in sorted(unique_models):\n",
    "        model_texts = arena_df[arena_df['model'] == model_name]['text'].tolist()\n",
    "        if not model_texts:\n",
    "            continue\n",
    "            \n",
    "        # Get predictions and confidences from your classifier\n",
    "        results = classifier.batch_detect(model_texts, batch_size=32)\n",
    "        predictions = [1 if r['prediction'] == 'gpt4' else 0 for r in results]\n",
    "        \n",
    "        # --- THE FIX ---\n",
    "        # The \"ground truth\" is that all these samples are AI (label 1).\n",
    "        # However, for this specific calculation, we don't need a separate labels array.\n",
    "        # The AI Detection Rate is simply the mean of the predictions.\n",
    "        \n",
    "        ai_detection_rate = np.mean(predictions) * 100\n",
    "    \n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"AI Detection Rate: {ai_detection_rate:.2f}%\")\n",
    "        print(f\"({sum(predictions)} out of {len(model_texts)} samples were classified as AI)\")\n",
    "\n",
    "# You can still calculate AUC if your classifier provides confidence scores,\n",
    "# as AUC measures the ability to rank predictions correctly, which is still valid.\n",
    "# The code for confidence and AUC calculation can remain if desired.\n",
    "# Note: Part 2 of the function remains commented out as in your original code.\n",
    "\n",
    "# --- Correct way to call the function ---\n",
    "# run_full_evaluation(detector, arena_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_full_evaluation(detector, arena_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 119\u001b[39m\n\u001b[32m    114\u001b[39m TARGET_FAMILY_PATTERN = \u001b[33m'\u001b[39m\u001b[33mgpt-4o-2024-08-06\u001b[39m\u001b[33m'\u001b[39m \n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Run the full test\u001b[39;00m\n\u001b[32m    117\u001b[39m test_family_classification_accuracy(\n\u001b[32m    118\u001b[39m     model, \n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[43mtokenizer\u001b[49m, \n\u001b[32m    120\u001b[39m     arena_df, \n\u001b[32m    121\u001b[39m     val_texts, \n\u001b[32m    122\u001b[39m     val_labels, \n\u001b[32m    123\u001b[39m     TARGET_FAMILY_PATTERN\n\u001b[32m    124\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ==============================================================================\n",
    "#  Prerequisites: Ensure these variables are loaded and functions are defined\n",
    "# ==============================================================================\n",
    "# \n",
    "# model: Your trained and loaded StyleContrastiveEncoder model, set to eval() mode.\n",
    "# tokenizer: The tokenizer corresponding to your model.\n",
    "# get_embeddings(texts, model, tokenizer): Your function to generate embeddings.\n",
    "# arena_df: The DataFrame containing processed data from the lmsys-arena-100k dataset.\n",
    "# val_texts, val_labels: The validation texts and labels from your original data split.\n",
    "# \n",
    "# ==============================================================================\n",
    "\n",
    "class FamilyStyleClassifier:\n",
    "    \"\"\"A classifier specialized for distinguishing Human vs. a specific AI model family.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, human_reference_texts, ai_family_reference_texts):\n",
    "        self.model = model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        print(\"Calculating Human style centroid...\")\n",
    "        human_embeddings = get_embeddings(human_reference_texts, self.model, self.tokenizer)\n",
    "        self.human_centroid = np.mean(human_embeddings, axis=0, keepdims=True)\n",
    "        \n",
    "        print(\"Calculating combined AI Family style centroid...\")\n",
    "        ai_family_embeddings = get_embeddings(ai_family_reference_texts, self.model, self.tokenizer)\n",
    "        self.ai_family_centroid = np.mean(ai_family_embeddings, axis=0, keepdims=True)\n",
    "        \n",
    "        print(\"Specialized classifier is ready.\")\n",
    "\n",
    "    def predict(self, texts_to_classify):\n",
    "        \"\"\"Predicts whether texts are Human (0) or from the AI Family (1).\"\"\"\n",
    "        embeddings = get_embeddings(texts_to_classify, self.model, self.tokenizer)\n",
    "        \n",
    "        sim_to_human = cosine_similarity(embeddings, self.human_centroid)\n",
    "        sim_to_ai_family = cosine_similarity(embeddings, self.ai_family_centroid)\n",
    "        \n",
    "        # Predict 1 (AI Family) if closer to the AI Family centroid\n",
    "        return (sim_to_ai_family > sim_to_human).astype(int).flatten()\n",
    "\n",
    "def test_family_classification_accuracy(model, tokenizer, arena_df, val_texts, val_labels, family_name_pattern):\n",
    "    \"\"\"\n",
    "    Tests the classification accuracy for a specific family of models against human text.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Starting Accuracy Test for Model Family: '{family_name_pattern}'\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # --- 1. Isolate Data for the Target Family and Humans ---\n",
    "    \n",
    "    # Find all models in the Arena dataset that match the pattern\n",
    "    target_models = [name for name in arena_df['model'].unique() if family_name_pattern in name]\n",
    "    if not target_models:\n",
    "        print(f\"Error: No models found matching the pattern '{family_name_pattern}'. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found target models: {target_models}\")\n",
    "    \n",
    "    # Get all texts for this family to be used for both training the classifier and testing\n",
    "    target_family_texts = arena_df[arena_df['model'].isin(target_models)]['text'].tolist()\n",
    "    \n",
    "    # Get all human texts from your original validation set\n",
    "    human_texts = [text for text, label in zip(val_texts, val_labels) if label == 0]\n",
    "    \n",
    "    if len(target_family_texts) == 0 or len(human_texts) == 0:\n",
    "        print(\"Error: Not enough data for the target family or humans. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(target_family_texts)} samples for the AI family and {len(human_texts)} human samples.\")\n",
    "\n",
    "    # --- 2. Create the Specialized Classifier ---\n",
    "    \n",
    "    # We use all available texts to create the most robust possible centroids\n",
    "    family_classifier = FamilyStyleClassifier(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        human_reference_texts=human_texts, \n",
    "        ai_family_reference_texts=target_family_texts\n",
    "    )\n",
    "\n",
    "    # --- 3. Run Evaluation ---\n",
    "    \n",
    "    # The test set is the same data we used to build the centroids\n",
    "    test_texts = target_family_texts + human_texts\n",
    "    # Ground truth: 1 for AI family, 0 for Human\n",
    "    ground_truth = [1] * len(target_family_texts) + [0] * len(human_texts)\n",
    "    \n",
    "    print(\"\\nPredicting labels for the test set...\")\n",
    "    predictions = family_classifier.predict(test_texts)\n",
    "\n",
    "    # --- 4. Report Results ---\n",
    "    \n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    report = classification_report(\n",
    "        ground_truth, \n",
    "        predictions, \n",
    "        target_names=['Human', f'AI Family ({family_name_pattern})']\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(ground_truth, predictions)\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#                                EXECUTION\n",
    "# ==============================================================================\n",
    "# Define the pattern for the model family you want to test\n",
    "TARGET_FAMILY_PATTERN = 'gpt-4o-2024-08-06' \n",
    "\n",
    "# Run the full test\n",
    "test_family_classification_accuracy(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    arena_df, \n",
    "    val_texts, \n",
    "    val_labels, \n",
    "    TARGET_FAMILY_PATTERN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ==============================================================================\n",
    "#  Prerequisites: Same as before (model, tokenizer, get_embeddings, etc.)\n",
    "# ==============================================================================\n",
    "# Your FamilyStyleClassifier class remains the same.\n",
    "# ... (FamilyStyleClassifier class definition here) ...\n",
    "\n",
    "def test_few_shot_classification_accuracy(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    arena_df, \n",
    "    val_texts, \n",
    "    val_labels, \n",
    "    family_name_pattern, \n",
    "    num_support_samples=25  # The number of samples to build the centroid from\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs a few-shot evaluation.\n",
    "    Uses `num_support_samples` to create style centroids and tests on the rest.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Starting FEW-SHOT Accuracy Test for: '{family_name_pattern}'\")\n",
    "    print(f\"Using {num_support_samples} samples to define each style centroid.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # --- 1. Isolate Data ---\n",
    "    target_models = [name for name in arena_df['model'].unique() if family_name_pattern in name]\n",
    "    if not target_models:\n",
    "        print(f\"Error: No models found matching the pattern '{family_name_pattern}'. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found target models: {target_models}\")\n",
    "    target_family_texts = arena_df[arena_df['model'].isin(target_models)]['text'].tolist()\n",
    "    human_texts = [text for text, label in zip(val_texts, val_labels) if label == 0]\n",
    "    \n",
    "    # Check if there's enough data for a meaningful split\n",
    "    if len(target_family_texts) < num_support_samples + 10 or len(human_texts) < num_support_samples + 10:\n",
    "        print(\"Error: Not enough unique samples for a meaningful few-shot evaluation. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. THE KEY CHANGE: Create Few-Shot Support and Query Sets ---\n",
    "    print(f\"\\nCreating support set (for centroids) and query set (for testing)...\")\n",
    "    \n",
    "    # Shuffle the lists to ensure random sampling\n",
    "    random.shuffle(target_family_texts)\n",
    "    random.shuffle(human_texts)\n",
    "\n",
    "    # Create the small support sets for building the centroids\n",
    "    ai_support_texts = target_family_texts[:num_support_samples]\n",
    "    human_support_texts = human_texts[:num_support_samples]\n",
    "\n",
    "    # The rest of the data becomes the unseen query set for testing\n",
    "    ai_query_texts = target_family_texts[num_support_samples:]\n",
    "    human_query_texts = human_texts[num_support_samples:]\n",
    "    \n",
    "    print(f\"Support set size: {len(ai_support_texts)} AI, {len(human_support_texts)} Human\")\n",
    "    print(f\"Query set size (test set): {len(ai_query_texts)} AI, {len(human_query_texts)} Human\")\n",
    "\n",
    "    # --- 3. Create the Classifier using ONLY the small Support Set ---\n",
    "    family_classifier = FamilyStyleClassifier(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        human_reference_texts=human_support_texts, \n",
    "        ai_family_reference_texts=ai_support_texts\n",
    "    )\n",
    "\n",
    "    # --- 4. Run Evaluation on the UNSEEN Query Set ---\n",
    "    test_texts = ai_query_texts + human_query_texts\n",
    "    ground_truth = [1] * len(ai_query_texts) + [0] * len(human_query_texts)\n",
    "    \n",
    "    print(\"\\nPredicting labels for the unseen query set...\")\n",
    "    predictions = family_classifier.predict(test_texts)\n",
    "\n",
    "    # --- 5. Report True Few-Shot Generalization Results ---\n",
    "    print(f\"\\n--- Classification Report (trained on {num_support_samples} shots) ---\")\n",
    "    report = classification_report(\n",
    "        ground_truth, \n",
    "        predictions, \n",
    "        target_names=['Human', f'AI Family ({family_name_pattern})']\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    overall_accuracy = accuracy_score(ground_truth, predictions)\n",
    "    print(f\"Overall Few-Shot Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#                                EXECUTION\n",
    "# ==============================================================================\n",
    "# Define the pattern for the model family you want to test\n",
    "TARGET_FAMILY_PATTERN = 'chatgpt-4o-latest' \n",
    "\n",
    "# Run the few-shot test. You can vary `num_support_samples`.\n",
    "test_few_shot_classification_accuracy(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    arena_df, \n",
    "    val_texts, \n",
    "    val_labels, \n",
    "    TARGET_FAMILY_PATTERN,\n",
    "    num_support_samples=100 # Let's try building the centroid with just 25 examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# You need your trained model, tokenizer, and the `get_embeddings` function from previous steps\n",
    "# --- Load your best model (using the robust method) ---\n",
    "# ... (your model loading code here) ...\n",
    "# model.load_state_dict(...)\n",
    "# model.eval()\n",
    "\n",
    "# --- 1. Prepare a balanced sample of data for plotting ---\n",
    "print(\"\\nPreparing data for visualization...\")\n",
    "\n",
    "# A) Sample from the new Arena dataset\n",
    "samples_per_arena_model = 500 # Adjust as needed\n",
    "arena_sample_df = arena_df.groupby('model').sample(n=samples_per_arena_model, random_state=42, replace=True)\n",
    "new_model_sample = [(row['text'], row['model']) for index, row in arena_sample_df.iterrows()]\n",
    "print(f\"Sampled {len(new_model_sample)} responses from the Arena dataset.\")\n",
    "\n",
    "# B) Load your original Human/GPT-4 validation data for context\n",
    "val_texts, val_labels, _ = val_data\n",
    "\n",
    "# Let's take a random sample to make the plot cleaner (e.g., 2000 points total)\n",
    "num_samples = min(2000, len(val_texts))  # Don't exceed available data\n",
    "random_indices = np.random.choice(len(val_texts), size=num_samples, replace=False)\n",
    "\n",
    "sample_texts = [val_texts[i] for i in random_indices]\n",
    "sample_labels = [val_labels[i] for i in random_indices]\n",
    "label_names = ['Human' if l == 0 else 'GPT-4' for l in sample_labels]\n",
    "# C) Combine all data\n",
    "all_samples = sample_texts  + new_model_sample\n",
    "all_texts_for_plot = [s[0] for s in all_samples]\n",
    "all_labels_for_plot = [s[1] for s in all_samples]\n",
    "\n",
    "# --- 2. Generate embeddings for the combined dataset ---\n",
    "print(\"Generating embeddings for all samples...\")\n",
    "all_embeddings = get_embeddings(all_texts_for_plot, model, tokenizer)\n",
    "\n",
    "# --- 3. Run t-SNE ---\n",
    "print(\"Running t-SNE on the combined data... (this will take time)\")\n",
    "tsne = TSNE(n_components=2, perplexity=50, random_state=42, max_iter=1000, init='pca', learning_rate='auto')\n",
    "embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "# --- 4. Plot the results ---\n",
    "print(\"Plotting results...\")\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(20, 16)) # Use a larger figure size for more models\n",
    "\n",
    "# Create a dynamic palette for all the unique labels\n",
    "unique_labels_for_plot = sorted(list(set(all_labels_for_plot)))\n",
    "palette = sns.color_palette(\"hsv\", len(unique_labels_for_plot))\n",
    "color_map = dict(zip(unique_labels_for_plot, palette))\n",
    "\n",
    "# Explicitly set colors for known categories for consistency\n",
    "color_map['Human'] = 'cyan'\n",
    "color_map['GPT-4 (trained)'] = 'yellow'\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=embeddings_2d[:, 0],\n",
    "    y=embeddings_2d[:, 1],\n",
    "    hue=all_labels_for_plot,\n",
    "    hue_order=unique_labels_for_plot,\n",
    "    palette=color_map,\n",
    "    s=50,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "plt.title('t-SNE Visualization of Human vs. Multiple AI Model Styles', fontsize=20)\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(title='Author/Model', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
    "\n",
    "plt.savefig('arena_model_style_visualization.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## harshit-split eval \n",
    "\n",
    "import pandas as pd \n",
    "file_path = \"/home/jivnesh/Rishi_Surge/data_1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# ==============================================================================\n",
    "#  Prerequisites: Ensure these are defined and loaded from your project\n",
    "# ==============================================================================\n",
    "#\n",
    "# class StyleClassifier:\n",
    "#     # ... (The class definition you have from previous steps) ...\n",
    "#     def predict(self, texts_to_classify, batch_size=32):\n",
    "#         \"\"\"\n",
    "#         Predicts labels for a list of texts with batching.\n",
    "#         This method is assumed to be part of your StyleClassifier.\n",
    "#         \"\"\"\n",
    "#         all_predictions = []\n",
    "#         # The tqdm wrapper provides the progress bar\n",
    "#         for i in tqdm(range(0, len(texts_to_classify), batch_size), desc=\"Detecting\"):\n",
    "#             batch_texts = texts_to_classify[i:i + batch_size]\n",
    "#             \n",
    "#             # The core logic from your existing detector\n",
    "#             embeddings = get_embeddings(batch_texts, self.model, self.tokenizer)\n",
    "#             sim_to_human = cosine_similarity(embeddings, self.human_centroid)\n",
    "#             sim_to_ai = cosine_similarity(embeddings, self.ai_family_centroid) # Or your gpt4_centroid\n",
    "#             batch_preds = (sim_to_ai > sim_to_human).astype(int).flatten()\n",
    "#             \n",
    "#             all_predictions.extend(batch_preds)\n",
    "#         return np.array(all_predictions)\n",
    "#\n",
    "# detector: An initialized instance of your StyleClassifier.\n",
    "#\n",
    "# ==============================================================================\n",
    "\n",
    "def evaluate_dataframe(detector, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Runs a full evaluation on a DataFrame with 'text' and 'models' columns.\n",
    "    \n",
    "    Args:\n",
    "        detector: Your trained and initialized StyleClassifier instance.\n",
    "        df (pd.DataFrame): The DataFrame to evaluate.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating DataFrame with {len(df)} samples...\")\n",
    "    \n",
    "    # --- 1. Prepare Data ---\n",
    "    # Extract texts and convert string labels ('human'/'ai') to integers (0/1)\n",
    "    texts_to_evaluate = df['text'].tolist()\n",
    "    ground_truth_labels = df['models'].apply(lambda x: 0 if x.lower() == 'human' else 1).tolist()\n",
    "\n",
    "    # --- 2. Get Predictions (with progress bar) ---\n",
    "    # The progress bar is handled inside the detector's predict method\n",
    "    predictions = detector.batch_detect(texts_to_evaluate,batch_size=32)\n",
    "    \n",
    "    # --- 3. Calculate and Print Metrics ---\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"  Evaluation Results\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # Generate and print the classification report\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    report = classification_report(\n",
    "        ground_truth_labels, \n",
    "        predictions, \n",
    "        target_names=['Human (Class 0)', 'AI (Class 1)']\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # Print overall accuracy\n",
    "    overall_accuracy = accuracy_score(ground_truth_labels, predictions)\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    \n",
    "    # Calculate and print the confusion matrix\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(ground_truth_labels, predictions)\n",
    "    try:\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    except ValueError: # Handle case where only one class is present in predictions\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0\n",
    "        if len(cm) == 1 and np.sum(ground_truth_labels) == 0: tn = cm[0,0]\n",
    "        elif len(cm) == 1: tp = cm[0,0]\n",
    "\n",
    "    # Print a formatted table\n",
    "    print(f\"                 Predicted Human | Predicted AI\")\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    print(f\"Actual Human    | {tn:<15} | {fp:<12}\")\n",
    "    print(f\"Actual AI       | {fn:<15} | {tp:<12}\")\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    print(f\"\\nTrue Negatives (Human as Human): {tn}\")\n",
    "    print(f\"False Positives (Human as AI):   {fp}\")\n",
    "    print(f\"False Negatives (AI as Human):   {fn}\")\n",
    "    print(f\"True Positives (AI as AI):       {tp}\")\n",
    "    \n",
    "    # Calculate and print the False Positive Rate (FPR)\n",
    "    if (fp + tn) > 0:\n",
    "        fpr = fp / (fp + tn)\n",
    "        print(f\"\\nFalse Positive Rate (FPR): {fpr:.4f} ({fpr:.2%})\")\n",
    "        print(\"(The percentage of all human texts that were incorrectly flagged as AI)\")\n",
    "    else:\n",
    "        print(\"\\nFalse Positive Rate (FPR): N/A (No actual human samples)\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "\n",
    "evaluate_dataframe(detector, df)\n",
    "\n",
    "# evaluate_dataframe(detector, my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PREREQUISITE: MODEL ARCHITECTURE\n",
    "# ==============================================================================\n",
    "class StyleContrastiveEncoder(nn.Module):\n",
    "    \"\"\"The definition of your model architecture.\"\"\"\n",
    "    def __init__(self, base_model=\"microsoft/deberta-v3-base\", embedding_dim=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(base_model)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "        \n",
    "        backbone_dim = self.backbone.config.hidden_size\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(backbone_dim, backbone_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(backbone_dim // 2, embedding_dim),\n",
    "            nn.LayerNorm(embedding_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        attention_weights = attention_mask.unsqueeze(-1).float()\n",
    "        pooled = (hidden_states * attention_weights).sum(1) / attention_weights.sum(1).clamp(min=1e-9)\n",
    "        style_embedding = self.projection_head(pooled)\n",
    "        return F.normalize(style_embedding, p=2, dim=1)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. OPTIMIZED & REFINED StyleDetector CLASS\n",
    "# ==============================================================================\n",
    "class StyleDetector:\n",
    "    \"\"\"\n",
    "    An optimized version of the detector class.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, centroids_path, device='cuda'):\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        # Load model\n",
    "        self.model = StyleContrastiveEncoder()\n",
    "        \n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        model_state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        \n",
    "        if list(model_state_dict.keys())[0].startswith('module.'):\n",
    "            from collections import OrderedDict\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in model_state_dict.items():\n",
    "                name = k[7:] # remove `module.`\n",
    "                new_state_dict[name] = v\n",
    "            model_state_dict = new_state_dict\n",
    "            \n",
    "        self.model.load_state_dict(model_state_dict)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        try:\n",
    "            self.model = torch.compile(self.model)\n",
    "            print(\"Model compiled successfully (PyTorch 2.0+).\")\n",
    "        except Exception:\n",
    "            print(\"Could not compile model (PyTorch < 2.0 or other issue).\")\n",
    "\n",
    "        self.tokenizer = self.model.tokenizer\n",
    "        \n",
    "        if centroids_path and os.path.exists(centroids_path):\n",
    "            centroids = torch.load(centroids_path, map_location=self.device)\n",
    "            self.human_centroid = centroids['human_centroid'].to(self.device)\n",
    "            self.gpt4_centroid = centroids['gpt4_centroid'].to(self.device)\n",
    "            print(f\"Style detector initialized successfully on {self.device}!\")\n",
    "        else:\n",
    "            self.human_centroid = None\n",
    "            self.gpt4_centroid = None\n",
    "            print(f\"Detector initialized on {self.device} without centroids. Use for embedding generation only.\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_embeddings(self, texts, batch_size=256):\n",
    "        \"\"\"Helper function to get embeddings for a list of texts.\"\"\"\n",
    "        all_embeddings = []\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Getting Embeddings\"):\n",
    "            batch_texts = texts[i : i + batch_size]\n",
    "            tokens = self.tokenizer(\n",
    "                batch_texts, max_length=512, truncation=True, padding=True, return_tensors='pt'\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                embeddings_batch = self.model(tokens['input_ids'], tokens['attention_mask'])\n",
    "            all_embeddings.append(embeddings_batch.cpu())\n",
    "        \n",
    "        return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "    def batch_predict(self, texts, batch_size=256):\n",
    "        \"\"\"\n",
    "        Optimized batch prediction. Returns a list of integer predictions (0=Human, 1=AI).\n",
    "        \"\"\"\n",
    "        if self.human_centroid is None or self.gpt4_centroid is None:\n",
    "            raise ValueError(\"Centroids are not loaded. Cannot make predictions.\")\n",
    "            \n",
    "        embeddings = self._get_embeddings(texts, batch_size).to(self.device)\n",
    "        \n",
    "        human_sims = F.cosine_similarity(embeddings, self.human_centroid.unsqueeze(0))\n",
    "        gpt4_sims = F.cosine_similarity(embeddings, self.gpt4_centroid.unsqueeze(0))\n",
    "        \n",
    "        predictions = (gpt4_sims > human_sims).long()\n",
    "        \n",
    "        return predictions.cpu().numpy().tolist()\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. HELPER FUNCTION TO CREATE CENTROIDS FILE (Run this once)\n",
    "# ==============================================================================\n",
    "def create_centroids(model_path, training_df_path, output_path='centroids.pt'):\n",
    "    \"\"\"\n",
    "    Calculates and saves the Human and GPT-4 centroids from a training dataset.\n",
    "    \"\"\"\n",
    "    print(\"Creating centroids file...\")\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    temp_detector = StyleDetector(model_path=model_path, centroids_path=None, device=device)\n",
    "\n",
    "    df_train = pd.read_csv(training_df_path)\n",
    "    human_texts = df_train[df_train['models'] == 'human']['text'].tolist()\n",
    "    gpt4_texts = df_train[df_train['models'] == 'ai']['text'].tolist()\n",
    "\n",
    "    print(\"Calculating human centroid...\")\n",
    "    human_embeddings = temp_detector._get_embeddings(human_texts, 256)\n",
    "    human_centroid = torch.mean(human_embeddings.float(), dim=0)\n",
    "    \n",
    "    print(\"Calculating gpt4 centroid...\")\n",
    "    gpt4_embeddings = temp_detector._get_embeddings(gpt4_texts, 256)\n",
    "    gpt4_centroid = torch.mean(gpt4_embeddings.float(), dim=0)\n",
    "    \n",
    "    torch.save({'human_centroid': human_centroid, 'gpt4_centroid': gpt4_centroid}, output_path)\n",
    "    print(f\"Centroids saved successfully to {output_path}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. NEW: SINGLE-GPU EVALUATION FUNCTION\n",
    "# ==============================================================================\n",
    "def evaluate_dataframe(detector, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Runs a full evaluation on a single GPU using a DataFrame with 'text' and 'models' columns.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating DataFrame with {len(df)} samples...\")\n",
    "    \n",
    "    texts_to_evaluate = df['text'].tolist()\n",
    "    ground_truth_labels = df['models'].apply(lambda x: 0 if x.lower() == 'human' else 1).tolist()\n",
    "\n",
    "    predictions = detector.batch_predict(texts_to_evaluate)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"  Evaluation Results\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    report = classification_report(\n",
    "        ground_truth_labels, \n",
    "        predictions, \n",
    "        target_names=['Human (Class 0)', 'AI (Class 1)']\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    cm = confusion_matrix(ground_truth_labels, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    print(f\"                 Predicted Human | Predicted AI\")\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    print(f\"Actual Human    | {tn:<15} | {fp:<12}\")\n",
    "    print(f\"Actual AI       | {fn:<15} | {tp:<12}\")\n",
    "    print(f\"-------------------------------------------------\")\n",
    "    \n",
    "    if (fp + tn) > 0:\n",
    "        fpr = fp / (fp + tn)\n",
    "        print(f\"\\nFalse Positive Rate (FPR): {fpr:.4f} ({fpr:.2%})\")\n",
    "    else:\n",
    "        print(\"\\nFalse Positive Rate (FPR): N/A (No actual human samples)\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. MULTI-GPU WORKER FUNCTION\n",
    "# ==============================================================================\n",
    "def process_chunk(args):\n",
    "    \"\"\"\n",
    "    Worker function that processes a DataFrame chunk on a specific GPU.\n",
    "    \"\"\"\n",
    "    df_chunk, gpu_id, model_path, centroids_path = args\n",
    "    device = f'cuda:{gpu_id}'\n",
    "    detector = StyleDetector(model_path, centroids_path, device=device)\n",
    "    \n",
    "    texts = df_chunk['text'].tolist()\n",
    "    labels = df_chunk['models'].apply(lambda x: 0 if x.lower() == 'human' else 1).tolist()\n",
    "    \n",
    "    predictions = detector.batch_predict(texts)\n",
    "    \n",
    "    print(f\"Process on GPU {gpu_id} finished processing {len(df_chunk)} rows.\")\n",
    "    return labels, predictions\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    # --- Step A: Create Dummy Files (for demonstration) ---\n",
    "\n",
    "    \n",
    "    # --- OPTION 1: Single-GPU Evaluation (using the new function) ---\n",
    "    print(\"\\n--- Running Single-GPU Evaluation ---\")\n",
    "    single_gpu_detector = StyleDetector(\n",
    "        model_path='best_style_model.pt', \n",
    "        centroids_path='centroids.pt',\n",
    "        device='cuda:0'\n",
    "    )\n",
    "    evaluate_dataframe(single_gpu_detector, df)\n",
    "\n",
    "\n",
    "    # --- OPTION 2: Multi-GPU Evaluation (for very large datasets) ---\n",
    "    # print(\"\\n--- Running Multi-GPU Evaluation ---\")\n",
    "    # full_df = pd.read_csv('dummy_large_eval.csv')\n",
    "    # num_gpus = torch.cuda.device_count()\n",
    "    # if num_gpus > 1:\n",
    "    #     print(f\"Found {num_gpus} GPUs. Splitting data into {num_gpus} chunks.\")\n",
    "    #     df_chunks = np.array_split(full_df, num_gpus)\n",
    "    #     process_args = [\n",
    "    #         (chunk, i, 'dummy_model.pt', 'centroids.pt') for i, chunk in enumerate(df_chunks)\n",
    "    #     ]\n",
    "    #     with Pool(processes=num_gpus) as pool:\n",
    "    #         results = pool.map(process_chunk, process_args)\n",
    "        \n",
    "    #     all_labels = []\n",
    "    #     all_predictions = []\n",
    "    #     for labels_chunk, predictions_chunk in results:\n",
    "    #         all_labels.extend(labels_chunk)\n",
    "    #         all_predictions.extend(predictions_chunk)\n",
    "        \n",
    "    #     print(\"\\n\" + \"=\"*40)\n",
    "    #     print(\"      Aggregated Final Results (Multi-GPU)\")\n",
    "    #     print(\"=\"*40)\n",
    "    #     report = classification_report(all_labels, all_predictions, target_names=['Human', 'AI'])\n",
    "    #     print(report)\n",
    "    # else:\n",
    "    #     print(\"Only one GPU found, skipping multi-GPU evaluation.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading AI-generated samples from 'Yelp_gpt-4-turbo-preview.json'...\n",
      "\n",
      "Evaluating 2000 AI-generated samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "AI Detection Rate: 84.45%\n",
      "(1689 out of 2000 samples were correctly classified as AI)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Load the AI-generated texts from an external JSON file ---\n",
    "file_path = 'Yelp_gpt-4-turbo-preview.json'\n",
    "print(f\"Reading AI-generated samples from '{file_path}'...\")\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        ai_texts_to_evaluate = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please create it and add your JSON data.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: The file '{file_path}' does not contain valid JSON.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Use your detector to get the detailed results ---\n",
    "print(f\"\\nEvaluating {len(ai_texts_to_evaluate)} AI-generated samples...\")\n",
    "# Assuming your `detector` object is initialized and available\n",
    "# The `results` variable will be a list of dictionaries\n",
    "results = detector.batch_detect(ai_texts_to_evaluate, batch_size=8)\n",
    "\n",
    "\n",
    "# --- 3. THE FIX: Convert the list of dictionaries into a list of binary predictions ---\n",
    "# This line processes the detailed results into the format needed for numpy.\n",
    "binary_predictions = [1 if r['prediction'] == 'gpt4' else 0 for r in results]\n",
    "\n",
    "\n",
    "# --- 4. Calculate and print the AI Detection Rate using the corrected list ---\n",
    "# Since all ground truth labels are 1 (AI), the detection rate is simply the mean of the binary predictions.\n",
    "ai_detection_rate = np.mean(binary_predictions) * 100\n",
    "num_detected = np.sum(binary_predictions)\n",
    "num_total = len(binary_predictions)\n",
    "\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(f\"AI Detection Rate: {ai_detection_rate:.2f}%\")\n",
    "print(f\"({num_detected} out of {num_total} samples were correctly classified as AI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_few_shot_on_json_collection() missing 1 required positional argument: 'human_texts_for_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 149\u001b[39m\n\u001b[32m    146\u001b[39m model = detector.model\n\u001b[32m    147\u001b[39m tokenizer = detector.tokenizer\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[43mtest_few_shot_on_json_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mJSON_DATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_support_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can vary this number\u001b[39;49;00m\n\u001b[32m    154\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: test_few_shot_on_json_collection() missing 1 required positional argument: 'human_texts_for_eval'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ==============================================================================\n",
    "#  Prerequisites: Same as before\n",
    "# ==============================================================================\n",
    "# You must have the following available in your environment:\n",
    "# - A trained `model` object (StyleContrastiveEncoder)\n",
    "# - The corresponding `tokenizer`\n",
    "# - The `get_embeddings` function\n",
    "# - The `FamilyStyleClassifier` class definition (its name is generic enough to work here)\n",
    "# - The `val_texts` and `val_labels` from your original RAID data split\n",
    "#\n",
    "# ... (FamilyStyleClassifier class definition here) ...\n",
    "#\n",
    "\n",
    "class FamilyStyleClassifier:\n",
    "    \"\"\"A classifier specialized for distinguishing Human vs. a specific AI model family.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, ai_family_reference_texts):\n",
    "        self.model = model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        print(\"Calculating combined AI Family style centroid...\")\n",
    "        ai_family_embeddings = get_embeddings(ai_family_reference_texts, self.model, self.tokenizer)\n",
    "        self.ai_family_centroid = np.mean(ai_family_embeddings, axis=0, keepdims=True)\n",
    "        \n",
    "        print(\"Specialized classifier is ready.\")\n",
    "\n",
    "    def predict(self, texts_to_classify):\n",
    "        \"\"\"Predicts whether texts are Human (0) or from the AI Family (1).\"\"\"\n",
    "        embeddings = get_embeddings(texts_to_classify, self.model, self.tokenizer)\n",
    "        \n",
    "        sim_to_ai_family = cosine_similarity(embeddings, self.ai_family_centroid)\n",
    "        \n",
    "        # Predict 1 (AI Family) if closer to the AI Family centroid\n",
    "        return (sim_to_ai_family > sim_to_human).astype(int).flatten()\n",
    "\n",
    "def test_few_shot_on_json_collection(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    json_file_path,        # Path to the JSON file with a list of AI texts\n",
    "      # A list of human texts for comparison\n",
    "    num_support_samples=25\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs a few-shot evaluation on a generic collection of AI texts from a JSON file.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Starting FEW-SHOT Accuracy Test on AI Collection from: '{json_file_path}'\")\n",
    "    print(f\"Using {num_support_samples} samples to define each style centroid.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # --- 1. Load All AI Texts from JSON File ---\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            # Assuming the JSON file contains a flat list of strings\n",
    "            ai_collection_texts = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{json_file_path}' was not found. Exiting.\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file '{json_file_path}' contains invalid JSON. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Validate the loaded data format\n",
    "    if not isinstance(ai_collection_texts, list) or not all(isinstance(i, str) for i in ai_collection_texts):\n",
    "         print(\"Error: JSON file must contain a flat list of strings. Exiting.\")\n",
    "         return\n",
    "\n",
    "    if not ai_collection_texts:\n",
    "        print(\"Error: No texts found in the JSON file. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Check if there's enough data for a meaningful split\n",
    "\n",
    "    # --- 2. Create Few-Shot Support and Query Sets ---\n",
    "    print(f\"\\nCreating support set (for centroids) and query set (for testing)...\")\n",
    "\n",
    "    # Shuffle the lists to ensure random sampling\n",
    "    random.shuffle(ai_collection_texts)\n",
    "    # Create the small support sets for building the centroids\n",
    "    ai_support_texts = ai_collection_texts[:num_support_samples]\n",
    "    # The rest of the data becomes the unseen query set for testing\n",
    "    ai_query_texts = ai_collection_texts[num_support_samples:]\n",
    "    print(f\"Support set size: {len(ai_support_texts)} AI, \")\n",
    "    print(f\"Query set size (test set): {len(ai_query_texts)} AI\")\n",
    "\n",
    "    # --- 3. Create the Classifier using ONLY the small Support Set ---\n",
    "    # The 'FamilyStyleClassifier' is general enough to work here.\n",
    "    # The 'ai_family_reference_texts' is now our collection from the JSON.\n",
    "    collection_classifier = FamilyStyleClassifier(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        ai_family_reference_texts=ai_support_texts\n",
    "    )\n",
    "\n",
    "    # --- 4. Run Evaluation on the UNSEEN Query Set ---\n",
    "    test_texts = ai_query_texts + human_query_texts\n",
    "    ground_truth = [1] * len(ai_query_texts) + [0] * len(human_query_texts)\n",
    "\n",
    "    print(\"\\nPredicting labels for the unseen query set...\")\n",
    "    predictions = collection_classifier.predict(test_texts)\n",
    "\n",
    "    # --- 5. Report True Few-Shot Generalization Results ---\n",
    "    print(f\"\\n--- Classification Report (trained on {num_support_samples} shots) ---\")\n",
    "    report = classification_report(\n",
    "        ground_truth,\n",
    "        predictions,\n",
    "        target_names=['Human', 'AI Collection (from JSON)']\n",
    "    )\n",
    "    print(report)\n",
    "\n",
    "    overall_accuracy = accuracy_score(ground_truth, predictions)\n",
    "    print(f\"Overall Few-Shot Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#                                EXECUTION\n",
    "# ==============================================================================\n",
    "# Define the path to your JSON dataset\n",
    "JSON_DATASET_PATH = 'Yelp_gpt-4-turbo-preview.json'  # <-- Replace with your JSON file path\n",
    "\n",
    "# Prepare the list of human texts from your original validation set\n",
    "# Run the few-shot test on the JSON collection\n",
    "model = detector.model\n",
    "tokenizer = detector.tokenizer\n",
    "\n",
    "test_few_shot_on_json_collection(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    JSON_DATASET_PATH,\n",
    "    num_support_samples=25  # You can vary this number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting Style Analysis on AI Collection from: 'Yelp_gpt-4-turbo-preview.json'\n",
      "==================================================\n",
      "Loading Human and GPT-4 style centroids...\n",
      "Style Analyzer is ready.\n",
      "\n",
      "Analyzing 2000 texts from the collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   2%|▏         | 1/63 [00:00<00:23,  2.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 63/63 [00:18<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Style Profile for the Collection ---\n",
      "Average Similarity to 'Human' Style:      0.0585\n",
      "Average Similarity to 'GPT-4' Style:      0.7643\n",
      "\n",
      "Conclusion: On average, this collection's style is closer to the 'GPT-4' style print.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+0AAAIkCAYAAABr18rbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAwyZJREFUeJzs3XdYFOfaBvCbriKIioAFsQv2rthQscYSjEc9USMYNbG3JBoTu0aNGjWKMbFhiQUVW2wYFKxYEDvYERWlCyy9vd8f8+0eVhbcRXBXuX/XNRfLzOzMM7uzu/PM2/QACBARERERERGRztHXdgBEREREREREpBqTdiIiIiIiIiIdxaSdiIiIiIiISEcxaSciIiIiIiLSUUzaiYiIiIiIiHQUk3YiIiIiIiIiHcWknYiIiIiIiEhHMWknIiIiIiIi0lFM2omIiIiIiIh0FJP2YsTJyQlCCMydO1cr+w8JCUFISIjSvLlz50IIAScnJ63EZGdnByEEPDw8tLL/wmBoaIi5c+fi4cOHSE1NhRACn3/+ubbDypOrqyuEEHB1ddV2KAA+zOdC1bn/oV4HVfsm3dCtWzdcuHABsbGxEELg4MGD2g6pSPj6+kIIoTRP279Hb9O17yUAsLa2xtatW/H8+XNkZmZCCIEyZcpoOyydoWvnEBWch4cHhBCws7PTdigfBSEEfH19tR1GLroa16eCSftHRp5k5pySkpIQFhYGHx8fzJ8/HzVq1CiSfau68PoYfOpJy3fffYd58+bh1atXWLFiBebNm4f79++/83lDhw7F6dOnER0djbS0NISHhyMwMBDr1q1Dx44dldb92H5Q27Zti7179+Lly5dIS0tDbGwsgoODsXPnTgwfPlzb4Wndh7pZZmBggPHjx+PSpUuIi4tDWloaXr16hcuXL2PlypVo0qRJke5fl9nZ2eHw4cOoUaMGPDw8MG/ePOzZs0dr8fTv3x9eXl548eIFUlNTkZCQgJs3b2LlypVwcHDQWlyF5WO8Qbt161Z89dVXOHfuHBYtWoR58+YhNTVV22FppGrVqoiLi0N4eDgsLS1VrmNiYoJ79+4hPT0dzZs3/8AR6pbCvF4ZNGiQ4jpx8ODBGj33Y/vNJyoODLUdABXM48eP8ffffwOQfvCsrKzQqlUrzJkzBz/99BOWLVuGn3/+Wek5V69ehb29PaKjo7URMpydnbWy3/yEhYXB3t4e8fHx2g6lwPr06QOZTIZu3bohIyNDreds2bIFI0aMQGxsLI4ePYqwsDCULFkSjRs3xsiRI2Fubo5z584VceRFw9XVFVu2bEFmZiaOHz+OR48eQQiBunXr4rPPPkPHjh2xfft2xfof4nOhzXNfW/vW19fHiRMn0K1bN4SFhWHfvn2IiIiAhYUFmjVrhkmTJiEpKQk3b97USnza1rVrV5QsWRIjR47E7t27tRZH2bJlsW/fPjg7O+PNmzf4999/8fTpUxgbG6N+/foYN24cJk2aBGdnZ5w9e1ZrcRa1gwcP4vLly3j9+rW2QwEAGBkZoVu3bvDx8cGwYcO0HU6BPX/+HFOmTIGHhwf+/PNP/Oc//8m1zqJFi1CvXj3MmzcP169f10KUnx5ra2usW7cOiYmJKF26tLbDoUJmb2+P5ORkbYeRi67G9alg0v6Revz4MebPn59rfrt27bBjxw789NNPyMrKwpw5cxTLUlJS8ODBgw8ZppKnT59qbd95yczM1OprUhgqVaqEmJgYtRP29u3bY8SIEbhx4wacnJwgk8mUlpcpUwb16tUrilCLXMmSJbFmzRrIZDK0bdsWQUFBSssNDQ3RqVMnpXkf4nOhzXNfW/seMmQIunXrhhMnTqBfv37IzMxUWm5tbY1KlSppJTZdID/2V69eaS0GAwMDHDx4EE5OTtixYwfGjx+f6/vAxsYGv/zyyydfLTshIQEJCQnaDkPBxsYGBgYGWj0/CsvWrVvh4uKCAQMGYOjQodi5c6diWdu2bTF16lRcu3YNixYt0mKUn5YNGzZAJpNh69at+P7777UdDhUyXb1u1dW4PiWC08cz2dnZCSGEOHHiRJ7r1KlTR6SkpIjU1FRRpUoVxXwnJychhBBz585VWr9WrVpiy5Yt4unTpyI1NVXExMSImzdvilWrVinWyYuHh4dSXB4eHsLe3l4cOHBAREdHCyGEsLOzEwBESEiICAkJUdr33LlzhRBCODk5ia+//lrcvn1bpKSkiJcvX4qVK1eK0qVLK62f1zG8HUPO/1WRP//t5+ScqlatKjZt2iRevnwp0tLSxIsXL8SmTZuEra1trnV9fX2FEEIYGhqKuXPnipCQEJGamioePHggxo4dq/H77ObmJi5fvixkMpmQyWTi8uXLwtXVVeVr97a3X+O3px9++EEIIcTkyZPViiUkJETlfnx9fYW5ublITEwUd+/eVflcPT09ERISImJjY0WJEiUEAOHq6iqEELmOB4CoVq2a2LhxowgNDRWpqani1atXwsPDQ1StWlWtWFu2bCmEEOLgwYNqv9Z5nVPy89Xc3Fz88ccf4tWrVyIxMVGcPXtWNG3aVAAQFStWFDt27BAREREiOTlZeHt7i1q1aql8Dd9+X/J6HVxcXMSuXbvEo0ePRFJSkoiLixPnzp0TX3zxRb7nvLqfO/m5quq80dPTE8+ePRPR0dHC2NhY5et19uxZkZGRISpXrpzv67pu3TohhBCff/65Rud+6dKlxZw5c8StW7cUxx8YGCgWLFggDA0NldZt27atOHr0qIiJiREpKSkiODhYzJs3T5QsWTLXduXnbKVKlcS2bdvE69evRVZWlnByclKs06FDB3HkyBERFRUlUlNTxcOHD8XChQtVbu+LL74Qfn5+IiIiQqSkpIiwsDDx77//qnyfVL1nquSMpX79+sLT01NERESI1NRU8fTpU7Fq1SpRrly5PM+vMmXKiLVr14rnz5+LjIwMlZ+xt79nhBDCz89P6Onp5bvu2+eDJvHJzzl1PncARIUKFcTKlSvFo0ePRGpqqoiKihL79+8X9evXVxlbhQoVxIoVK8T9+/dFcnKyiImJEZcvXxbfffed0mctv9c8v++lgpxnVlZWYuvWrSIqKkokJycLf39/pfc3vymvz6j8dyrn76arq6u4fv26SEpKEr6+voptFOT3y9jYWPzyyy8iNDRUJCcni4CAAOHs7CwACHNzc+Hu7i7CwsJESkqKuHTpkmjZsqXan+sKFSqIiIgIERsbKypVqiQAiJIlS4qHDx+K5ORkYW9vr1i3X79+wsfHR8TGxoqUlBRx584d8d133wl9fX21zqGcn4c///xTvH79WqSkpIjAwEDx3//+V6PvI1Wf3z179oiYmBghk8mEn5+f6NChg9J7oiq+du3aCV9fX5GQkCDevHkj9u/fL2rWrKnW94Kqz0h+k/xc7tKliyKuwYMHq/38/H7zc8aq6rop52dA1TlmYmIiFi5cKB4/fizS09MVx+bh4SGEEKJ69erihx9+EA8fPhQpKSni6dOnYvbs2bm++3N+h73rWkmTz5yJiYlYsmSJCA0NFSkpKSIoKEhMmDAhz9fY1dVV9OnTR1y4cEEkJCQo/dYaGRmJqVOniuvXr4vExESRkJAgzp07J/r27au0rU2bNgkhhOjQoYPK2KZOnSqEEGLUqFH5vsaa7HPSpElCCCEGDBigNH/VqlVCCCHOnz+f67wXQogtW7bk+zqqisvc3FzMnz9f3Lt3T8hkMhEfHy8ePXoktm7dmuvarlSpUmLevHkiODhYpKSkiJiYGHH06FHRtm3bXPvK+Zn78ssvxY0bN0RycrJ49eqVWL16teKa81OaWNL+CXr48CH27t2L4cOHw8XFBe7u7nmuW7FiRVy9ehWmpqY4duwYPD09YWpqitq1a2PcuHH4/vvvkZWVhXnz5sHNzQ3VqlXDvHnzFM9/u2prrVq1cPnyZdy5cwdbt25F+fLlkZ6e/s6Yp02bBmdnZ3h6euLYsWPo2rUrpk6dijZt2qBjx465SunUERcXh3nz5mHKlCkAgNWrVyuW+fn55fvc2rVr48KFC7CyssKRI0dw7949NGjQACNHjkTfvn3Rvn17PHr0KNfzdu/ejVatWuHEiRPIysrCoEGD8McffyAjIwObNm1SK+7ff/8dkyZNwsuXL7F582YAwIABA7B161Y0bdpUcTx+fn4qjy8uLi7f7cfExAAA6tSpo1Y8q1evhpubG5o0aYLVq1crtv/s2TMkJCRgz549GDlyJBwdHeHv76/03G7duqFatWpwd3d/Z1vMVq1awdvbG6ampjh69CgePXqEatWqYejQoejVqxccHR3f2dZPfmw1atSAvr4+srOz1TrGvBgbG+Pff/9FiRIl4OnpCWtrawwaNAg+Pj5o27YtvL298fr1a/z999+oVasW+vXrh2PHjsHBwaHA+16yZAnS09Nx4cIFvH79GhUqVEC/fv3g5eWFiRMnqvw8a/K527p1KwCgU6dO2Lp1K549ewZAOm+EENi0aRMWLlyIAQMG5Kq2XadOHXTs2FHRpCI/mp5nAFChQgWcPXsWDg4OuHHjBtavXw99fX3Y29tjxowZ+O233xRNWf7zn/9g9+7dSEtLg6enJyIjI9G9e3fMnTsXPXr0QKdOnZCWlqa0/fLly8Pf3x+xsbHYs2cPSpQooShdHTNmDNatW4e4uDj8888/iIyMRIsWLTBr1ix07twZnTt3VtRmGTNmDNavX49Xr17h4MGDiImJgY2NDVq1aoX+/fvjwIEDeR6j/HupU6dOud4D+d927drB29sbxsbG2L9/P549ewZHR0dMmTIFffr0QZs2bRSvr5yJiQnOnDmD0qVL48iRI8jMzERERES+r/fIkSMBSNWTxTv6K8l5PhUkPnXVqFEDfn5+sLW1hbe3Nw4dOgQrKysMGDAAPXr0gLOzM65evapYv06dOvD19UWlSpVw/vx5HDp0CKampqhfvz5++ukn/Pbbb7h58yZWr16NKVOm4ObNmzh06JDi+fLXPC8FOc8sLCxw4cIFxMfHY8eOHbCyssLgwYPh7e2N5s2b4969e/nuc+vWrbh582aueN/+vf3hhx/QuXNnHD58GKdOnUJWVhaAgv9+eXp6omHDhjhy5AhKliyJoUOH4ujRo2jXrh02bNgAY2Nj7Nu3DxUqVMDgwYNx8uRJVK9eXa0aClFRUfj2229x8OBBbN68Gb169cKyZctQu3ZtTJkyRdEPy+LFizFz5ky8fPkSBw4cQHx8PDp06IAVK1agdevWGDRo0Dv3BUjf3T4+PihdujR27NgBU1NTDBo0CLt374alpWW+10V5qVSpEi5duoRKlSrhxIkTuHHjBurWrYt///0XZ86cyfN5bdq0wcyZM3Hy5EmsXbsW9evXR//+/dGhQwe0adMGISEh73W9klOVKlWwevVq/PXXXzhz5gw6dOig8XHm95v/vry8vNC4cWOcPHkScXFxuX7TV69ejXbt2mHv3r1ITExE3759sWDBAjRq1AgDBw5UWlfdayVN7N27F02bNoWXl5die2vXrkW1atVU1lgYOHAgunfvjqNHj+KPP/6Aubk5AOn8O3nyJDp37owbN25g8+bNMDIyQu/evXHkyBFMmDAB69atAwDs2LEDI0eOxLBhw3D+/Plc+/jqq6+QmpqKffv25Ru7JvuUdxbXuXNnxbHK/wek67FSpUopqrrL5xekkzlvb2+0adMGFy5cwMmTJ5GdnQ07Ozv069cPO3bswPPnzwH87zesdevWuH79OlavXg1ra2sMHjwYPXr0wJdffon9+/fn2v6ECRPQs2dPHD58GGfOnEHPnj0xefJkWFpaftRNi/Ki9TsHnNSf1ClpByBGjBghhBBi27Ztinmq7kpPmDBBCCHEpEmTcm2jbNmySv+rKi15Oy4hhJg3b57KdfIraU9NTRUNGzZUWvb3338LIYSYNm1avsfwdgxv3/1Vtd93Pef06dNCCCFGjx6tNH/s2LFCCCF8fHxUvjb+/v7CzMxMMb9OnToiPT1dBAcHq/X+dujQQQghxL1794S5ublivoWFhbh//74QQoj27durfXyqpsqVK4u4uDiRlZUl/v77bzFgwIB3lmTL74LLS29zTvLSbVV3YPfu3SuEEKJRo0aKeapKtAwNDcXTp09FfHy8aNKkidI22rVrJzIyMsSRI0fUOr5r164JIYQ4d+6cGDlypKhfv36uEpqcU36lNUII4enpKQwMDBTz5TUVYmNjxW+//ab0HHnpcv/+/d/5HuVVsle9evVcMZqamopbt26JN2/eKJXuve/nTlXJX8WKFUV6ero4c+ZMrmXLli0TQgjRr1+/d74PTZs2Fenp6SI1NVWsX79e9OnTR9jY2OT7nH379gkhhFi0aFGuZVZWVor3wczMTLx580akpKQofW/o6emJ3bt3CyGEmDVrltLz5TZv3pzrfHBwcBDp6enixo0buUqKZ8yYket7KCAgQKSmpooKFSrkilNVSbOqKa/3QE9PTzx69EgIIUT37t2Vlv36669CCCE2bdqk8lw9ceKE2qULBgYGIi0tTaSnpwsTExO1nlPQ+DQpab9w4YLIyMjIte3atWuL+Ph4cevWLaX5V69eFUIol0LJp5y1Qd5VOqjq8/g+55m7u7tS7YWvv/5aCCHE+vXr1Xqd84tXfu7IZDLRoEGDXMsL+vt17tw5UapUKcX8gQMHKr7r8voenDp1qtrnDgCxbds2IYT0e5GVlaX0PdO1a1fFeZwzDgDijz/+EEIIpZos7/ru9vPzE0ZGRkrnQ2RkpEhJSVGU9msybd++XQghxMyZM5Xmy6+33v48y+MTQohvvvlG6TnffPONEELk+l3T9Pf87cnb21uEhoYqaikWpKQdyP83/31K2gMDA3NdW+bcX0REhNLn1sjISPj5+eV67wtyrZTfJI8vODhYaXvm5uYiODhYZGVliebNmyvmy78vMjMzFbVRck6LFi0SQggxf/58pfmlS5cWV69eFampqaJixYqK+c+ePRMxMTEqazQJIcTevXvf+Rprus+oqChx7949xf/lypUTWVlZ4t9//xVCCNGtW7dcn9uctXfVee8bNGgghBDiwIEDudY1NjYWpqamiv9nz54thBBix44dSus1adJEpKamitjYWKXat/Jz+82bN6JOnTqK+SVKlBD3798XmZmZSsf7iUxaD4CTBpO6SXuPHj2EEEIcO3ZMMS+/pP3tH3dVkzpJ+6tXr5R+JHNO+SUPGzZsyLV+1apVRUZGhrh9+3a+x/B2DO+btNva2gohhMoq33p6eiIoKCjXl5f8tenUqVOer9vbVf1VTfJqUgMHDsy17MsvvxRCqL5g1/RH3tnZWTx79kzkFBERIfbs2SM6d+6ca/38fsABiOvXrwuZTKZ0w8LS0lKkpqaKK1euKK2r6uLYxcVFCJH7Alg+7d+/X2RmZiptP7/PyPnz55WOLTExUfz777/C1dVVoyqWQohc1UmrVKkihBAiISEhV/XY9u3bCyFyJ9CaJO15TfIqch07diy0z11e1XW9vLxEVlaWUvVNQ0NDER4eLsLCwpQu3vObvvzySxEZGan0Xjx//lxs2bJFNGvWTGlda2trkZWVJR49epRnVUj5NGzYMCGEEOvWrcu1zNbWVqSnp4vHjx8rzRdCujlYvnz5XM9ZvXq1EEL1RZ6enp6IiIgQ165dU8wLCAgQMplMWFhYaPS5U+c9kJ9DOb+75ZOpqamIjo4WycnJSu+3/Fx9+8ZnfpOVlZXi3NEk7oLEp27S3qRJE5XfcfJpxYoVQgihqCYvv2Ho5+f3zrgLkrQX9DyTyWRKF6OAdJMkPT1dBAQEqPU6q5O0v33TUB6XEAX7/Xq7eq6enp5IS0vL93tw69atGp0/5ubmIjQ0VAghRFxcnNIN40OHDqncl/x5WVlZYt++ffmeQzk/D6qq1P78889CCOWbcOpMxsbGIiUlRYSHh6tsOhQcHJzr8yyP7/79+7man+jp6YkHDx6IrKwsYWlpqRR7QZP2MWPGCCGUb6bpWtL+djXtt/f3008/5VrWrl07IYTyDY6CXCvlN8njGzJkSK5lQ4cOFUIIsWbNGsU8+feFl5dXrvX19PRETEyMePTokcp99enTRwghxPjx4xXzfvnlFyFE7hv+S5cuFULkvlH+9mtckH3Kb5JbW1sLQGryJT+HU1JSxJIlSxTrPn/+PNd3nTrvvTxp37lz5zuf+/jxY5GWlqay6d1ff/0lhBBi2LBhuc5tVQUW8mV9+vQp0GdJVydWjy/m/vnnHyxZsgTr1q2Ds7MzTp48ibNnzxZ4yJFbt26p3SFaTqqqBD1//hwvXrxA/fr1YWRkVKDtFoR8GCpVPSULIXDu3Dk4ODigSZMmePnypdJyVT3fytexsLBAYmJivvtu2rQpANXV4eTVkgpjmKzTp0+jZs2a6NSpEzp27IjmzZujffv2GDx4MAYPHozFixfnGn0gP3/99Rf++usvDBkyBH/99RcAYPjw4TAxMcHGjRvf+fw2bdoAAOrWratyzF15p0x16tR5Z+/CoaGh6NChAxo3boyuXbuiRYsWaNeuHbp27YquXbti+PDh6NWrl1rNNmJjY/HixQulefLepR89eoSUlBSVy96ng7UKFSrgxx9/RK9evWBnZ4dSpUopLVe17YJ+7vLy119/4YsvvsCoUaMwc+ZMAEC/fv1gbW2NX375RVEN9112796NAwcOoFu3bmjfvj2aN2+Otm3bYsSIERg+fDjGjx+vOF9atGgBfX19+Pr6vrM5TH6fkxcvXuDp06eoW7cuSpcurfSZCwkJUVltW37+yatfvy0jIwP29vaK//fs2YPly5fj7t272LVrF3x9fXHhwoVcnbgVRH7HlpSUhICAAPTo0QN169bF3bt3FctSUlJw586d995/UcWnDvn7YG1trfJ7QP4e2Nvb4969e2jVqhUA4NSpUxrtR10FPc8ePnyIpKQkpfWzsrIUoycUlpzNBOTe5/fr7er3QghERkaiVKlSeX4Pavpdl5CQgCVLlmD9+vX4888/FVVjAen9T0xMxNdff63yuSkpKUqfw/xkZGTkaq4F/O9aQ/7eqqtu3booUaIETp8+rfK349KlS3nGdvHixVzNT4QQuHjxIurUqYPGjRvj9OnT74xB1Wdi9erViI+PR/Xq1bF8+XJs3rxZrc+Dk5NTrk5Zb968icOHD7/zue9D1Tmbk6prQX9/f2RkZCi9Z5peK33++ee5rp38/PxyfU5U7T+/c0bV8dStWxflypXDq1evVL5nFSpUAACl80XegfRXX32FgwcPAgD09PQwZMgQREdH4/jx47m287779PX1xX/+8x907twZe/bsQefOnZGQkIALFy7g8uXLiirxNWvWhK2trdpNPHMKDg7GrVu3MGTIEFSpUgWHDh2Cn58fbt68qfSZMDMzQ82aNREUFKSy6Z2vry+++eYbNGnSRDFylty7rrs/JUzaP1HyH9KoqKh81wsNDUWbNm0wb948fPbZZ4qxPIODgzFnzhyV7Ufy8642lJo+LyIiAtWrV4eZmRliY2MLtG1Nydsk5RWT/GJFvl5Oqi7a5QmIgYGBWvvOyspS+b5FREQgOztb5X4LIisrC6dPn1ZcLBgYGMDNzQ3r16/HTz/9hP379+PGjRtqbWvXrl1YsWIFRo0apUjCRo4cCZlMptZwVuXKlQOAd7Y/MjU1VSseQEpkb926pfjfyckJf//9N7p06YJx48YptRnMi6q2mvKEVdUy+XttZGSkdpw5lS1bFteuXYOdnR0uXLgAHx8fxMXFISsrC02aNIGLiwtMTExyPa+gn7u8nDp1Ck+fPoWrqytmzZqFrKwsjBo1CtnZ2Yq2g+pKS0vD0aNHcfToUQBSu7Xvv/8eixYtwu+//45Dhw4hIiJC0Tv5u9rKA+p9RuvWrQtzc3OlZCqv9eXn36xZs9Q6phUrViAmJgZjx47Fd999hx9++AEZGRk4duwYpk6d+l5tPwv6/RMZGanRfmJiYpCeno7y5cvD2NhYrZtY7xOfOuTvQ58+fdCnT58815N/D2hyzhREQc+zvNp4Z2ZmqvU7oC5VcRXF71d+34MF+a6T3+x8+6ZnuXLlYGRkpNRvztvU/Q2Ijo5W2U+D/HXRdDQE+euV1+csv+/g/K5vNIlF1euydetWxMfHY/PmzYiLi8O0adPU2lanTp1ybW/r1q1FnrS/67dK1fLs7GzExMQovU6aXiu5uLjAzc1Nab158+blStpV7T+/90nV+vLvsQYNGqBBgwa5lsvlPJfv37+PgIAAfPbZZ7CwsEBcXBw6deoEW1tbrFu37p03sguyz5zt2uVJ+7lz55CVlQVfX1/Mnj0bZmZm79WePSsrC126dMG8efMwYMAArFy5EoD0OXJ3d8cvv/yi9F4V5Hsrv2uxwvy+1QX62g6Aiob8Duq1a9feue69e/cwcOBAlCtXDm3atMH8+fNhY2MDT09PtG3bVqP9qvqRVIe1tXWe87OzsxUXE/LOvQwNc99vKqwhieRfAHnFZGNjo7ReYUpISICBgYHirmhOVlZW0NfXL7JhibKysrB582bs2rULwP86HlFHYmIidu7ciRYtWqBx48Zo27Yt6tWrhz179uQqcVJFfkx9+vSBnp5entP7jB1/9uxZzJ49GwDQpUuXAm+nKI0cORJ2dnaYNWsWOnTogEmTJmHOnDmYP38+Ll++nOfzCvq5y8+GDRtQsWJF9O3bF1WqVEH37t1x+vTpAtfCkUtLS8Mvv/yCs2fPwsTEBO3atQPwvw4UK1eu/M5tFPQzmtfrJF/PzMws3/MvJw8PD7Rq1QoVKlSAi4sLDhw4ABcXFxw9ehT6+gX/aS3sY8tLVlYWrl69CmNjY3Ts2LHI49Nk2xMmTMj3fdi+fTsAzc6ZgtDmb4E6VL3nuh5zfhISEhAdHZ3ve1+jRg21tmVpaZnrMwv873WRd2ipSWyA9DusSl6vd37LNI1F1esRGhoKQCoFrlKlCuLj4yGEUEzyxHzPnj0QQmDy5MkAgPnz5+fa1ogRI9SKI7/rsPctVFD1Wunr66N8+fJKr5Om10ojRozIdbyqhk1Wtf/83qf8PoP79+/P91x+u0bJjh07YGJiouhs8auvvlLMf5eC7DM4OBjh4eHo3LkzKlSogPr16ysSc19fXxgaGqJDhw6KfKIgSTsg1VicNGkSKleuDAcHB4wfPx6xsbFYsGABpk+frhT/x/i99SExaf8E1a5dG4MGDUJqaqqimo06MjMzceXKFcybNw+TJk2Cvr6+UmmH/M76+1yQ5kVVD6dVq1aFra0t7t27p6j6++bNGwCqL9Lyqu6WlZWl0d02eRXBvC5k5fPfrkpYGOQl229XW8s5ryj2m5OqKvzy9z6/11Fewj569GiMGjUKANSqGg8AV65cAQA4OjpqFKum3tU8Qdtq1qwJACpLOwrSC3Be1Hk/PTw8kJ6ejlGjRuHrr7+GgYGB2u+nOt5+LwICApCVlYXOnTurvBjMKb/PSZUqVVCzZk08efJE7fdbfv7Jq2drIjY2FocPH8Z///tfnD59GvXr10etWrU03o5cfsdWqlQptGjRAsnJyYUyHq681sRPP/30znWNjY2LPD5NvwfkVVO7d+/+znXVOeffVtjn2Yegzd+v93XlyhVYWlq+1+dHzsjISOV5JP8eVbcWmdyDBw+QmpqK5s2bKz4LOeV3zrZr1y7XDQQ9PT20bdsW2dnZSjXCNL1ekdu+fTs2bdqUawoMDAQAnDlzBps2bVK7yUp+n5f8bpZp2uzgbap+5xwdHWFkZKT0nhXVtZKq/Wt6zgQHByM+Ph4tWrR4529ZTrt370ZGRgaGDRuGEiVK4IsvvsCjR48U34tFsU8/Pz/Url1bcYNAPgrC5cuXkZycjC5duqBz5854+PChorT7fdy/fx9//PEHunXrBkBqdgdItXyePHmCWrVqqWxy86Guf3Udk/ZPjHwYqhIlSmDp0qV49epVvus3a9YMZmZmuebL73blHKZLXj3d1ta2ECOWDB8+HA0bNlSat3jxYhgaGiqGqAKkH86EhAT069cPZcuWVcy3srLKs2prbGwsLC0tVVYrVuXFixc4c+YMGjRokOtO6DfffIN69erh9OnTudoDFoZt27YBkNqu5XxfzM3NFe2U5OsUVI8ePdCvXz+VP8Y1a9ZUDKty4cIFxXx13vubN2/i6tWrGDp0KAYOHIhbt26pVdMDkJLU0NBQTJs2TeWPpqGhoaJENj/VqlXD+PHjUbp06VzLSpYsqShlyHlsukReatK+fXul+V9++SV69+5daPtR5/2MjIzEoUOH0LNnT4wdOxZRUVFKQ2W9y+DBg/OsrdG6dWvFEGryGgSRkZHw8vJCrVq18myTJz9nDx8+jLi4OIwYMQL16tVTWu/XX3+FkZGR0vfGu8iHZVy7dq3K16RMmTJK7SGdnJxyrWNoaKiooviu4Q3zc/HiRTx+/BifffZZrvb1s2bNgqWlpeLi7n3t2LED586dQ+fOneHh4aHyc2NlZYUNGzagZ8+eRR7ftWvXcPnyZXz55Zcqh/bS09NTSkYDAgJw9epVODk5KW4U5pTz4u/NmzfIzs7W6PersM+zD0Gbv1/va82aNQCALVu2KD5LOVlbW6vdph2QriFyVt+vXLkyJk+ejNTUVOzZs0ej2NLT07F//37Y2NjkGkps+PDhcHBwyPO5devWxejRo5XmjR49GnXr1sWxY8cQHR2tmK/p9Yrc5MmTMXr06FzTkSNHAEg1p0aPHq1W23l5HIDq3wiZTIb79++jffv2ihvNAFC6dGksWbJEo7hVHUfOmwFGRkb45ZdfAEDps1ZU10qzZ89Wqi1gbm6OWbNmITs7W+3tZWVlYf369ahWrRpWrFihMomuX79+rloCUVFROHXqFNq1a4cpU6agTJkyudpvF/Y+5aXnM2bMQExMjOIGUkZGBi5evIivvvoKlSpVylXKXrduXdStW/edcdnZ2cHOzi7XfFU5xrZt22BsbJzrHGrYsCHc3NwQFxen0TXIp4ht2j9SOS9sjY2NYWVlhVatWqFRo0bIzMzEwoULVVb9edtXX32Fb7/9FufOncOTJ0+QkJCAevXq4bPPPkNMTAw8PDwU6545cwYDBw6El5cXTpw4gdTUVNy6dUvRVvV9eHt7w9/fH3v27EFUVBScnZ3RsmVL+Pv7Y+3atYr15BfWP//8MwIDA3H48GGYmZmhb9++OHv2rMo79GfOnEHLli1x4sQJnD9/Hunp6Th37pzKDkfkxo4diwsXLmDjxo3o27cvgoKCUL9+fXz++eeIjIzE2LFj3/uYVTl//jzWrFmDSZMm4e7du/Dy8oKenh4GDBgAW1tb/P777/nGrQ57e3usXr0aUVFRivddT08PtWrVwmeffQYTExP88ccfSh2snDlzBj/88AM2bNgALy8vJCUlITQ0NNcPyp9//oktW7YAUL+UHZAuiP7zn//gxIkTOHfuHE6fPo07d+5ACAE7Ozt06NABMTEx+V4YAVJy5e7ujuXLl+PChQu4e/cuUlJSULlyZfTu3RuWlpYICAhQOqd0yY4dOzBjxgysXbsWnTt3RmhoKBo3bgxnZ2d4eXlhwIABhbIfX19fZGdnY/Hixahfvz7i4+MRFxenGMNV7s8//8SgQYNgY2ODFStWaJSItWnTBlOmTMHLly9x7tw5PH/+HMbGxnBwcED37t1hYGCAGTNmKN1YHDduHBo0aIBZs2bhs88+w5kzZ6Cnp4c6deqge/fusLa2Rnx8PGQyGUaPHo3du3fjypUr8PT0RFRUlKLjwStXrmD58uVqx3rv3j2MGzcO69evx4MHD3D8+HE8efIEZmZmqFGjBpycnLB161bF5/7QoUNISEjA5cuXERoaCiMjI3Tr1g3169fHvn37lDrX0pQQAm5ubvD29sbx48exb98+hIaGwtHREZ07d8bjx4/x448/Fnj7OWVlZcHFxQX79u2Dm5sb+vXrh1OnTiEkJATGxsaoV68eOnXqBCMjI8Vnvajj+/LLL+Hr6wtPT09MmTIFgYGBSElJQdWqVeHo6IgKFSqgZMmSivWHDh0KPz8/bNy4EV999RX8/f1RokQJ1K9fH02bNoWlpSUAqZO8a9euoWPHjti+fTsePXqE7OxspXGC31bY59mHoq3fr/fl7e2NBQsWYM6cOXj8+DFOnjyJ0NBQlC9fHrVq1UKHDh0wa9YsxZju+Xn16hVMTU1x+/Zt/PPPP4px2i0tLTFx4sR3FmioMnPmTHTt2hW//vornJycFOO09+nTBydOnECvXr0UVcdzOnnyJNasWYPPPvsM9+7dQ/369dG3b19ERUUpbiTLFeR6pSi86zf/t99+w8aNG+Hv7499+/ZBX18fvXr1UvtGfV4uX76MW7duwdPTE0lJSejbty/s7e3h5eWFAwcOKNYrqmulhw8fKrYHQLG933777Z2d4OY0d+5cNGvWDJMnT0bv3r1x7tw5REZGonLlymjYsCGaNGmCNm3a5GqTv2PHDvTu3Vtx/a5u0l7QfcqTcSsrKxw4cECpur+vr6+iRPztpF3+GVTVBCWnJk2a4MCBA7h69SqCgoIQHh6OypUrw8XFBVlZWVi1apVi3WXLlqF3796Km2CnT5+GlZUVBg8eDENDQ4wePVqnajVpi9a7sOek/pRzXGa5pKQkERYWJk6fPi3mz58vatSoofK5qoZHadWqlVi/fr24ffu2iI2NFUlJSeLBgwdizZo1uYZdMTAwEEuXLhXPnj0T6enpSkN+vGsIEODdQ0+NHDlS3LlzR6SkpIiwsDCxatUqlcOk6enpiTlz5ojQ0FCRmpoq7t+/LyZOnCiqVaumMgZTU1Px119/ibCwMJGRkaH0GuQXd9WqVcXmzZtFWFiYSE9PF2FhYWLz5s0qxzTPbzi8dw2Xpmpyc3MTV65cEYmJiSIxMVFcuXJFuLm5qf265jdZWlqKkSNHir1794rg4GARHx8v0tLSRFhYmDhy5IjSWKg5p++//148ePBAMQTQ20O6ABAlS5YUKSkpIikpSZQpU0bldvIb6qxSpUpi1apV4sGDByIlJUXExcWJe/fuiQ0bNqgciu7tydjYWPTv31/8+eef4saNGyIyMlJkZGSImJgYce7cOTFlypRcY1LnN2xQXq9rXsevybCDeb0OjRo1EidPnhQxMTEiPj5e+Pr6ii5duqhcv6CfOwBi+PDh4tatWyIlJUUIIfI8VvnQgHXr1lX7HAOkIaHGjx8vDh8+LB4+fChkMplITU0Vz549E56ennm+n2ZmZmL+/PkiKChIpKSkiDdv3ojAwEAxb968XEPBtW/fXhw7dkzExsYqvgvmz5+fa4zn/N6znFOLFi3Erl27xMuXL0VaWpqIjIwUAQEBYvHixUrHP2bMGHHo0CEREhIikpOTRVRUlLh8+bL49ttv3zlcnXx617B7DRo0EHv37hWRkZEiLS1NhISEiFWrVqkcsu59x3YGpOF+Dhw4IF6+fClSU1NFYmKiuH37tli9erWwt7d/r/g0GacdkMZaXrBggbh9+7ZISkoSCQkJ4sGDB+Lvv/8WLi4uuda3srISq1atEo8fPxapqakiOjpa+Pv7iylTpiitV7t2bXH06FERGxsrsrKylF7//L6XCus80+R9UmfIt7zOHaDwfr8K8j34rkn+Wqt67wFpSNLDhw+LiIgIkZaWJl69eiUuXrwofv75Z6Wh6t713W1hYSH+/PNP8fr1a5GSkiJu3Lgh/vvf/77X56RatWrC09NTvHnzRiQmJoqzZ8+KDh06iDVr1gghhGjcuLHK+Nq1ayd8fX2FTCYTcXFxwsvLS2lITfmU3/VKQaaCDvkGvPs3f+zYsYrlz549U3xHq1o3v3MM+N91UvXq1cX06dPFw4cPRWpqqggJCRFz5szJc0hTTa6V8pvk8ZmYmIilS5cqri+Dg4PFhAkT8jyH8xuyVV9fX4wePVqcP39exMXFiZSUFPHs2TNx/Phx8e2336r8/ihRooSIi4sTQghx8eLFPLed12evIPt88eKFEEJ5ODgAok2bNkJOPixczv2rej/fjqty5cpi8eLF4tKlSyI8PFxxDbB//37RunXrXM8vVaqUmD9/vrh//75ibPZjx46Jdu3a5Xluq/oe1HRI3Y9o0noAnDhx+kSm5s2bCyGE2LZtm9Zj4fT+k42NjUhPTxdnz57VeiycOHHipM5UGDexNJ3Onz8vMjMzhampqWJefjemOOnW9K6bCpzePZmYmAghhDh58qTWY/lUJ7ZpJ6JC88MPPwAA1q9fr+VIqDBMmTIFRkZGfD+JiPC/XqxzGjp0KNq3bw8fHx+1Rksh+hTJm6fqYn8Znwq2aSei92Jra4shQ4agfv36GDx4ME6ePJnv8GSk28zNzTF27FjY2dlh1KhRuHfvHvbu3avtsIiItO7u3bu4ceMGgoKCkJWVhSZNmqBz585ISEjA999/r+3wiD44KysrTJw4Ef379wcApb4HqHAxaSei91KjRg0sXboUMpkMR44cwTfffKPtkOg9lC1bFkuXLkVKSgouXLiAMWPGqOxciYjoY9a4cWO4uLi8c71nz54peg7/888/0bdvX7Ro0QKmpqaIiorCzp07sXDhwkIZhpHoY1OxYkVMnz4dT548wTfffIPjx49rO6RPlh6kevJERERERMWCq6urWkP2+fn55Tl8JRHRh8KknYiIiIiIiEhHsSM6IiIiIiIiIh3FNu3/r1KlSpDJZNoOg4iIiIiIiIoJMzMzvHr1Kt91mLRDStjDwsK0HQYREREREREVM5UrV843cWfSDihK2CtXrszSdiIiIiIiIipyZmZmCAsLe2cOyqQ9B5lMxqSdiIiIiIiIdAY7oiMiIiIiIiLSUUzaiYiIiIiIiHQUk3YiIiIiIiIiHcU27WoqWbIkKlSoAD09PW2HQlTohBCQyWSIi4uDEELb4RARERER0f9j0q6GBg0aYOrUqTAyMtJ2KERF6v79+9i4cSOioqK0HQoREREREQHQA1Dsi9XMzMyQkJAAc3PzXL3HlyxZEu7u7ggODsbBgweRmZmppSiJio6BgQGsrKwwaNAglC5dGuPGjeO5TkRERERUhPLLQ3NiSfs7VKhQAUZGRjh48CCePHmi7XCIiszTp08RGxuLWbNmwcbGBi9fvtR2SERERERExR47onsHeRt2ljpScZCWlgZAKnknIiIiIiLtY9JOREREREREpKNYPb6AbG1tYWlp+cH2Fx0djRcvXnyw/REREREREZH2MWkvAFtbWwTfvw/TUqU+2D6TkpPhYG9fqIm7EAIuLi44fPhwgbfh4eEBCwsL9O/fHwDg6+uLmzdvYurUqe8V29y5c+Hi4oKmTZu+13aIiIiIiIg+ZkzaC8DS0hKmpUph6OnTCI6LK/L9OVhYYKezMywtLdVO2i0tLbFgwQL07t0b1tbWePPmDW7duoUFCxbg0qVLAAAbGxu8efPmvWKbPHlykYxdv2LFCqxdu1bx/9s3BwqqMG8G5HXTo7BiJSIiIiIiYtL+HoLj4nAjOlrbYajk5eUFY2NjuLq64unTp7C2toazszPKly+vWCciIuK995OQkPDe23ibgYEBkpKSkJSUVOjbJiIiIiIi+piwI7pPUJkyZdCxY0fMmDEDfn5+eP78Oa5du4alS5fin3/+UawnhMDnn38OALCzs4MQAgMHDsS5c+eQnJyMq1evonbt2mjRogWuXbsGmUyG48ePK7Xl9/DwwMGDB/OMZdiwYbh27RoSEhLw+vVr7Ny5ExUqVFAsd3JyghACPXv2REBAANLS0tC+fXvMnTsXN27cACCVjru5ucHFxQVCCAgh4OTkhNOnTyuVxgNSDYO0tDR06dIlVyyurq6YN28emjRpotiOq6srAKnJw6FDhyCTyRAfHw9PT09YWVkV4NXPLSQkBJMnT1aad+PGDcydO1fxvxAC33zzDf755x8kJSUhKCgIbdq0Qc2aNeHr64vExERcvHgRNWrUUDynRo0aOHToEMLDwyGTyXD16lU4Ozvn2vfMmTOxefNmJCQkIDQ0FKNHjy6U4yIiIiIioqLHpP0TlJiYCJlMBhcXFxgbG2v03Pnz52PRokVo1qwZMjMzsWvXLixbtgyTJ09Ghw4dUKtWLSxYsEDt7RkZGWH27Nlo3LgxXFxcUK1aNWzdujXXekuXLsWPP/4IBwcH3L59W2nZihUr4OnpiRMnTsDGxgY2Nja4dOkSNm3ahCFDhigd47BhwxAWFoYzZ87k2oenpydWrFiBu3fvKrbj6ekJPT09HD58GOXKlYOTkxO6deuGGjVqwNPTU/0XrhDMnj0b27dvR5MmTXD//n3s2rULf/31F5YsWYIWLVpAT08P7u7uivVLly6N48ePw9nZGU2bNsXJkyfxzz//wNbWVmm73333HQICAtC0aVP88ccfWL9+PerUqfNBj42IiIiIiAqG1eM/QVlZWXBzc8PGjRsxZswYBAYG4uzZs9izZw/u3LmT73NXrFiBU6dOAQB+//137NmzB126dFG0g9+8eTPc3NzUjsXDw0PxOCQkBJMmTUJAQABMTU2Vqr/PmTMHPj4+KreRlJSElJQUmJiYKFXpP3DgANzd3fH5559j3759AAA3NzeVNwUAIDU1FYmJicjMzFTaTteuXdGwYUNUr14dL1++BAAMHz4cQUFBaNGiBQICAvI8vt27dyMrK0tpnomJCY4dO5bnc/Li4eGhOI5ff/0Vly9fxsKFC5Xej5yv5+3bt5VucMyZMwf9+/dHv379sG7dOsX848ePY/369YrtTp06FZ07d8bDhw81jpGIiIiIiD4slrR/og4cOIBKlSqhX79+OHnyJDp16oTAwEBFdfC85EwC5YltzkQ/IiJCo2rjzZo1w5EjRxAaGoqEhAScPXsWAFC1alWl9fJLjPOSlpaGHTt24OuvvwYANG3aFA0aNMgzac+Lg4MDXrx4oUjYASA4OBhv3ryBg4NDvs+dOnUqmjRpojQdOXJE42MB1HvtS5YsCTMzMwCAqakpli9fjqCgILx58wYymQwODg65Xtu3ay6Eh4cXWtV/IiIiIiIqWkzaP2FpaWnw8fHBokWL0K5dO2zduhXz58/P9zkZGRmKx0IIlfP09dU7bUqVKgVvb28kJCRg6NChaNmypaJH9ber7Re007lNmzahW7duqFy5MkaMGIEzZ87g+fPnBdpWQYSHh+PJkydKk0wmU1onOzs7Vw/7RkZGubalzmsPQPH6r1ixAv3798dPP/2EDh06oEmTJrhz506u1zbnNuTbUfc9JCIiIiIi7WL1+GIkKCgILi4uH2x/9vb2sLS0xI8//qgoxW7RokWBtpWeng4DA4Nc8+/evYuAgACMHj0aQ4YMwYQJEzTeTnBwMGxtbVGlShVFnA4ODihbtiyCgoIKFG9OUVFRqFixouJ/MzMzVK9e/b23K78Rc+jQIQBSyXu1atXee7tERERERAVla2ur1HG1NkRHR6s9VPbHgEn7e3CwsNDJ/ZQrVw779u3Dli1bcPv2bchkMrRo0QLTp0/PNaZ4UXr+/DnS0tIwceJE/Pnnn2jQoAFmz55doG09e/YMPXr0QJ06dRATE4P4+HhkZmYCkErb3d3dkZSUlG9P9vLtVK9eHY0bN8bLly8hk8ng4+ODO3fuYOfOnZgyZQoMDQ3xxx9/wM/PD9evXy9QvDmdOXMGbm5u+OeffxAXF4cFCxbkagdfEI8ePcIXX3yBf/75B0IILFy4kCXoRERERKQ1tra2uH8/GKVKmWo1juTkJNjbO3wyiTuT9gKIjo5GUnIydr41vFZRSkpORrSaY8InJibiypUrmDp1KmrWrAkjIyO8ePECGzduxOLFi4s40v+Jjo6Gm5sbFi9ejEmTJiEwMBDff/+90rBz6tq4cSM6deqEgIAAmJmZoVOnTor28bt378bq1auxe/dupKWl5bsdLy8vfPHFF/D19UXZsmXh5uaGbdu24fPPP8fatWtx7tw5ZGdn4+TJk5g4cWKBjvttS5YsQfXq1XH06FHEx8dj9uzZhVLSPm3aNGzZsgWXLl1CdHQ0fv31V5ibmxdCxEREREREmrO0tESpUqY4fXoo4uKCtRKDhYUDnJ13wtLS8pNJ2vUACG0HoW1mZmZISEiAubl5rvbIdnZ2WLhwIWbPno3Q0FDF/A9d7eNTq+JRmOzs7PDkyRO0bNlSMbY7FUxe5zsRERER0bs0bdoUgYGB8PJqhuho7VyXW1o2xYABgWjWrJnO5wb55aE5saS9gF68eMEkWssMDQ1Rvnx5LFq0CJcvX9b5DyUREREREZGm2ACWPlrt2rVDeHg4WrZsiTFjxmg7HCIiIiIiokLHknb6aJ09ezbXUGpERERERESfEpa0ExEREREREekoJu1EREREREREOopJOxEREREREZGOYtJOREREREREpKOYtBMRERERERHpKPYeX0C2trawtLT8YPuLjo7muPBERERERETFDJP2ArC1tcX9+8EoVcr0g+0zOTkJ9vYOhZq4CyHg4uKCw4cPF3gbHh4esLCwQP/+/QEAvr6+uHnzJqZOnfpesc2dOxcuLi5o2rTpe22HiIiIiIjoY6bVpF1fXx/z5s3DsGHDYGNjg1evXmHr1q1YtGiR0nrz58/H6NGjYWFhgYsXL2Ls2LF4/PixYnnZsmWxdu1a9O3bF9nZ2fDy8sLkyZORlJRUJHFbWlqiVClTnD49FHFxwUWyj5wsLBzg7LwTlpaWaiftlpaWWLBgAXr37g1ra2u8efMGt27dwoIFC3Dp0iUAgI2NDd68efNesU2ePLlIxkpfsWIF1q5dq/j/7ZsDBVXYNwM6deqE7777Dq1bt4aZmRnCwsIQEBCAdevW4fz58wAAJycn+Pn5KZ4TERGBCxcu4IcffkDVqlWVluW1j7Nnz+a5fP369RgzZgymTJmC33//vTAOi4iIiIiIdIRWk/YZM2Zg7NixcHV1xb1799CiRQt4eHggPj5ekbBNnz4dkyZNgqurK0JCQrBw4UJ4e3ujXr16SEtLAwDs3LkTFStWRLdu3WBkZAQPDw9s2LABQ4cOLdL44+KCER19o0j3UVBeXl4wNjaGq6srnj59Cmtrazg7O6N8+fKKdSIiIt57PwkJCe+9jbcZGBggKSmpyG66FJaxY8fC3d0dO3bswODBg/HkyROUKVMGnTt3xqpVq9CiRQul9evUqQOZTIbatWtjw4YN+Oeff9CsWTPY2Ngo1vn9999hbm6OESNGKObFxsbmGYOLiwvatGmDsLCwwj9AIiIiIiLSOq12RNe2bVscPnwYx48fR2hoKLy8vHDq1Cm0atVKsc6UKVOwaNEiHDlyBHfu3MHw4cNRqVIluLi4AADs7e3Rq1cvjBo1ClevXsXFixcxceJE/Pe//0XFihW1dGTaVaZMGXTs2BEzZsyAn58fnj9/jmvXrmHp0qX4559/FOsJIfD5558DAOzs7CCEwMCBA3Hu3DkkJyfj6tWrqF27Nlq0aIFr165BJpPh+PHjSm35PTw8cPDgwTxjGTZsGK5du4aEhAS8fv0aO3fuRIUKFRTLnZycIIRAz549ERAQgLS0NLRv3x5z587FjRvSDZG5c+fCzc0NLi4uEEJACAEnJyecPn1aqTQekGoYpKWloUuXLrlicXV1xbx589CkSRPFdlxdXQFITR4OHToEmUyG+Ph4eHp6wsrKKs/jsrW1xerVq7F69Wq4ubnB19cXz58/x507d7BmzZpcCTsAREZGIjw8HOfPn8eCBQtQv359VKtWDREREYopJSUFaWlpSvMyMjJUxlCpUiWsXbsWQ4cOzXMdIiIiIiL6uGk1ab906RKcnZ1Ru3ZtAECjRo3Qvn17nDhxAgBQvXp1VKxYET4+PornJCQk4MqVK3B0dAQAODo64s2bN7h+/bpiHR8fH2RnZ6N169Yq92tsbAwzMzOl6VOSmJgImUwGFxcXGBsba/Tc+fPnY9GiRWjWrBkyMzOxa9cuLFu2DJMnT0aHDh1Qq1YtLFiwQO3tGRkZYfbs2WjcuDFcXFxQrVo1bN26Ndd6S5cuxY8//ggHBwfcvn1badmKFSvg6emJEydOwMbGBjY2Nrh06RI2bdqEIUOGKB3jsGHDEBYWhjNnzuTah6enJ1asWIG7d+8qtuPp6Qk9PT0cPnwY5cqVg5OTE7p164YaNWrA09Mzz+MaMGAAjI2NsWzZMrVfi5xSUlIAQOP3R05PTw87duzA8uXLERQUVKBtEBERERGR7tNq9filS5fC3Nwc9+/fR1ZWFgwMDPDzzz9j165dAKCoNvx2Ne6IiAjFMhsbG0RGRiotz8rKQmxsrFK145xmzpyJefPmFfLR6I6srCy4ublh48aNGDNmDAIDA3H27Fns2bMHd+7cyfe5K1aswKlTpwBIVbX37NmDLl26KNrBb968GW5ubmrH4uHhoXgcEhKCSZMmISAgAKampkrV3+fMmaN0cyanpKQkpKSkwMTEROlcOHDgANzd3fH5559j3759AAA3NzeVNwUAIDU1FYmJicjMzFTaTteuXdGwYUNUr14dL1++BAAMHz4cQUFBaNGiBQICAnJtq06dOoiPj1fazhdffIFt27Yp/nd0dMTdu3dzPdfGxgbff/89Xr58iQcPHqiM9V1mzJiBzMxMrFmzpkDPJyIiIiKij4NWS9oHDRqEoUOHYsiQIWjWrBlcXV3x/fffY/jw4UW63yVLlsDc3FwxVa5cuUj3pw0HDhxApUqV0K9fP5w8eRKdOnVCYGCgojp4XnKWcssT0pyJfkRERL7Vxt/WrFkzHDlyBKGhoUhISFB0qFa1alWl9VQlxu+SlpaGHTt24OuvvwYANG3aFA0aNMgzac+Lg4PUK788YQeA4OBgvHnzBg4ODnk+Twih9L+3tzeaNGmC3r17o3Tp0jAwMFBa/vLlSyQmJuL169cwNTXFgAED3lmtfciQIZDJZIqpffv2aNasGSZPnqzRzRMiIiIiIvo4abWkffny5Vi6dKmiGvLdu3dhZ2eHmTNnYvv27QgPDwcAWFtbKx7L/7958yYAIDw8PFcSaWBggHLlyik9J6f09HSkp6cXwRHplrS0NPj4+MDHxweLFi3Cxo0bMX/+fKXS4LflTCLlSenb8/T11bvXU6pUKXh7e8Pb2xtDhw5FVFQUqlatilOnTuWqFl7QTuc2bdqEmzdvonLlyhgxYgTOnDmD58+fF2hbmnj06BEsLCxgbW2tuLmRlJSEJ0+eIDMzU+VzOnTogISEBERGRiIxMVGt/Rw5cgRXrlxR/B8WFoZvv/0WVlZWSsdpaGiI3377DVOmTEH16tXf48iIiIiIiEiXaLWkvVSpUsjOzlaal5WVpUgKQ0JC8Pr1azg7OyuWm5mZoXXr1vD39wcA+Pv7o2zZsmjWrJlinS5dukBfX18p2SEgKCgIpqYfbmx5e3t7WFpa4scff8SFCxfw4MEDjUrpc0pPT89Vcg1IN3oCAgIwevRoDBkyBFu2bNF4O8HBwbC1tUWVKlUU8xwcHFC2bNk824vv378f6enpmDFjhtrHEBISgqdPn6qdsANS/wRPnjxRTKmpqdixYwcaNWqEJk2aKKawsDAsX74cPXr0UHvbRERERESk+7Ra0v7PP//g559/xvPnz3Hv3j00bdoU06ZNU0q8Vq9ejVmzZuHRo0eKId9evXqFQ4cOAQDu37+PEydOKNpvGxkZwd3dHXv27MHr16+LNH4Li7yrTmtzP+XKlcO+ffuwZcsW3L59GzKZDC1atMD06dNx+PDhIooyt+fPnyMtLQ0TJ07En3/+iQYNGmD27NkF2tazZ8/Qo0cP1KlTBzExMYiPj1eUaG/atAnu7u5ISkrKtyd7+XaqV6+Oxo0b4+XLl5DJZPDx8cGdO3ewc+dOTJkyBYaGhvjjjz/g5+en1MFhTi9evMB3332H33//HeXKlcPWrVsREhKCcuXKYdiwYQCkG1BFITY2NtcwcBkZGQgPD8fDhw+LZJ9ERERERKQdWk3aJ06ciIULF+KPP/6AlZUVXr16hb/++kupd/Jly5bB1NQUGzZsgIWFBS5cuICePXsqxmgHgKFDh8Ld3R2nT59GdnY2vLy8MGnSpCKLOzo6GsnJSXB23llk+3hbcnISoqOj1Vo3MTERV65cwdSpU1GzZk0YGRnhxYsX2LhxIxYvXlzEkf5PdHQ03NzcsHjxYkyaNAmBgYH4/vvvlYadU9fGjRvRqVMnBAQEwMzMDJ06dVK0j9+9ezdWr16N3bt3K50Xqnh5eeGLL76Ar68vypYtCzc3N2zbtg2ff/451q5di3PnziE7OxsnT57ExIkT892Wu7s7goODMW3aNOzfvx/m5uaIiYmBv78/evToobITOiIiIiIiIk3oARDvXOsTZ2ZmhoSEBJibm0Mmkykts7Ozw8KFCzF79myEhoYq5tva2iqNV17UoqOj8eLFiw+2v4+JnZ0dnjx5gpYtWyrGdqeCyet8JyIiIiJ6l6ZNmyIwMBBeXs0QHa2d63JLy6YYMCAQzZo10/ncIL88NCetlrR/zF68eMEkWssMDQ1Rvnx5LFq0CJcvX9b5DyUREREREZGmtNoRHdH7aNeuHcLDw9GyZUuMGTNG2+EQEREREREVOpa000fr7Nmz0NPT03YYRERERERERYYl7UREREREREQ6ikn7Owgh9dOnaoxwok+NoaFU+UZ+3hMRERERkXYxaX8HeS9+VlZWWo6EqOjZ29sDgNrDCxIRERERUdFim/Z3iIuLw/379zFo0CDExsa+cxxwoo+RoaEh7O3tMWjQIPj5+SE5OVnbIREREREREZi0v5MQAhs3bsQvv/yCWbNmaTscoiLl5+cHDw8PbYdBRERERET/j0m7GqKiojBu3DjY2NiwbTt9koQQiI6OZgk7EREREZGOYdKupszMTLx8+VLbYRAREREREVExwo7oiIiIiIiIiHQUk3YiIiIiIiIiHcWknYiIiIiIiEhHMWknIiIiIiIi0lFM2omIiIiIiIh0FJN2IiIiIiIiIh3FpJ2IiIiIiIhIRzFpJyIiIiIiItJRTNqJiIiIiIiIdBSTdiIiIiIiIiIdxaSdiIiIiIiISEcxaSciIiIiIiLSUUzaiYiIiIiIiHQUk3YiIiIiIiIiHcWknYiIiIiIiEhHMWknIiIiIiIi0lFM2omIiIiIiIh0FJN2IiIiIiIiIh3FpJ2IiIiIiIhIRzFpJyIiIiIiItJRTNqJiIiIiIiIdBSTdiIiIiIiIiIdxaSdiIiIiIiISEcxaSciIiIiIiLSUUzaiYiIiIiIiHQUk3YiIiIiIiIiHcWknYiIiIiIiEhHMWknIiIiIiIi0lFM2omIiIiIiIh0FJN2IiIiIiIiIh3FpJ2IiIiIiIhIRzFpJyIiIiIiItJRWk3aQ0JCIITINbm7uwMATExM4O7ujujoaMhkMuzfvx9WVlZK27C1tcXRo0eRlJSEiIgILFu2DAYGBto4HCIiIiIiIqJCpdWkvWXLlrCxsVFMXbt2BQDs27cPALBq1Sr07dsXAwcOhJOTEypVqoQDBw4onq+vr49jx47B2NgYbdu2haurK9zc3LBgwQKtHA8RERERERFRYdJq0h4dHY2IiAjF1KdPHzx+/Bhnz56Fubk5Ro4ciWnTpsHX1xeBgYEYMWIE2rVrh9atWwMAunfvjnr16mHYsGG4desWTp48idmzZ2P8+PEwMjLS5qERERERERERvTedadNuZGSEYcOGYcuWLQCA5s2bw9jYGD4+Pop1Hjx4gNDQUDg6OgIAHB0dcefOHURGRirW8fb2RpkyZVC/fv0892VsbAwzMzOliYiIiIiIiEjX6EzS7uLiAgsLC2zduhUAYGNjg7S0NMTHxyutFxERARsbG8U6ERERuZbLl+Vl5syZSEhIUExhYWGFeCREREREREREhUNnkvaRI0fixIkTeP36dZHva8mSJTA3N1dMlStXLvJ9EhEREREREWnKUNsBAEDVqlXRtWtXfPHFF4p54eHhMDExQZkyZZRK262trREeHq5Yp1WrVkrbsra2VizLS3p6OtLT0wvzEIiIiIiIiIgKnU6UtI8YMQKRkZE4duyYYt7169eRnp4OZ2dnxbw6derAzs4O/v7+AAB/f380bNgQFSpUUKzTrVs3xMfHIygo6MMdABEREREREVER0HpJu56eHkaMGIFt27YhKytLMT8hIQGbN2/GypUrERsbi4SEBKxduxaXLl3ClStXAACnTp1CUFAQduzYgenTp8PGxgaLFi3CunXrWJJOREREREREHz2tJ+1du3aFnZ2dotf4nKZOnYrs7Gx4eXnBxMQE3t7eGDdunGJ5dnY2+vTpg/Xr18Pf3x9JSUnYtm0b5syZ8yEPgYiIiIiIiKhIaD1p//fff6Gnp6dyWVpaGiZMmIAJEybk+fznz5+jd+/eRRUeERERERERkdboRJt2IiIiIiIiIsqNSTsRERERERGRjmLSTkRERERERKSjmLQTERERERER6Sgm7UREREREREQ6ikk7ERERERERkY5i0k5ERERERESko5i0ExEREREREekoJu1EREREREREOopJOxEREREREZGOYtJOREREREREpKOYtBMRERERERHpKCbtRERERERERDqKSTsRERERERGRjmLSTkRERERERKSjmLQTERERERER6Sgm7UREREREREQ6ikk7ERERERERkY5i0k5ERERERESko5i0ExEREREREekoJu1EREREREREOopJOxEREREREZGOYtJOREREREREpKOYtBMRERERERHpKCbtRERERERERDqKSTsRERERERGRjmLSTkRERERERKSjmLQTERERERER6Sgm7UREREREREQ6ikk7ERERERERkY5i0k5ERERERESko5i0ExEREREREekoJu1EREREREREOopJOxEREREREZGOYtJOREREREREpKOYtBMRERERERHpKCbtRERERERERDqKSTsRERERERGRjmLSTkRERERERKSjmLQTERERERER6Sgm7UREREREREQ6ikk7ERERERERkY7SetJeqVIl7NixA9HR0UhOTsbt27fRvHlzpXXmz5+PV69eITk5Gf/++y9q1aqltLxs2bL4+++/ER8fjzdv3mDTpk0wNTX9kIdBREREREREVOi0mrRbWFjg4sWLyMjIQK9evVCvXj189913ePPmjWKd6dOnY9KkSRgzZgxat26NpKQkeHt7w8TERLHOzp07Ub9+fXTr1g19+vRBx44dsWHDBm0cEhEREREREVGhMdTmzmfMmIEXL17g66+/Vsx79uyZ0jpTpkzBokWLcOTIEQDA8OHDERERARcXF3h6esLe3h69evVCixYtcP36dQDAxIkTcfz4cXz//fd4/fp1rv0aGxsrJf1mZmZFcHRERERERERE70erJe39+vVDQEAA9u7di4iICAQGBmLUqFGK5dWrV0fFihXh4+OjmJeQkIArV67A0dERAODo6Ig3b94oEnYA8PHxQXZ2Nlq3bq1yvzNnzkRCQoJiCgsLK6IjJCIiIiIiIio4rSbtNWrUwNixY/Ho0SP06NED69evx5o1azB8+HAAgI2NDQAgIiJC6XkRERGKZTY2NoiMjFRanpWVhdjYWMU6b1uyZAnMzc0VU+XKlQv70IiIiIiIiIjem1arx+vr6yMgIAA///wzAODmzZto0KABxowZg+3btxfZftPT05Genl5k2yciIiIiIiIqDFotaX/9+jWCgoKU5gUHB6Nq1aoAgPDwcACAtbW10jrW1taKZeHh4bCyslJabmBggHLlyinWISIiIiIiIvoYaTVpv3jxIurWras0r06dOggNDQUAhISE4PXr13B2dlYsNzMzQ+vWreHv7w8A8Pf3R9myZdGsWTPFOl26dIG+vj6uXLnyAY6CiIiIiIiIqGhotXr8qlWrcOnSJcycORN79+5Fq1at8M033+Cbb75RrLN69WrMmjULjx49QkhICBYuXIhXr17h0KFDAID79+/jxIkT2LhxI8aMGQMjIyO4u7tjz549KnuOJyIiIiIiIvpYaDVpDwgIQP/+/bFkyRLMmTMHISEhmDJlCnbt2qVYZ9myZTA1NcWGDRtgYWGBCxcuoGfPnkhLS1OsM3ToULi7u+P06dPIzs6Gl5cXJk2apI1DIiIiIiIiIio0egCEtoPQNjMzMyQkJMDc3BwymUzb4RAREREREX10mjZtisDAQHh5NUN09A2txGBp2RQDBgSiWbNmuHFDOzGoS908VKtt2omIiIiIiIgob0zaiYiIiIiIiHQUk3YiIiIiIiIiHcWknYiIiIiIiEhHMWknIiIiIiIi0lFM2omIiIiIiIh0FJN2IiIiIiIiIh3FpJ2IiIiIiIhIRzFpJyIiIiIiItJRTNqJiIiIiIiIdBSTdiIiIiIiIiIdxaSdiIiIiIiISEcxaSciIiIiIiLSUUzaiYiIiIiIiHQUk3YiIiIiIiIiHcWknYiIiIiIiEhHMWknIiIiIiIi0lFM2omIiIiIiIh0FJN2IiIiIiIiIh3FpJ2IiIiIiIhIRzFpJyIiIiIiItJRTNqJiIiIiIiIdBSTdiIiIiIiIiIdxaSdiIiIiIiISEdpnLRXqVIFlStXVvzfsmVLrFq1CqNHjy7UwIiIiIiIiIiKO42T9l27dqFz584AAGtra/z7779o1aoVfvnlF8yePbvQAyQiIiIiIiIqrjRO2hs0aICrV68CAAYNGoS7d++iXbt2GDp0KNzc3Ao7PiIiIiIiIqJiS+Ok3cjICGlpaQCArl274siRIwCA+/fvo2LFioUbHREREREREVExpnHSfu/ePYwZMwbt27dHt27dcPLkSQBApUqVEBMTU+gBEhERERERERVXGiftM2bMwLfffgs/Pz/s3r0bt2/fBgD069dPUW2eiIiIiIiIiN6foaZPOHv2LCwtLWFubo64uDjF/A0bNiApKakwYyMiIiIiIiIq1jQuaT99+jTMzMyUEnYAiI2NhaenZ2HFRURERERERFTsaZy0d+rUCcbGxrnmlyhRAh06dCiUoIiIiIiIiIhIg+rxDRs2VDyuV68eYmNjFf8bGBigZ8+eCAsLK9zoiIiIiIiIiIoxtZP2mzdvQggBIQTOnDmTa3lKSgomTpxYqMERERERERERFWdqJ+3Vq1eHnp4enj59ilatWiEqKkqxLD09HZGRkcjOzi6SIImIiIiIiIiKI7WT9ufPnwOQqsITERERERERUdHTuCM6Dw8PlCpVKtd8Ozs7nDt3rlCCIiIiIiIiIqICJO2NGzfG7du30aZNG8W84cOH49atW4iOji7U4IiIiIiIiIiKM7Wrx8u1atUKixcvhp+fH3777TfUqlULvXr1wrRp07Bp06aiiJGIiIiIiIioWNI4ac/MzMT06dORnJyM2bNnIzMzE05OTrh8+XJRxEdERERERERUbGlcPd7Q0BArVqzAjBkzsGTJEvj7++PAgQPo1auXxjufO3euYhg5+RQcHKxYbmJiAnd3d0RHR0Mmk2H//v2wsrJS2oatrS2OHj2KpKQkREREYNmyZewsj4iIiIiIiD4JGpe0BwQEoFSpUujUqROuXLkCAJg+fToOHDiALVu2YPz48Rpt7+7du+jatavi/8zMTMXjVatWoXfv3hg4cCDi4+Ph7u6OAwcOoH379gAAfX19HDt2DOHh4Wjbti0qVqyI7du3IyMjAz///LOmh0ZERERERESkUzQuaQ8ICECTJk0UCTsALFu2DI6OjujYsaPGAWRmZiIiIkIxxcTEAADMzc0xcuRITJs2Db6+vggMDMSIESPQrl07tG7dGgDQvXt31KtXD8OGDcOtW7dw8uRJzJ49G+PHj4eRkZHGsRARERERERHpEo2T9lGjRiE5OTnX/Js3b6J58+YaB1C7dm2EhYXhyZMn+Pvvv2FrawsAaN68OYyNjeHj46NY98GDBwgNDYWjoyMAwNHREXfu3EFkZKRiHW9vb5QpUwb169fPc5/GxsYwMzNTmoiIiIiIiIh0jcZJOwAMGzYMFy5cQFhYGKpWrQoAmDx5Mnr27KnRdq5cuQI3Nzf07NkTY8eORfXq1XH+/HmULl0aNjY2SEtLQ3x8vNJzIiIiYGNjAwCwsbFBREREruXyZXmZOXMmEhISFFNYWJhGcRMRERERERF9CBon7WPGjMHKlStx/PhxWFhYKDp9i4uLw5QpUzTa1smTJ7F//37cuXMHp06dwmeffQYLCwsMGjRI07A0smTJEpibmyumypUrF+n+iIiIiIiIiApC46R94sSJGD16NBYvXoysrCzF/ICAADRs2PC9gomPj8fDhw9Rq1YthIeHw8TEBGXKlFFax9raGuHh4QCA8PBwWFtb51ouX5aX9PR0yGQypYmIiIiIiIhI12ictFevXh03btzINT8tLQ2mpqbvFYypqSlq1qyJ169f4/r160hPT4ezs7NieZ06dWBnZwd/f38AgL+/Pxo2bIgKFSoo1unWrRvi4+MRFBT0XrEQERERERERaZvGSXtISAiaNGmSa37Pnj2VxlhXx/Lly9GxY0fY2dnB0dERBw8eRFZWFnbv3o2EhARs3rwZK1euRKdOndCsWTN4eHjg0qVLip7rT506haCgIOzYsQONGjVC9+7dsWjRIqxbtw7p6emaHhoRERERERGRTlF7nPbZs2djxYoVWLlyJdatW4cSJUpAT08PrVq1wpdffomZM2di1KhRGu28SpUq2L17N8qXL4+oqChcuHABbdq0QXR0NABg6tSpyM7OhpeXF0xMTODt7Y1x48Ypnp+dnY0+ffpg/fr18Pf3R1JSErZt24Y5c+ZoFAcRERERERGRLtIDINRZMTMzExUrVkRUVBSGDBmCefPmoWbNmgCAV69eYe7cudiyZUtRxlpkzMzMkJCQAHNzc7ZvJyIiIiIiKoCmTZsiMDAQXl7NEB2du0n1h2Bp2RQDBgSiWbNmKpt16xJ181C1S9r19PQUj3ft2oVdu3ahZMmSKF26NKKiot4vWiIiIiIiIiLKRe2kHQCEUC6UT0lJQUpKSqEGREREREREREQSjZL2hw8f5krc31a+fPn3CoiIiIiIiIiIJBol7XPnzkV8fHxRxUJEREREREREOWiUtO/Zs4ft14mIiIiIiIg+ELXHaX9XtXgiIiIiIiIiKlxqJ+05e48nIiIiIiIioqKndvV4AwODooyDiIiIiIiIiN6idkk7EREREREREX1YTNqJiIiIiIiIdBSTdiIiIiIiIiIdpVbSfv36dVhYWAAAZs+ejZIlSxZlTEREREREREQENZN2BwcHmJqaAgDmzp2L0qVLF2lQRERERERERKRm7/E3b96Eh4cHLly4AD09PXz//fdITExUue7ChQsLNUAiIiIiIiKi4kqtpN3NzQ3z589Hnz59IIRAr169kJmZmWs9IQSTdiIiIiIiIqJColbS/vDhQ3z55ZcAgKysLDg7OyMqKqpIAyMiIiIiIiIq7tRK2nMyMDAoijiIiIiIiIiI6C0aJ+0AUKNGDUyZMgUODg4AgKCgIPz+++94+vRpoQZHREREREREVJxpPE579+7dERQUhFatWuH27du4ffs2WrdujXv37qFr165FESMRERERERFRsaRxSfvSpUuxatUqzJw5U2n+kiVL8Ouvv6J58+aFFhwRERERERFRcaZxSbuDgwM2b96ca/6WLVtQr169QgmKiIiIiIiIiAqQtEdFRaFJkya55jdp0gSRkZGFERMRERERERERoQDV4zdu3IgNGzagRo0auHTpEgCgXbt2mDFjBlauXFnoARIREREREREVVxon7QsXLoRMJsN3332HJUuWAABevXqFefPmYc2aNYUeIBEREREREVFxVaAh31avXo3Vq1ejdOnSAIDExMRCDYqIiIiIiIiICpi0yzFZJyIiIiIiIio6GndER0REREREREQfBpN2IiIiIiIiIh3FpJ2IiIiIiIhIR2mUtBsaGsLHxwe1atUqqniIiIiIiIiI6P9plLRnZmaiUaNGRRULEREREREREeWgcfX4v//+GyNHjiyKWIiIiIiIiIgoB42HfDM0NMTXX3+Nrl274vr160hKSlJa/t133xVacERERERERETFmcZJe4MGDRAYGAgAqFOnjtIyIUThREVEREREREREmiftXbp0KYo4iIiIiIiIiOgtBR7yrWbNmujevTtKlChRmPEQERERERER0f/TOGkvV64cfHx88PDhQxw/fhwVK1YEAGzevBkrVqwo9ACJiIiIiIiIiiuNk/ZVq1YhIyMDVatWRXJysmK+p6cnevbsWajBERERERERERVnGrdp7969O3r06IGwsDCl+Y8ePYKdnV2hBUZERERERERU3Glc0m5qaqpUwi5Xrlw5pKWlFUpQRERERERERFSApP38+fMYPny44n8hBPT09DB9+nT4+voWanBERERERERExZnG1eOnT5+O06dPo0WLFjA2NsayZctQv359lCtXDu3atSuKGImIiIiIiIiKJY1L2u/du4c6dergwoULOHz4MExNTXHgwAE0bdoUT58+LXAgM2bMgBACq1atUswzMTGBu7s7oqOjIZPJsH//flhZWSk9z9bWFkePHkVSUhIiIiKwbNkyGBgYFDgOIiIiIiIiIl2hcUk7ACQkJGDx4sWFFkSLFi3w7bff4tatW0rzV61ahd69e2PgwIGIj4+Hu7s7Dhw4gPbt2wMA9PX1cezYMYSHh6Nt27aoWLEitm/fjoyMDPz888+FFh8RERERERGRNhQoabewsMDIkSPh4OAAAAgKCoKHhwfevHmj8bZMTU2xc+dOjB49GrNmzVLMNzc3x8iRIzFkyBBFW/kRI0bg/v37aN26Na5cuYLu3bujXr166Nq1KyIjI3Hr1i3Mnj0bv/76K+bNm4eMjIyCHB4RERERERGRTtC4enyHDh3w7NkzTJo0CWXLlkXZsmUxadIkhISEoEOHDhoHsG7dOhw7dgynT59Wmt+8eXMYGxvDx8dHMe/BgwcIDQ2Fo6MjAMDR0RF37txBZGSkYh1vb2+UKVMG9evXz3OfxsbGMDMzU5qIiIiIiIiIdI3GJe3r1q2Dp6cnxo4di+zsbABSNfU//vgD69atQ6NGjdTe1uDBg9GsWTO0bNky1zIbGxukpaUhPj5eaX5ERARsbGwU60RERORaLl+Wl5kzZ2LevHlqx0lERERERESkDRqXtNeqVQu//fabImEHgOzsbKxcuRK1atVSeztVqlTB77//jqFDh37w8d2XLFkCc3NzxVS5cuUPun8iIiIiIiIidWictAcGBirasufk4OCQqyO5/DRv3hzW1tYIDAxERkYGMjIy0KlTJ0yaNAkZGRmIiIiAiYkJypQpo/Q8a2trhIeHAwDCw8NhbW2da7l8WV7S09Mhk8mUJiIiIiIiIiJdo1b1+IYNGyoer1mzBr///jtq1aqFy5cvAwDatGmD8ePH48cff1R7x6dPn0aDBg2U5nl4eOD+/fv49ddf8eLFC6Snp8PZ2RkHDhwAANSpUwd2dnbw9/cHAPj7++Pnn39GhQoVEBUVBQDo1q0b4uPjERQUpHYs9P5sbW1haWmp7TByiY6OxosXL7QdBhERERERUYGolbTfvHkTQgjo6ekp5i1btizXert27cLevXvV2nFiYiLu3bunNC8pKQkxMTGK+Zs3b8bKlSsRGxuLhIQErF27FpcuXcKVK1cAAKdOnUJQUBB27NiB6dOnw8bGBosWLcK6deuQnp6uVhz0/mxtbRF8/z5MS5XSdii5JCUnw8Henok7ERERERF9lNRK2qtXr17Ucag0depUZGdnw8vLCyYmJvD29sa4ceMUy7Ozs9GnTx+sX78e/v7+SEpKwrZt2zBnzhytxFtcWVpawrRUKQw9fRrBcXHaDkfBwcICO52dYWlpyaSdiIiIiIg+Smol7c+fPy/qOAAAnTt3Vvo/LS0NEyZMwIQJE/J8zvPnz9G7d++iDo3UEBwXhxvR0doOg4iIiIiI6JOh8ZBvAFCxYkW0b98eVlZW0NdX7stu7dq1hRIYERERERERUXGncdLu6uqKv/76C+np6YiJiYEQQrFMCMGknYiIiIiIiKiQaJy0L1y4EAsWLMCSJUuUEnYiIiIiIiIiKlwaj9NeqlQp7Nmzhwk7ERERERERURHTOGnfvHkzBg4cWBSxEBEREREREVEOGlePnzlzJo4ePYqePXvizp07yMjIUFr+3XffFVpwRERERERERMVZgZL2Hj164MGDBwCQqyM6IiIiIiIiIiocGift3333Hb7++mts27atKOIhIiIiIiIiov+ncZv2tLQ0XLx4sShiISIiIiIiIqIcNE7af//9d0ycOLEoYiEiIiIiIiKiHDSuHt+qVSt06dIFffr0wb1793J1RDdgwIBCC46IiIiIiIioONM4aY+Li8OBAweKIhYiIiIiIiIiykHjpP3rr78uijiIiIiIiIiI6C0at2knIiIiIiIiog9D45L2p0+f5jsee82aNd8rICIiIiIiIiKSaJy0r169Wul/IyMjNG3aFD179sTy5csLKy4iIiIiIiKiYk/jpH3NmjUq548bNw4tWrR474CIiIiIiIiISFJobdpPnDjB4d6IiIiIiIiIClGhJe3/+c9/EBsbW1ibIyIiIiIiIir2NK4eHxgYqNQRnZ6eHmxsbFChQgWMGzeuUIOj3GxtbWFpaantMJTY29trOwQiIiIiIqJPksZJ+6FDh5T+z87ORlRUFPz8/PDgwYPCiotUsLW1RfD9+zAtVUrboahUsmRJbYdARERERET0SdE4aV+wYEFRxEFqsLS0hGmpUhh6+jSC4+K0HY5CL1tb/NKqFUxMTLQdChERERER0SdF46SdtC84Lg43oqO1HYaCvYWFtkMgIiIiIiL6JKmdtGdlZSm1ZVdFCAEjI6P3DoqIiIiIiIiINEja+/fvn+cyR0dHTJo0Cfr6hdYZPREREREREVGxp3bSfuTIkVzz6tSpg6VLl6Jv377YuXMn5syZU6jBERERERERERVnBSoar1ixIjZs2IA7d+7A0NAQTZo0gZubG54/f17Y8REREREREREVWxol7ebm5li6dCkeP36M+vXrw9nZGf369cO9e/eKKj4iIiIiIiKiYkvt6vE//PADZsyYgfDwcHz55Zcqq8sTERERERERUeFRO2lfunQpUlJS8PjxY7i6usLV1VXlegMGDCi04IiIiIiIiIiKM7WT9u3bt79zyDciIiIiIiIiKjxqJ+0jRowoyjiIiIiIiIiI6C0cWJ2IiIiIiIhIRzFpJyIiIiIiItJRTNqJiIiIiIiIdBSTdiIiIiIiIiIdxaSdiIiIiIiISEcxaSciIiIiIiLSUUzaiYiIiIiIiHSU2uO0ExERERERERWEiQlQsSJQrhxgYCBN+vqAnh4QGwtERUl/s7O1HanuYdJOREREREREhc7GBqheHahUCShfXkrQ85OZCcTEAE+eAPfvAxkZHyZOXceknYiIiIiIiApJNipWjEP79oC1tfKSN2+AyEggPV0qUc/Kkkrby5cHrKyk0nhra2lq3lxK3O/eBRITtXMkukKrbdrHjBmDW7duIT4+HvHx8bh06RJ69uypWG5iYgJ3d3dER0dDJpNh//79sLKyUtqGra0tjh49iqSkJERERGDZsmUwMDD40IdCRERERERUrPXqFQugAdq2DYG1tVRy/uAB4OMDbN8O7N0L+PkBly4Bly8D164BV64Ax48DW7cCu3cD585Jyb2JCdC4MfDll0DHjoCRkZYPTou0WtL+8uVL/Pjjj3j06BH09PTg6uqKw4cPo2nTpggKCsKqVavQu3dvDBw4EPHx8XB3d8eBAwfQvn17AIC+vj6OHTuG8PBwtG3bFhUrVsT27duRkZGBn3/+WZuHRkREREREVCzY2gIbNwI9eoQCADIy9HH3bjbu3AFSUtTfTkKCNAUHS9ts1AioUgVwcJD++vkBr14VzTHoMq2WtB89ehQnTpzA48eP8ejRI8yaNQuJiYlo06YNzM3NMXLkSEybNg2+vr4IDAzEiBEj0K5dO7Ru3RoA0L17d9SrVw/Dhg3DrVu3cPLkScyePRvjx4+HUXG+FUNERERERPQBjBolVWHv0QNITdUDsBDHjzfA1auaJexve/ECOHYMOHxYSuTNzIC+fQFHR6kTu+JEZ4Z809fXx+DBg2Fqagp/f380b94cxsbG8PHxUazz4MEDhIaGwtHREQDg6OiIO3fuIDIyUrGOt7c3ypQpg/r16+e5L2NjY5iZmSlNREREREREpB5LS+DkSamE3dxcqvL+5Zf2AGYhM7PwsurwcGD/fiAoSPq/USPgiy8AU9NC24XO03rS3qBBA8hkMqSlpeHPP/9E//79ERwcDBsbG6SlpSE+Pl5p/YiICNjY2AAAbGxsEBERkWu5fFleZs6ciYSEBMUUFhZWyEdFRERERET0aapXD7h6VSpdT0kBpk0DOnQAQkNLFMn+MjKA8+eltu9JSdKwcZ9/DlhYFMnudI7Wk/YHDx6gSZMmaN26NdavX49t27bBwcGhSPe5ZMkSmJubK6bKlSsX6f6IiIiIiIg+BT16AP7+0lBujx9LvbyvWvVhxld/8QI4dEjqqM7MDOjXD6hQoej3q21aT9ozMjLw5MkTBAYG4qeffsKtW7cwefJkhIeHw8TEBGXKlFFa39raGuHh4QCA8PBwWL81joD8f/k6qqSnp0MmkylNRERERERElLeJE6V25ubmwNmzQOvWUqdxH1JiInDkCBARAZQsKbVz/9TLYLWetL9NX18fJiYmuH79OtLT0+Hs7KxYVqdOHdjZ2cHf3x8A4O/vj4YNG6JCjtsr3bp1Q3x8PILkjR6IiIiIiIjovSxeDKxZI3UCt3kz0K0bEBurnVhSU4GjR6WSdyMjoFevTztx1+qQb4sXL8aJEyfw/PlzmJmZYciQIejUqRN69OiBhIQEbN68GStXrkRsbCwSEhKwdu1aXLp0CVeuXAEAnDp1CkFBQdixYwemT58OGxsbLFq0COvWrUN6ero2D42IiIiIiOiTsHQpMGOG9Hj6dGD5cu3GA0hjwJ88CTg7AzVqAN27Sz3Nf4q0mrRbWVlh+/btqFixIuLj43H79m306NFD0WP81KlTkZ2dDS8vL5iYmMDb2xvjxo1TPD87Oxt9+vTB+vXr4e/vj6SkJGzbtg1z5szR1iERERERERF9Mn79VUrUAWDCBGDdOu3Gk1N2NnD6NFCiBFCpEvDZZ8DZs59e4a1Wk/ZRo0bluzwtLQ0TJkzAhAkT8lzn+fPn6N27d2GHRkREREREVKwtWwb88IP0ePx44I8/tBuPKtnZgLe31Jt8uXJAu3ZPAMRpO6xCpXNt2omIiIiIiEi7Fi36X8I+bpxuJuxy6enAiRPScHBlyqQC6A8jow/Qnf0HwqSdiIiIiIiIFMaOBX7+WXo8bhywfr1241FHYqKUuGdk6APww7RpYdoOqdAwaSciIiIiIiIAUjVzd3fp8ezZH0fCLhcTA1y+XB1Affz9t5W2wyk0Wm3TTgRDQ8DKCrC2BkqXlgZbLFFCmgwMpLouGRnS39RU6ZMon9LStB09EREREdEnw9ER2L0b0NcHNmyQqsh/bCIjzQFcRVhYK22HUmiYtNOHZ20N1KwJ2NgA5ctL3woFIZMBL18CoaHS36yswo2TiIiIiKiYqFMH+OcfqQztn3+kavEfr08rzf20joZ0V6lSQO3aQN26QNmyystkMiAiAoiLA1JSpBL1lBSpK0gjI8DYWPpraiol+eXLA2XKAGZmgIODNGVkSIn7o0dSEp/96XQ8QURERERUlMqWBY4dky6zr1wB/vtflofpEibtVLTMzYEWLaSSdXmJekYGEBICPH8OhIdL3TxqyshIqlZfrRpgZycl8NWrS1NiIhAcjIyIiEI9FCIiIiKiT42BAeDpCdSqBTx9CvTpAyQnazsqyolJOxWNUqWAZs0Ae3vpmwAAXr8GHjyQvg0yMt5v+xkZQFiYNF28KN0WrFlTKskvXRpo2RL3srPhCiDN1ha4ceO9D4mIiIiI6FOzbBnQrZtU7vX550B0tLYjorcxaafCpa8vJeuNGkml4QDw4gVw9WrRfgPIO6cLCABq1ADq14ewscF2APDyArZsARYulKrQExERERERhg8Hpk2THru6AnfvajceUo1DvlGhSSxdGujfH2jeXErYw8OBI0eA48c/3C277Gzg8WPg8GHUOXMGvQCph/pvvpHmr1oFWFh8mFiIiIiIiHRUq1bAX39JjxcsAA4c0G48lDcm7fTesvX0sBBAQMuWgKWl1Incv/8Chw9LVeK1xPTNGxwHUPvrrwE/P8DEBJgyRaqiP3y41uIiIiIiItKmChWkJL1ECemSfd48bUdE+WHSTu/H1BQ+zZtjDgChry91MLdvn9RuXUeUvnkT6NwZ6N4dCA6WOrDbtg04dw5o0EDb4RERERERfTD6+sCuXUDlytKl8VdfAUJoOyrKD5N2Kjhra+CLLxBTpgwsADjcvQucOiWVtOuif/8FGjcGZsyQeqzv0EHqoG7Bgv+1vyciIiIi+oTNmQN07SpdDg8YII2+TLqNSTsVTJ06QN++QKlSKCOTIRCAzccwxFpGhtRFpoODVCfI0BCYPVvqKK9hQ21HR0RERERUZLp1ky59AeDbb6WSdtJ9TNpJM3p6gKOjVN3cwAAICUG369dRXdtxaerFC+nW4sCBUid5TZpIPc/PmPG/IeqIiIiIiD4RlSsDO3dK1eP//FN6TB8HJu2kPn19KVlv1Ej6//p14NQpGGVlaTeu97F/P1C/vtQDh7ExsHQp4OsLVKmi7ciIiIiIiAqFoSHg6Sl1QHf9utQ3M308mLSTevT1pcYvtWsDWVmAj49UMv0piIwEXFykwSkTEqS27jdvAn36aDsyIiIiIqL3Nm8e0K4dEBcnVTRNS9N2RKQJJu30boaGQM+eQPXqQGam1Nnckyfajqrwbd8ONG0q3YwoXx745x/gt9/YSR0RERERfbQ6dgRmzpQejx4tDfZEHxcm7ZQ/IyOgVy/A1lbqxO3kSeD5c21HVXSePpVuQ65aJf0/bRpw/jyryxMRERHRR8fCAvj7b6nS7JYtUstQ+vgwaae8GRgAPXoAlSpJdWiOHQPCwrQdVdFLT5eS9c8/B2JjgdatpcY/Tk7ajoyIiIiISG1//SWVvT16BEyapO1oqKCYtJNqenqAs7PUzWR6upSwfwxDuhWmI0eA5s2l9u1WVlI7fvbaQUREREQfATc3YNAgqbLskCHSuOz0cWLSTqp17Pi/NuwnTwJRUdqOSDuePQPatpXqFRkaStXmd+4ESpTQdmRERERERCrVqgWsXSs9nj370+k/urhi0k65tW4N2NsD2dlS6fLr19qOSLtSUoCvvgImTvzfrUo/P8DGRtuREREREREpMTICdu0CSpeWRjJevlzbEdH7MtR2AKRjGjUCmjSRHp87B4SGajUcneLuDty+DRw4IN3YuHoV6NsXuHVL25EREREREcHW1hbz5qWjZcsIxMcb4Ndf7dG4sfEH27+9vf0H21dxwqSd/sfODmjTRnp8+TLw4IF249FF585JCfvRo1JthAsXgKFDpfbvRERERERaYmtri4cP/0SJEn0AAGXKeOLkyQFaiaVkyZJa2e+nikk7ScqVkzqe09MD7t1j6XF+njwBHB2BvXuBbt2AgweBGTOAFSu0HRkRERERFVM1aligRIlvAAiEhJRHYOAvAH75oDHY2vZCq1a/wMTE5IPu91PHpJ2kTtV69pQawLx8CVy6pO2IdF9cHPDZZ8DvvwPjxkmNhRwcgDFjpHbvREREREQf0OzZzwHEQyYzwZkzMcjMjPngMVhYsHp8UWBHdMWdvj7QvTtgZgbEx0sdz2Vnazuqj0NmJjB+vNRBXVYW8PXXwL//AuXLazsyIiIiIipGRo4EnJ3jARji6tVqyMzUdkRUmJi0F3cdOwIVKwJpadLQbmlp2o7o4+PuDvTuDSQkAE5OUn8AdetqOyoiIiIiKgbq1JEqf0p+QVxcKW2GQ0WASXtx5uAgJZfyod3i4rQd0cfL21tq5/70qTQw5qVL0g0RIiIiIqIiYmQE7NwJmJoCV6+WBvC9tkOiIsCkvbiytATatZMeX70qtWWn9xMUJPUsf+mS1LHfv/9KPcsTERERERWBhQuBFi2AmBhg9mw7ML37NPFdLY6MjaVezw0MgJAQ9hRfmKKjpV749+6VXue//wZmz9Z2VERERET0ienSBfjhB+nxqFFAVNSHG4+dPiz2Hl8cdekCmJtLbbD9/LQdTZGzt//wvViKX3/Fq6QkRI4YASxYgHItWsB20SLo5+gVJDo6Gi9evPjgsRERERHRx61cOWD7dqlP6Q0bgEOHgKZNtR0VFRUm7cVN48aAnZ3U8/mpU0B6urYjKjI2JUsiG8CuXbu0FsMGAOMAxPbrh8b9+uEAAIv/X5aUnAwHe3sm7kRERESkkU2bgMqVgfv3galTtR0NFTUm7cWJjQ3QqpX0+OJFqfHLJ8zCxAT6AMZcvYqrWkyMq1lbI6R1a/gaGaFiQgJqXLyIJsbG2OnsDEtLSybtRERERKS20aOB/v2lsrchQ4DkZG1HREWNSXtxYWwsVYvX1wcePpRuyxUTD2Uy3IiO1l4A0dHA69dAr15INTdHkJMTMi9f1l48RERERPRRqlsXWL1aevzTT8CNG1oNhz4QdkRXXHTsCJiZAfHxwIUL2o6m+ImNBQ4elBL4UqXwqGNHHNJ2TERERET00TA2BnbtAkqVkgYpWrlS2xHRh8KkvTioUweoWRPIygJOnwYyMrQdUfGUnAwcOQI8fw5haIgvAEQOGaLtqIiIiIjoI/DLL0CzZlIZkKsrIIS2I6IPhUn7p87cHGjfXnocEABERWk3nuIuIwM4eRKWT59CAAj7/ntgzRqp2QIRERERkQpduwLffy89HjlSanlJxQczhU+Zvr40ZriRERAWxvHYdYUQqHLjBpbL/584URqnw9RUi0ERERERkS6qUEEa3g0A/vxTqrhJxQuT9k9Z8+aAlRWQmgr4+rIOjQ7RA/A9gGo//ACkpAB9+wJnz0o9/BMRERERAdDTA7ZuBSpWBIKCgGnTtB0RaQOT9k+VlRXQpIn0+Nw5IClJq+GQamVPnwY6dwYiI6WbLFeuAA0aaDssIiIiItIBU6YAn30mlcENHiyV9VDxo9Wk/ccff8TVq1eRkJCAiIgIHDx4EHXq1FFax8TEBO7u7oiOjoZMJsP+/fthZWWltI6trS2OHj2KpKQkREREYNmyZTAwMPiQh6JbDA2lRFBfH3j0CAgJ0XZElJ8rV4A2baRh+KpWlXr379pV21ERERERkRY1bw4sXSo9njoVuHtXu/GQ9mg1aXdycsK6devQpk0bdOvWDUZGRjh16hRKlSqlWGfVqlXo27cvBg4cCCcnJ1SqVAkHDhxQLNfX18exY8dgbGyMtm3bwtXVFW5ubliwYIE2Dkk3tGoFWFgAiYkc3u1jERICtG0rVZEvUwY4fhz4+mttR0VEREREWmBmBuzZIw3z5uUltWWn4stQmzvv1auX0v9ubm6IiopC8+bNcf78eZibm2PkyJEYMmQIfH19AQAjRozA/fv30bp1a1y5cgXdu3dHvXr10LVrV0RGRuLWrVuYPXs2fv31V8ybNw8ZxW14s8qVgYYNpcdnzwLp6dqNh9T35g3QvTuweTMwbJj0t2ZNYNYs9kdAREREVIysXw/UqgWEhgKjRmk7GtI2nWrTXqZMGQBAbGwsAKB58+YwNjaGj4+PYp0HDx4gNDQUjo6OAABHR0fcuXMHkZGRinW8vb1RpkwZ1K9fX+V+jI2NYWZmpjR9EoyNAScn6XFQEPDypXbjIc2lpwNffQXIa4r89BOwaxdgYqLduIiIiIjog3B1BYYOBTIzgSFDgLg4bUdE2qYzSbuenh5Wr16NCxcu4N69ewAAGxsbpKWlIT4+XmndiIgI2Px/L9s2NjaIiIjItVy+TJWZM2ciISFBMYWFhRX24WhHmzZSXZr4eMDfX9vR0PuYOxdwc5PGdf/vfwEfH6B8eW1HRURERERFqG5dYN066fHcucClS9qNh3SDziTt69atQ4MGDfDf//63yPe1ZMkSmJubK6bKlSsX+T6LXOXKgIODVI3az0+6NUcft23bgJ49pdur7dtLN2Jq1dJ2VERERERUBExMpHbspqbA6dP/64SOSCeS9rVr16JPnz7o3LmzUql3eHg4TExMFNXm5aytrREeHq5Yx9raOtdy+TJV0tPTIZPJlKaPmqHh/6rF37sH5HHc9BE6c0bqoO7ZM6B2bSlxb9tW21ERERERUSFbvlwasTkyUmotmZ2t7YhIV2g9aV+7di369++PLl264NmzZ0rLrl+/jvT0dDg7Oyvm1alTB3Z2dvD//+rf/v7+aNiwISpUqKBYp1u3boiPj0dQUNAHOQata9VKqhYvk0nDh9GnJThYavpw7RpgaSndeh00SNtREREREVEh6dcPmDhReuzqCrx+rd14SLdoNWlft24dhg0bhiFDhkAmk8Ha2hrW1tYoUaIEACAhIQGbN2/GypUr0alTJzRr1gweHh64dOkSrvx/cnrq1CkEBQVhx44daNSoEbp3745FixZh3bp1SC8OPadbWwMNGkiPz51jtfhPVUQE0KkTcOgQUKIE4OkJzJyp7aiIiIiI6D3Z2gIeHtLjFSuAkye1Gw/pHq0m7ePGjYOFhQXOnj2L8PBwxTR48GDFOlOnTsXRo0fh5eWFc+fOITw8HF988YVieXZ2Nvr06YOsrCz4+/vj77//xvbt2zFnzhxtHNKHZWAgVYvX0wPu32dv8Z+65GRgwABg1Srp/8WLpYZPpUppNy4iIiIiKhBjY2DfPqBcOalS5U8/aTsi0kVaHaddT0/vneukpaVhwoQJmDBhQp7rPH/+HL179y7M0D4OzZsDZcsCSUnsLb64yM4Gpk0DHjwA1q4FBg8G7O0BFxep3TsRERERfTR++w1o3RqIjZVaP2ZkaDsi0kVab9NOBWRpCTRuLD2+cEEa35uKj7/+Arp0karNN24MBARI/xMRERHRR+HLLwF5ueRXX7H8hfLGpP0jJPT0pGrx+vrAkyf8hBdXFy4ALVpIdanKlwe8vYHJk7UdFRERERG9g4MDsHGj9HjRIuD4ce3GQ7qNSftHKKJuXamkPTUVuHhR2+GQNr18CXTsKI3pbmgIrF4tPf7/zhyJiIiISLeULg14eUnjsfv4AHPnajsi0nVM2j8yQQDC7e2lfy5dAlJStBoP6YDUVMDNTSplz8wEhg8Hzp8HqlTRdmRERERElIOeHrB1q1TS/vIlMGQIx2Ond2PS/hER+voYCUAYGAChocCjR9oOiXTJmjVA9+5AdLRUbT4gAOjcWdtREREREdH/++knaTCgtDRg4EAgKkrbEdHHQKu9x5Nmov77X4QB0M/IQPb589oOhwqBvbzWRGGJi0OaqytCVq5ESt26wL//wmbDBths3gw9NW/jRkdH48WLF4UbFxEREVEx16cPsGCB9HjcOODyZe3GQx8PJu0fi+rV8Xr8eABA5Tt38CIpScsB0fuwKVkS2QB27dpVJNtPBjARwBYDA4SPHYsGY8fibwDWajw3KTkZDvb2TNyJiIiICkndusDOnVI/0u7uwJYt2o6IPiZM2j8WJiYwefYMrR0cEBcSAqZTHzcLExPoAxhz9SquFmFyXLVqVbxs2hQ+hoaokpKCalevwiw6Os/1HSwssNPZGZaWlkzaiYiIiAqBuTlw+LD09+xZYOpUbUdEHxsm7R+L+/dR19UVe69eRQ9tx0KF5qFMhhv5JNHvLToaePoU6NYNmeXK4XGHDlJb9xs3im6fRERERAQAMDAA9uyRStqfP5fasWdmajsq+tiwI7qPiF5mJipoOwj6+MTFAQcPAg8eSHWyWrUCPvuMw8IRERERFbHffwd69QKSkgAXF3Y8RwXDpJ2oOMjMBPz8AF9fICMDsLUF/vMfoGJFbUdGRERE9EmaOBEYP14a0m3oUFZ0pIJj0k5UnDx8KJW6v3kDmJoCfftKJe/6/CogIiIiKiy9ewOrVkmPZ8yQ2rQTFRSv1ImKmzdvgAMHgPv3AT09oGlToH9/oGxZbUdGRERE9NFr1Ehqx25gAGzcCKxYoe2I6GPHpJ2oOMrMlLov9fYGUlIAS0tgwABE1q4N9UZzJyIiIqK3Va0KHD8OlC4NnD4tjcdO9L7YezxRcfbsGRARATg5AXZ2CGvUCF0BpNvYaDsyIiIioo9KuXJSeUjlysC9e1L3QewpngoDS9qJiruUFODkSeDcOehnZsIXQLCnp9RjChERERG9U6lSwNGjgL098OIF0LOnNIAPUWFg0k5EkuBg2Pv4oA2AbDMz4O+/AU9PoAIHGiQiIiLKi6GhdMnk6AjExgI9egAvX2o7KvqUMGknIgWTpCScB1Bx3TppaLhBg4DgYGD4cG2HRkRERKRz9PSADRuAPn2A5GTpb3CwtqOiTw2TdiJSYgjAZvNmoHVraUDR8uWBbduAf/8FatTQdnhEREREOmPtWmDECKnt+uDBgL+/tiOiTxGTdiJS7cYNaQz36dOldu9duwJ370r/G7IPSyIiIireVqwAxo8HsrMBNzepTTtRUWDSTkR5y8wEli8HGjQAfHyAkiWBX38Frl0DmjfXdnRERET0f+3deXhV1bnH8e+ZczIHAiRADKMEqYAgQbRKNWpxqgNWa7Vare1FrVO91urVYrXW2sehtXptnXDCOrRXaytqhVKnIiioYBlkCBCGEELm4czr/rFPTmbIfEL4fZ7nffa8z9rJzvDutfZaEhd33w033WTN/+hHsHBhfMsjA5uqy0TkwLZsgVNOgcsugwcegKlTYfly+N3v4Oc/h9raeJdQREREpE/cdhvcfrs1/+Mfw1NPWfM5OTlkZmbGrVx5eXlx+2zpXUraRaTjnn0WFi2C3/4Wvvtd+MlPrM7qfvpT+NOf4l06ERERkV51xx1w113W/H//Nzz6qDWfk5PD+vXrSExMil/horxeb7yLID1MSbuIdM7evdYY7s8/b/2lGjMGXnzReqnr+uth5cp4l1BERESkx/3qV3Drrdb8bbdZjQ8bZGZmkpiYxJIlF1NREZ/u43NyTiM//x48Hk9cPl96j5J2Eemat9+GI46wattvuw2OOw5WrIBnnrGW9+yJdwlFREREesRDD8ENN1jzN95oNTpsS0XFOkpLP+urYjWTnq7m8QOVOqITka7z++Hee2HCBHjuObDb4Yor4Kuv4Oabwe2OdwlFREREusxmg8cea0zYr7qq/YRdpLcoaReR7tu1y+qk7phjrA7qUlPhN7+xhog766x4l05ERESk0zweeOklmDfPGtbt8svhD3+Id6nkUKSkXUR6zvLlMGsWXHop7N4N48fDG2/ARx/B7NnxLp2IiIhIh6SlWW8CXnABBAJW/7vPPBPvUsmhSkm7iPQsY6xO6g4/3Oqxpa4Ojj0W/vUveOcdOProeJdQREREpF0jRsCHH8I3vgGVlTBnDrz8crxLJYcyJe0i0jtqauB//gfGjoVHHrEeU596KnzyCfzf/8GkSfEuoYiIiEgzX/saLFtmTXftghNOgKVL410qOdQpaReR3lVcDNdea3VW98wzEA7DuefC6tVW53VjxsS7hCIiIiKcfbaVsOfkwNq11ht/q1fHu1QiStpFpK9s3Wr14HLkkfDnP1s9zX/ve7B+PTz1lNWcXkRERCQO/ud/4PXXITkZliyBr38dtm+Pd6lELEraRaRvrVsH3/42TJ8Ob70FLpc1TNy6dVYyr3feRUREpI94vVYP8b/8pbX88MPWO+zl5fEtl0hTStpFJD5WrYLTT7fanr3+ulXzPneu9c77u+9CQUG8SygiIiID2PjxVnP4Cy+EYBB++EO4/noIheJdMpHmlLSLSHx9/LH1jvsRR8Czz1p/NU8+GRYvhhUr4LzzrIReREREpIdceCGsXAlTpkBJiVVX8OST8S6VSNuc8S6AiPQ/eXl58fng3/2OwCuvUHLxxZSeey5mxgz4y1/wbNuG95lnqHjoIWvsFREREZEu8HjgwQfh6qut5X/9yxqDfffuuBZLZL+UtItITJbXSwR48cUX410U9gK/Bx4BynNz8c+fj+3mmzHPPQePPgpffhnnEoqIiMjBZNIkeOEFmDrVWv7lL+HOO62BbUT6MyXtIhKT7vFgB+atWMGKoqJ4FweAHIeDcXl51Ofl8WViIsybZ8V771nJ+2uv6eUzERERaZfdDjfeCPfcY9W0791rDWDzzjvxLplIxyhpF5FWvqqu5rPS0ngXI+aocJjVeXlMuPJKNp56qvWe++zZVuzaBX/8Izz9NOzYEe+iioiISD+Sm2t1mTN7trX8t79ZHc7t2RPfcol0hnp3EpGDgg1IXrXK6jkmNxd+8QvrBbThw635bdusR+YXXWSN3yIiIiKHLLsdrrvOeptu9myoroYrr4RvfUsJuxx8lLSLyMFn1y7rJbTcXPjOd2DpUuuv86mnwosvWsn8H/9oDScnIiIih5SpU63BaX73O0hOhvfft3qJf+qpeJdMpGuUtIvIwSsYhJdfhpNOgtGjYf582LIF0tLgRz+Cf/8bNmyA226Dww6Ld2lFRESkFyUnw29+A598AjNmQEWF9e/AN74BhYXxLp1I18U1aT/++ON544032LlzJ8YYzj777Fb7/OIXv2DXrl3U1dXx7rvvMm7cuGbbMzIyeOGFF6isrKS8vJwnn3ySpKSkvroEEekvtm6Fu+6CceOsdnALFkBNDRx+uNXzzLZtVhJ/442QkxPv0oqIiEgPsdng+9+Hr76Cm28Gp9N6pj9xIjzxBBgT7xKKdE9ck/akpCS++OILrrnmmja3//SnP+W6665j3rx5zJw5k9raWt555x08Hk9sn4ULFzJp0iROOeUUzjzzTE444QQef/zxvroEEelvjLHawV1xBWRlwWWXWc3nIxGrufyDD8L27UrgRUREBoDjjoMVK6xn9dnZsHEjnHGG9fZccXG8SyfSM+KatL/99tvccccdvP76621uv+GGG/jlL3/JG2+8wZo1a7j00ksZPnw455xzDgB5eXmcdtppXHnllaxYsYKPPvqIa6+9lu985ztkZ2f33YWISP9UWwvPPWc1nx8xAn78Y2uouPYS+DFj4l1iERER6YCvfc0a9fXDD+Hoo6GyEm66yRqLfdGieJdOpGf123faR48eTXZ2NosXL46tq6qqYvny5cyKdi41a9YsysvLWblyZWyfxYsXE4lEmDlzZrvndrvdpKSkNAsRGeCKi61x3b/xjfYT+M2bYe1a64W4E04AhyPepRYREZEmxoyB55+HL76Ac86BcBgefxzGj7f+lAeD8S6hSM/rt0l7VlYWAHtajMmwZ8+e2LasrCxKSkqabQ+Hw5SVlcX2acutt95KVVVVLHbu3NnDpReRfq1pAj9ypJXA//Of1l/6iROtF+Leew/27oWFC61h5DIy4l1qERGRQ9b48fDkk7B+PVxyiTVozCuvWDXr//Vf1p9skYGq3ybtvenee+8lNTU1FiNGjIh3kUQkXnbvthL4ggIYMgQuuMBqUl9aaiXq3/2uNYxcSQl88IHVQ/1xx1m93IiIiEivmjrV6lRu/Xr4wQ/A5bKav0+bBhdeaA0SIzLQ9dv/OoujPUcMGzYsNt+w/Pnnn8f2GTp0aLPjHA4HgwYNanZMS4FAgEAg0POFFpGDW2UlvPqqFXY7zJwJZ50FZ54JRx4JX/+6FXfeCdXVVm38u+/C4sVWs3oRERHpNpsNTjsNrr8eTj21cf1f/wr33gvLl8evbCLx0G+T9sLCQnbv3k1BQQFffPEFACkpKcycOZPHHnsMgGXLlpGRkcG0adNYtWoVACeddBJ2u53l+mkWGXDy8vL69gN9vlgSH8jOpmrmTKpnzqQmP59QRoaVzJ95prXv7t2wZImVyL//vjXujIiIiHRYcrI1dNu111ojtoL1zvpLL8Gvfw1ffhnX4onETVyT9qSkpGbjro8ePZopU6ZQVlZGUVERv/3tb7n99tvZuHEjhYWF3H333ezatSvW2/z69et56623eOKJJ5g3bx4ul4tHHnmEl156id27d8fpqkSkp2V5vUSAF198Md5FASACrAYWA2+Hw/wzEMBkZ1sv2V1yibXTnj1Wc/oPPrCS+NWrrU7vREREpJmjj4Yf/cjqQiY52VpXUWG9w/7II7BtW1yLJxJ3cU3ajz76aP71r3/Flh966CEAnnnmGS6//HJ+85vfkJSUxOOPP056ejoffvghc+bMwe/3x465+OKLeeSRR1iyZAmRSIS//OUvXHfddX19KSLSi9I9HuzAvBUrWFFUFO/ixExMT2dxQQFTTzyRL7xea2i544+3mtUPGwbnn28FWE3vP/rIGl5u+XL45BNrnYiIyCEoM9N6J/3KK6331husXw8PP2x1L1Nb27Fz5eTkkJmZ2Svl7Kg+bw0oh5S4Ju3vvfceNpttv/vMnz+f+fPnt7u9vLyciy++uKeLJiL90FfV1XxWWhrvYrRiDwSsRLzhIaTbbVUbHH+8NXTc178OaWlw+ulWNFi3zjquIdasgVAoLtcgIiLS2xISrK5ivvc9mDPH6lQOrLfR/vxna+i2Dz7o3DlzcnJYv34diYlJPV/gLvB6vfEuggxA/faddhGRg1YgYNWo//vfcN99Vqd2kydbCfzMmVaMHWsNLzdxovUCH0BdHaxc2TyR70ctC0RERDorIQG++U2r4dm3vgWpqY3bPv3UqlF/4QUoL+/a+TMzM0lMTGLJkoupqFjXM4Xugpyc08jPvwePxxO3MsjApaRdRKS3RSLw+edWNMjMbEzgZ86E/HxIT7dq548/vnG/3bth1arG+OwzvdwnIiL9WkaGVZPeMABLSkrjtq1brSR94UKrKXxPqahYR2npZz13wk5KT1fzeOk9StpFROKhtBTefNMKsMa3OfxwK4E/5hhrOnkyZGfDGWdY0aCszEreG5L4Vatg40Z1dCciInFz5JGNf65mzQKHo3Hb9u1W8/dXX7UakRkTv3KKHIyUtIuIdFOPdj6zZo0VTzxBJCGBugkTqM/Li019Y8diBg2CggIrouz19Xg3bMC7YQOJ69fj+/RTSv75T6vJvYiISA9LSrL6Xz3jDKu7lpyc5tvXrIFFi+C112DFCiXqIt2hpF1EpIviMRSdH/gP8BmwKjr9HKj3eqmdOpXapl3wRiKwebM13NyaNY3TLVtUKy8iIp3i9cJxx8GJJ8I3vgEzZjR2JAfWM+J//tNqQLZokVW7LiI9Q0m7iEgX9Zeh6CYAvpQU6tPTqUtPx56ZSWTQIPba7TB+vBVz5zYeUFcHX37ZPJFfs8Zqsi8iIoLVgdysWVaSfuKJVtcrbnfzfbZssRL0RYtg6VKrF3gR6XlK2kVEuqlfDEXX5POPysxk1dy5nDtvHmsA3/jx1I8fT/24cfjGjMEkJlr/feXnNzuFc+9evJs24d24kYTNm0nYsoWEwkIcPdzEvrS0lCL1ii8i0m09Nz65ITs7yJFH1jJ5shUTJtTjcjVv0757t4tPP01h5cpkPvkkmd27PbjdbgKBABMn9kAxukDjo8uhQEm7iMgA09Bs/7U//KHVtjCwCVgNrInGamALEBoyhOohQ6ieNavZMYcBR7SIiUB6F8tXW1fHxLw8Je4iIt3QvfHJa7FesPoYWBaN3W3sNwI4EfgGcCLZ2aM56ywbZ53VuIcxYWw2RxvH9i2Njy4DmZJ2EZEBprPN9tOAyQ4HvtRU6tPSqE9Lw5eaii8lhZDXy3ZgO/B2i+Nc9fUkVFVZUV0dm3cGg+1+1sT0dBYWFJCZmamkXUSkGzo6PrnTGSY9vZ709DrS0+vIyKgnJcWHzdZ8v0gEKioSKStLoqwskX37kqirc2P1pPIf4NFW524Ym3zFinkUFa3o0evrKI2PLocCJe0iIgNUp5vt79nTep3HY40fn5HRPJKTCXq9BL1eqocNa35MXR2Ul7cOvewoItLjmo5P7nZDZiYMGWJNMzOtX+Ftqa2FkhLrV/+ePdZbVqFQHdDxV6Iaxiavrv4qbmOka3x0ORQoaRcRkfb5/Y3/0TXldredzKekQGKiFSNGND+mvp6v6uq4HCj+/vchNxc2bLB6uA8E+uiCREQOfnY7HHaYD/gLEyfuJiHBStBTU9vev7raSsqbhkYEFTl4KGkXEZHOCwSsKpqSkubrnc62k/nUVPB6qfV6eQbguuusAAiHobDQSuBbRnFx316XiEg/k5UFRx7ZPI44ArzedcD5HHFE8/0rK1sn6GroJHJwU9IuIiI9JxRq/C+xKacTUlMZlZPDFcccw0OLFlE+ZAhMmGAl9OPGWXHGGc2Pq6pqnsR/9VXjtL6+765LRKSXDR0KEydCXp6VlDck6O11Dl9fb8Prnc7WrVvYtauMffusX71quCQy8ChpFxGR3hcKQVkZGXY7dwCv3X475Z9F33/MyrKS96Zx+OEwZoyV0M+YYUVL27dbCfymTVZs3mxNt2xRQi8i/ZLdDqNGWYn5xImNSfrEiTBoUNvHhMOwcSOsWWPFl19a07S0KXz66SesXDmN0tKyPr0OEelbStpFRKTPtRpXt6oKPvnEiqiI00kgJwdfbi7+3Fx8o0ZZ09xcwhkZcNhhVpxySqvzu0pK8BQV4S4qwlNUhGfHjtjUUVPTZpk0fryI9JT0dBg/vjEaEvPDD4f2RiaLRKw3hdavh3XrGpP0devabt5+1FG21itFZEBS0i4iIn2mYQz5F198sVvn2QdsAL4CNmONPb8Z2AhUAMGhQwkOHQrTp7c6NhMYF42x0RgNDK2vpyAvjx3bt3erbCJyaEhOtt7qOfzw5gn64Ye336QdrAT8q6+sZHzdusYk/auv9O65iLRNSbuIiPSZzo4h31mjgZDLhT85GX9yMoGkJGs+Og0lJFAKlAIftzzY68W2aRNs3WpFYWHz6dat6hhP5BBis0F2Nowe3TzGjoW8PDtDh0b2e/zevU62b09g+3YP27Z5KCxMYOvWBHbudBOJNK8ldzismvjOaNViSUQGLCXtIiLS5zo9hnxPcbms9+RTUyEtLTbvTk8nnJRE2OVqrC5rS309bNvWPJEvLLTW7dhhJfWR/f8jL3Iwy8nJIXN/1ch9oCdfZUlPt7rPaJmYjx5tvXuekNDekQ0/50OA8W3EOIYMSWHIkDYb/PQob3vt7UVkwFDSLiIih45gEPbts6KJSZmZrJg7l7nXXcfaujoCw4cTGDGCQHY2geHD8Y8YYTW393qtl1Pbq+EKhXDt3Yt7zx5cJSW49uyx5ptMXfv2YetEYq937aW/yMnJYf36dSQmJsW1HHV1teTlTezQz8WQIVbXFzk5jd1gNE3M09P3f3woBEVFVv+WhYVWGJPLr371Z9577z5KSzcD9cDqaPSdnJzTyM+/B4/H06efKyJ9T0m7iIgc8rK8XuzAXx9+uN19gsAOoBDYGo3CaBQBO4Gw00kwO5tgdna753EAw4GRQE6T6XAgq0mkADagtq6OiXl5Stwl7jIzM0lMTGLJkoupqFgXlzKkp0+koGAhmZmZlJUVNUvGG+abTtuvKW9UXNyYkDdEQ5JeVGT13t7UUUcN4le/OprS0s2Uln7WOxfaAenpah4vcqhQ0i4iIoe87r5rPxgYBIQSEgh4vQS9XgKJida0YTk6DdvtFGEl+sv2c057KERiIMDkxESqFiyweqsqLm4de/ZYLQhE+khFxbpeT1bdbkhKaozERGs6aNBmYApLl/6HtLSOnWvXLiv53r7dmjZNzrduhbq63rwSkYEjOTmJhAM8CUtJSYlNMzMH90WxAPD5fNTU1PbZ5/U1Je0iIiJRvf6uvc1mNbFPSrK6nm6YJidbWYnXa03dbiJOJzVOJ/8GKCiwoj379lkJfEmJNV9a2hhNlxvmq6t77xpF9sNub0zA20rKG+ZdrvbOUAWsjiXslZVWMt6QkLec7twJgUAfXZzIAJacnMQFF1yIy3Wg9HEGAPn5M8jPz+r9gkUFgyFeeeXlAZu4K2kXERHpK8ZY1Xp1dbB3b/v7OZ3g9TI+O5tfn3gi1997LztCIcjKah0uFwwebMWkSR0rRyDQfkJfXg4VFc2jsrJxGgp1+8sgA09DMt7w3Knh2VTLhLwzfab5fNaPSm2tFVaNeA7Tpv2Rb3/7J/zjH+upquqtKxKRphISEnC5nCzZuZMKf/tPwnKSRpE/DFaU7KWoprBPypbucVMwYgQJCQlK2kVERKSPhEJQXU2yx8N5wC9ffZUdn7XRHNlmg4wMK3nPzrYGh26IwYPbno/W5DN8uBWdVVPTPJFvK7mvrraipqb1fMO05YvC0u/Y7dYt0/B8aObMfcBvmDx5B2DdSg0JekfeHW8QDjdPxBvmmy7X1bX9fCgzM5Np007D5XqesWPj02u6hlqTQ1mFP0Cpz9fu9nS39bpWdSC43/2kc5S0i4iIHKyMgbIyK9au7dgxXm/7CX1mptWddlqaNW0a0fcUY835R47sVtFtfj+Oujrs0WiYd9TWWut8Puw+HylOJ8k2G45AAKffb00DARx+f7vT6r172bN7d7fK19RA6cHf6Wz8Ng8Z0nracn7oUGv88EbbgVvaHRExHLZGRayra5w2TcgbkvHu/B/v9WYBEV588cWun6SHaKg1EekrStpFRET6uV6r2WsY/u6rrw64q3E4rLHsU1JIHzWK/7n/fvweDxUQi0qgHKgBqqNR02La0KjSeDyEPB6rpcB+lHTlugAvkNgkvEBCk/C0mO5vnc3v45brb2Dfzp1Wxun3W9Om803XBQLWA5Ve4PVaz08yMhqfp7Q133Jdw/OYzopEoKLCyb59Turr05k8+RS2bfsXlZX78Pns0bDh99sJBGxYYx60zW5vfObTEW11LOXxpAN2VqyYR1HRis5fUA/QUGsi0teUtIuIiPRTWV4vEegXtYptueKjj/i8uHi/+7iwetYfFF2O2GxEnE4iLhdhh8OaOp1EnM7YNOJ0EnE4SE9KoiA3l231q6kxAfw2Nz6bG7/Njd/mapy3W+uDtsbey+qjsQ+DDYOdCLYW8weaxuY9Bs8f7mBEB45xEsKDn4RgDQmh2lh4wnW4gzU4A9V4wnV4IvWxSKSOZFstyfY6kuz1JDvqSXL4SXb6SHL5SXYFSPYESXIHsdu79z0Lhxu7L9i7F2prvZxyyndxubKATGBIk2k2dvsQBg1yMmhQ4zlyc3+JNf5B79pfx1LV1V/Fbbg1DbUmIn1NSbuIiEg/1ZWh6By2MG57AI8jiNsRxG0P4rKHcNpCOO0hXPZwdBrCaQ/jsodwxbY1rnPaQ2S4baS4wGkP4oju47CFGJnkYtKgZP5rQjGVuZU4bWHstggOWwS7LYLdZqwpjfMOWwRbk30cNivJbXVMk+NcdkjHhd9dRcSEsNka6nFNrD7XZrNqtG3GYDPWa/42W/N94sIVjV5SQRrlZFBBemzadL7puopwCqWBVPb6U6nwJRDxh8Dhgww/iZkOjnJNYlNZGfWBALZwGFskgj0cxhapxx7ZGls31O3me2PHsq3icILBFNwmgNMEcZkgruh8s3UEcUUCuE0Qp4lOCXbo+9LQsVRWVhYVFRWx9fEaTqop1bCLSF9T0i4iIgDkJCeT2ZnepLpgVPQf7vEpKVRkZrbaXurzUVRT06tl6F0Gpz1CgiPYPJyhNpc9jhbrHSESnNZ8ZoKNSRleYAE/HLeLi3MqY0m4xxGIToO47QHcjsZ5pz3SZ1c7s/W3sFd4HAfep7cYAzabg1AEIqah/t2Gic7H1kWnYeMgEHE1hnETMC7s9gRGpmTy2ZqNlFf78UdcsagNJ1AT9lIb9lIT8VJrEqkhmVqSqbElU2tLpsaeSihpGP6EwdQ6Uwm7Eoi43RiXC+N2W/PRiLhc1gvsDRxY7we08Qp2HfAR0KwqvR17gJ8CpF/Qra+pM+LHZQJWoh9pSPijyX7EWp/iiHAYThIKLsdDiASCJBBkFUN5B0jIvxZP/kUkRLc13aflcuN8CE902UHXX18IBqd16/pFDqQj46G3pTcfaqV35f0a6TFK2kVEhJzkZNZf+G0Sne4++bw/5udDfn6r9XWhAHkvv9ojibvdFsHrCOB1Bkl0WtOG5di66PIJ2euA1Vw8ag0nZRTjdQRjyXMsmW62rkmy7Wy+7LD3/LvM0w+cT7XDhfVWtjsarhbT9uYb1xXXraEmWEfE2K1G4MZOiiuBkckpbK72Ue0PRbc1Jq8ApsU6q967cd60MU+z9TDMO5kjB3+bj4t/ybaaTdHtRM/fWOdurBkMNkalpPD17Cz+sbuY4qqa6P7WPtZr5gc+R+N30EZmwuHMHfMk+a/9hc9KS7v6jeCozExWzZ3LzZdN47O2RgI4gJycHNavX0diYlKH9g8B/nbC18F17a0vrP2UqnA9IbuLUPS1hJCtYd4dXe+y5m0uQvbmNdMhu4cQHuoPcA37f2P95A59HdrjNMFYy4CGlgItp+4mrQca1ifbwxyePAoPsCP3Iqq8k3GG/bjCPhzhAM5IoHEaCbZabrpPw/aGZbsJx7d1iPQYA0TsTsI2Z2watruI2NtYtjkJN6y3u3AnpnD8iQU4nM7G31Wt2hjRapsNQyXjWQq48s9jRP4sXIRxEolOm8+7COMhRCKBTj3Ecjjj+BT1EKakXUREyExIINHpZsmOu6kIbOulTzHkJns4emgay0v3UFFfjcMWikaYVPcgpmaew2WHL6ekfl80yQ7idTZJvBuWHU0S7ybLXkcglqC7HZ0fUuwHY3v2igNhJ/6Im0DYRSDsis37Iy4CYTeBiAt/2JpvWOePuEh2pvCtURMorvuErETYWF1PZX2YsHEQMY5mU2ve2cY2O9D1F6BzkmaSP+yH/KfsajZVfdls27i0VEYmj2Bt1U52VbYcKLvhn7/uD+lmwwkcSW1oMBWBjvUG748kAEn4IwnUh9sfSzheutqpYF5eHomJSaxYMY/q6gN3HNgRNmBISgr5+TNYsmMXFYH9f70a7okl5U+3uif2x0CTpD46tbtjSb41byX5VqLvZlBSKqMzhrKyso4yfzi2LdkzliEpMyms/ZjyUG2r41ueO2RzEbRb88bWmGyEog8afCR28asHjPshjOv64W1xhv1tJ/kNDwHC1rwzHCAlYTBZQNnku/GNLsZmwjgiIewmjN2EsEeiUxPGHmk+dURC7e/fYh+7CWMz0X4eTNNU0bBj6EzKgC+HnkBxOMN65GWaPPoyscdyjeujU4MNY7ODzUYEO8bWJKLbGpftGJstNh+Jrgcb/xmazzpg/chz2eOd0iQRdjUmw/tJkmPLTfYJN9mvYZ+G9c2WbY3nMY4EDBA88V0iBfFObC/r1N5OEyAh4sNt/HgifjzGj9v48ET8eE0dSZFahjoCTEi0sSOtmKBzHwnhGryRWpLCVaSEKkgOV+I2/l66HlHSLiJyiHLYwnijNcdZXgNswLAKu60Qpy2Cwx7BaYvgtEdw2MLRaQRXdOq0h6PTtvdrvb7xSX77zaoXcveMnr9Wf9iFP+zGF/ZEp2780fCF3aS705k0aDif7KvjqIzhOO1JWH2OJ9B2n+MdCQ9uhx23gy6/27y79kayEutYH0uOw/REMtwR6e7D+uRzDhZ53WwaetywYT3SqWB+/kjoRK1YxxRRHdlOqa91h29NdfWesEG09jrYVgv9No2zpVKQMYK/1TR/MDQu9WQKUmaypPy5Tj04AAjjiLYEaOfhQbSVQCz5t7mi+3piDwVcrkRGZUzCx5Fs2fUWZbXlhBwego4EQg43Ybs7OnVZ83Y34ehyw3zIHt3uaN2yKeTwEHJ46FTqM+Q4q9/AeDryTjgyzmWYcG2cCxBlbz9ht0eshyIOE8IRCTZbth6WhPDYIqSnJlPt9xFq8gDEZpq2AWp8eNKwbLDjcqThcWdRFdyDz4QJ2xxW/brNQdjmsKY4CdscLR5iualp435sU1o02uCK+EiP+BkJ2DN/jD1lJymhClJDZaSHSkkN7SM9VEpacB+JkWq1LOkEJe0iIn3IbovgtofwOEK47SHcjnDzqT0c7UCs9Xp39Bjr2DAeRwivM0BCrJbZaqp9eJobeIAHpu3C97WqWC10QpPa6ARHEJej9bvPJ3dv6O0OCxs7oYiNUMRO2DgIRezYbamke8bT+PJtw6Bd3m6uS8DjsONxQOoByjUj+grgR8X3UFxX2JOX3CkNNZouRze7Cpdu8zoGARFeLCiId1EA+HB3MXvqe+7ezElOIn/oUByOeNcM9j4HYRymHsIHapjfvsyEBOZmXAAcyYodf6Co6KMun6uhBYKV0FtJfcjeuNzwgCFsd8a2xZZtblKHHEfO2CvYVPgIpeVbcXi8jM87AuNwEsZOCAdhbNGpnVA0Wm9rvk9b04bxFKxyR183wYYhFUM2hu0Y/M1eL2lSx07EQGVlFeGIwdisV2Eaa+8j2IhgNxGrQ8mW62hYb01brkvyDidz0HTK9n2Av7YYRySEI9p6wBkJWq0GTCjaqiCEMzp1GKuZuD0csPZvSKaj+zbM2yNhnCYY3R6OtkII4jRNEnATZmTWyRw95R7WfPZ9incsi623R0LW8R18/SE9PZ2CggL+srOQUp+vU/fUuNSTKRj5c5bs+cUBH2pFsBGyuQjYEwjYEgjYPdF5T2yd3+7F50ik3p5MQuIgMlKGsLYOysJu6h1J1NuTqXWkUONItx5w2RPYa09gL0DCEVa0wxnxkxYqIy20j4xgCYOCexgU3MPgYDGDgsUMDu7BG9n/g8RDiZJ2kUNUW52OHaiTsP0zTXqQDuOI1rY6ouuc0XUN83ZbhOpgPXvra6I1smEcduscsVra6Dnyh+4CSikY9gU59l2x7Q5bpEmNcBiHzcQ+1xn7/ObzzZcNqW47iU6a9WjdbN5u/bsSm2+yPd3tANy8eGwtwZmB2LU2ve7YuewRXPYQDlvfdRJ21P6Hv27GH3bhcSRRH/ITjJhoMm0nZOyEI9a0aYLduGwnFHE07hfd1nR9KNJ4jtyUdL4xPIdFu3a3albd8M/GipJfU1SzqckWXzTKe+LL0iYrcRnCusrDmJh2Kb7QTkp9PdMEuStUy91/eBzJgL2N+7JzGu6x90v2sreNIcwOeHz0QY4/HOn0P/L7k+7pm34sBgqv03r71wbk588gPz8rjqWJ/j0ZXQGjq4FqoIR/FRezr67rDyY6IyfpRPKH3cqKkgcoqlnX5j5ZXi/HZmdhS++tUswApsPg92Bw54YijBiD3dZWKm2nsa+PjhoNQM5R4+Co7o8w0NvvjtsxuE0AdzgAtHzNqbVxoVQKUkbwt/LWr0UZwG/3UuNIJz31FMYMu5L3yp5hc6CGamcGlc7BzaLWmUbI7mGfO5t97ux2P9MbrmZQsIRBweImCb01zQzsIjlcecjU1itpF+nXGnui9jhCeOzRacuwN9bMuuzh5vPRGtqGeZc9TGaCnSsnjsZljwCBaARj83/MD0J+6/Vtzzed9q7/+Vqvf0SXZHW0vWebXBjjpjIAvrCDQNiBP+IkEHYSiDgJhB3WNOLAH25YH10XdlIfdlEfclEfclMfduELufjaoOFckXcUd3+5iU937KM+7MYX28/VOB92Ux9y4Q87mZo5lFVz57Jo+5W9mqyGjZMDvWddHdje5wlzuicV8FEf1lBO0rbu3pcN91hlcCelvgP/g9zqeD3I6Rc8DkcsSVhRspeimni2yBlF/rDGcjS0mqgOh3v0wc7+pLutv/3VgWC7n5nucWMD3i8p6dIDqwNp+XXo8HHRr1dPlaur5WivXAdT6xcbkBCpJyFSz7jgLgoAd90KRrdT2x+0ual0DqLKOZgKZyZlrqGUuYZR5sqizDWMfa5h1DrTqXeksNORws6Etjuc8YTryAzuYkS4mM3sYSx/6b2LjDMl7XJI6cyQVjYieBzW0EoNkWD3N847A3js1nzDMEwN4yE3HRvZ7QjisjdsD2Hwk5VoA5L5/fQSfJNrosl3EI+9dUJut/V8T9R9LWJssZ6kG3qZtuHC7UjB+jXkxBqTqK1pR9a1nO/ccmHVUioD5U16rba36NXa3ryn6+hyZoKXvIwMPi+vorzOf8DjI8ZBxNij4SCCnXT3KApG3sFJf+9ez9RNXTRuHFfkFbB0zxKWbut6zaCIiLRvf4lqX2iZMPf3VhOVwd75enXkwUGbx0W/Xj1Vrq6Wo71yDWQuEyAzWExmsLjdfXw2L+XRZH6fK4sytzUtdw1lnyubCmcmfkciOx3j2Mk4MvgPPdyXbL+ipF0OYgavM0iKy0eyy0+y009yw7zLz/FZW4D1XJT7GSdl7CI7McJlhw/HafcD9dGoazLfMnr/D/Gk9M7tH4rYCUTcBMJOgrFxgJ0Ewy6CEWcsQsZBqGG+xfpgxEmKK5kzc8eytvwdaoJlRIyVTA9O8DIhfRCflVdRVusjHF0fiY5FHDb22L7WtpbzjcM1RYyNSHSIp7a03xS6tc43K+1YZ10NzU23VBWyqaqtIcZMNNpu0j4uzUlehouiOl8bPWh3lPX16W4nV0115TWHnvx8ERERke5IMPVkB7aR3c6INkGbm32uYZS6h1OfmMuczC72+HqQUNJ+iOhMDXNndTRBcNvtBCJW8mMnTJKrnhRXLSmuWpJddaS46xrnm6531ZLiqiPZVUeis55Epw+v00ei09ehWugf9sBwLFbC6iQccUaHWGoyjTiitaaOaFLbdNgle7MhmJKcIxmbdgpW51ieJpHQYrntcNodOO2Q2EM/uVury5q9gzYuLZUJ6SPYUbeTXVVdTUI7pyNNTrvbrLTd8/aD5qa92clVe2Oh77c8Gn9VRERE+jmXCZAVKCIrUERm6AvmZo4ewI3jlbQfEnKSk1l/4bdJdPZGc5swUAFs4I/5Ich3A6XAviZTa96Ycmy2CqASq7OUnpQEJAMp0WnLaFifxLryv7PXVxrrGKsjnWyZHurmYlzqFMamzWNz5UOMTavtcodE3dVQw+zZz7Ak0jd6qpOrprrS4ZXuCREREZH+SUn7ISAzIYFEp5slO+6mop0mJmC9w+12+HHbfXgcPtx2P+7o1ONoOt98W5udbrZ1/jb2C0UcBCMeghE3wYgrOu9qss5NMOwmEHETirgJGhehSDSMk1DEFe3YqvXJWyYuOUlHkj/sh+yq3dnpsV17Wn14B1DT4zXHHdUfapiluZ7sfK0rLRN0T4iIiIj0T0raB7iRSWXMGLIbiJDheZsU904SHEESHCGrR3JnKLocxOM48DvA7XNRG3JRG7Tji/Zg7Y/2bO0PO0l3T+PIwT9ixZ4/sLlqm9X7ddhJ5AC9SDcK0/iuece0TFyUlIiIiIiIyMFGSfsAd9Wk97ntqLcBmDbkwPsbA/6w00q8w078YVds3hdqe93I5EGcNCKHf+5pPW5jg3GpXwNOpjr4f1QFS3rwCkVERERERAauAZO0X3311dx8881kZWXxxRdfcO211/LJJ5/Eu1hxt616EFuqRjImdRQ7a4uoCvjwhV3RxLsxEW9Y5w87O/3+tulwbbmIiIiIiIh0xoBI2i+44AIefPBB5s2bx/Lly7nhhht45513mDBhAnv37o138eLq8XUn8Mne81g1dy4f77myx96ZFRERERERkd43IKpIf/KTn/DEE0/wzDPPsG7dOubNm0ddXR1XXHFFvIsmIiIiIiIi0mUHfU27y+Vi+vTp3HvvvbF1xhgWL17MrFmz2jzG7Xbj8XhiyynRccYbpv1VUlISANMGDybJ2fFv3eFpaQDkphzBYE9qj5drqDcBSCfHO5gUfO3sMwaA7MQ8HLbeGS/+QOWKRxlal8kqQ4Z7HFC9369ZX5Sj5deiI9/L3i5D2/v2Trm6e0/0RLl6477sSrn66udjf2WL589oQ7kGuQ6LWxmalyf+vyv29/3oq98VXbknerpsPXVfdrdcvfXz0Zly9eXPaHvlivffcqtcWXEtQ2NZmn8t+vJveHtlaHuf3i1XV++Jgfi7ojd/Pjparnj8jCa7nUAmgwcfg9NZSVraBMDKnfp7ftfR8tkA07tF6V3Z2dns2rWLWbNm8fHHH8fW33fffcyePZtjjjmm1THz58/nzjvv7MNSioiIiIiIiLQ2YsQIdu3a1e72g76mvSvuvfdeHnzwwWbrBg0aRFlZWZxKdPBLSUlh586djBgxgurq6ngXR/oR3RvSHt0b0h7dG9Ie3RvSHt0b0paD4b5ISUnZb8IOAyBpLy0tJRQKMWzYsGbrhw0bRnFxcZvHBAIBAoFAs3X99Zt4sKmurtbXUtqke0Pao3tD2qN7Q9qje0Pao3tD2tKf74uOlOug74guGAyycuVKCgoKYutsNhsFBQUsW7YsjiUTERERERER6Z6DvqYd4MEHH+TZZ5/l008/ZcWKFdxwww0kJSWxYMGCeBdNREREREREpMsGRNL+yiuvMGTIEO666y6ysrL4/PPPmTNnDiUlJfEu2iHD7/dz55134vf7410U6Wd0b0h7dG9Ie3RvSHt0b0h7dG9IWwbKfXHQ9x4vIiIiIiIiMlAd9O+0i4iIiIiIiAxUStpFRERERERE+ikl7SIiIiIiIiL9lJJ2ERERERERkX5KSbt0WUZGBi+88AKVlZWUl5fz5JNPkpSUtN/9H374YdavX09dXR3btm3jd7/7HampqX1YaukNV199NYWFhdTX1/Pxxx8zY8aM/e5//vnns27dOurr61m9ejWnnXZaH5VU+lpn7o0rr7yS999/n7KyMsrKynj33XcPeC/JwauzvzcaXHjhhRhjeO2113q5hBIvnb030tLSeOSRR9i1axc+n48NGzbo78oA1Nn74vrrr4/9z7l9+3YefPBBPB5PH5VW+srxxx/PG2+8wc6dOzHGcPbZZx/wmNmzZ7Ny5Up8Ph8bN27ksssu64OSdp9RKLoSixYtMp999pnJz883xx13nPnqq6/MwoUL291/0qRJ5s9//rM588wzzZgxY8yJJ55oNmzYYF599dW4X4ui63HBBRcYn89nvv/975uJEyeaP/7xj6asrMwMGTKkzf1nzZplgsGg+e///m+Tl5dn7rrrLuP3+82kSZPifi2K+N4bL7zwgrnqqqvMlClTzIQJE8zTTz9tysvLzfDhw+N+LYr43hsNkZuba4qKisx7771nXnvttbhfhyL+94bL5TIrVqwwf//7382xxx5rcnNzzQknnGAmT54c92tRxO++uOiii0x9fb256KKLTG5urjnllFPMzp07zQMPPBD3a1H0bMyZM8fcfffd5pxzzjHGGHP22Wfvd/9Ro0aZmpoac//995u8vDxzzTXXmGAwaE499dS4X8sBIu4FUByEkZeXZ4wxZvr06bF13/zmN004HDbZ2dkdPs/5559vfD6fcTgccb8mRdfi448/Nr///e9jyzabzezYscPccsstbe7/0ksvmb/97W/N1i1btsw89thjcb8WRXzvjZZht9tNZWWl+d73vhf3a1HE/96w2+3mww8/NFdccYVZsGCBkvYBGp29N/7rv/7LbNq0yTidzriXXdF/7ovf//73ZvHixc3W3X///eaDDz6I+7Uoei86krT/+te/NmvWrGm27k9/+pN566234l7+/YWax0uXzJo1i/LyclauXBlbt3jxYiKRCDNnzuzwedLS0qiqqiIcDvdGMaWXuVwupk+fzuLFi2PrjDEsXryYWbNmtXnMrFmzmu0P8M4777S7vxycunJvtJSYmIjL5aKsrKy3iilx0NV74+c//zklJSU8/fTTfVFMiYOu3Bvf+ta3WLZsGY8++ijFxcWsWbOGW2+9Fbtd/+IOFF25L/79738zffr0WBP60aNHc/rpp7No0aI+KbP0Xwfr/6HOeBdADk5ZWVmUlJQ0WxcOhykrKyMrK6tD5xg8eDB33HEHjz/+eG8UUfpAZmYmTqeTPXv2NFu/Z88e8vLy2jwmKyurzf07et/IwaEr90ZL9913H7t27Wr1x1UObl25N4477jh+8IMfMHXq1D4oocRLV+6NMWPGcNJJJ7Fw4UJOP/10xo0bx//+7//icrm46667+qLY0su6cl/86U9/IjMzkw8//BCbzYbL5eKxxx7j3nvv7YsiSz/W3v+haWlpJCQk4PP54lSy/dNjSGnm3nvvxRiz35gwYUK3PyclJYU333yTtWvXcuedd3a/4CIyoNxyyy185zvf4dxzz8Xv98e7OBJHycnJPP/88/zwhz9k37598S6O9DN2u52SkhJ+9KMfsWrVKl555RXuuece5s2bF++iSRzNnj2b2267jauvvppp06Zx7rnncsYZZ3D77bfHu2giXaKadmnmgQce4JlnntnvPlu2bKG4uJihQ4c2W+9wOBg0aBDFxcX7PT45OZm3336b6upqzj33XEKhUHeLLXFSWlpKKBRi2LBhzdYPGzas3fuguLi4U/vLwakr90aDm266iZ/97GecfPLJrFmzpjeLKXHQ2Xtj7NixjB49mr/97W+xdQ1Nn4PBIBMmTGDLli29W2jpE135vbF7926CwSCRSCS2bt26dWRnZ+NyuQgGg71aZul9Xbkv7r77bp5//nmeeuopAL788kuSkpJ4/PHHueeeezDG9Hq5pX9q7//QysrKflvLDqpplxZKS0vZsGHDfiMYDLJs2TIyMjKYNm1a7NiTTjoJu93O8uXL2z1/SkoK//jHPwgEAnzrW99SDdpBLhgMsnLlSgoKCmLrbDYbBQUFLFu2rM1jli1b1mx/gFNOOaXd/eXg1JV7A+Dmm2/mjjvuYM6cOc36zJCBo7P3xvr16/na177G1KlTY/HGG2+wdOlSpk6dSlFRUV8WX3pRV35vfPTRR4wbNw6bzRZbd/jhh7Nr1y4l7ANEV+6LxMTEZg9ygFj/SU3vFTn0HMz/h8a9NzzFwRmLFi0yK1euNDNmzDDHHnus2bBhQ7Mh34YPH27WrVtnZsyYYQCTkpJili1bZr744gszZswYM2zYsFjY7fa4X4+ia3HBBReY+vp6c+mll5q8vDzzhz/8wZSVlZmhQ4cawDz77LPmV7/6VWz/WbNmmUAgYH7yk5+YCRMmmPnz52vItwEanb03fvrTnxqfz2fOO++8Zr8fkpKS4n4tivjeGy1DvccP3OjsvTFy5EhTWVlpHn74YTN+/Hhz+umnm+LiYnPbbbfF/VoU8bsv5s+fbyorK82FF15oRo0aZU4++WSzceNG89JLL8X9WhQ9G0lJSWbKlClmypQpxhhjbrjhBjNlyhSTk5NjAPOrX/3KPPvss7H9G4Z8u++++8yECRPMVVddpSHfFAM7MjIyzMKFC01VVZWpqKgwTz31VLN/rnNzc40xxsyePdsAZvbs2aY9ubm5cb8eRdfjmmuuMVu3bjU+n898/PHHJj8/P7Zt6dKlZsGCBc32P//888369euNz+cza9asMaeddlrcr0ER/3ujsLCwzd8P8+fPj/t1KOJ7b7QMJe0DOzp7bxxzzDFm2bJlpr6+3mzatMnceuutqgwYgNGZ+8LhcJif//znZuPGjaaurs5s27bNPPLIIyYtLS3u16Ho2Wgvv2i4HxYsWGCWLl3a6phVq1YZn89nNm3aZC677LK4X8eBwhadEREREREREZF+Ru+0i4iIiIiIiPRTStpFRERERERE+ikl7SIiIiIiIiL9lJJ2ERERERERkX5KSbuIiIiIiIhIP6WkXURERERERKSfUtIuIiIiIiIi0k8paRcRERERERHpp5S0i4iIHMQuu+wyysvL410McnNzMcYwZcqUbp1n6dKlPPTQQ7HlwsJCrr/++u4WjwULFvDaa691+zwiIiLxYBQKhUKhUPRODBs2zDz88MNm8+bNxufzme3bt5s33njDnHTSST1y/oSEBDNkyJBev45Ro0aZhQsXmp07d5r6+npTVFRkXn/9dTNhwgQDGLvdboYNG2YcDke3PicjI8MkJyfHlgsLC83111/f7fKnpqaatLS02PLSpUvNQw89FPf7Q6FQKBSKA4UTERER6RW5ubl89NFHVFRUcPPNN7NmzRpcLhff/OY3efTRR5k4cWK3P8Pn8+Hz+XqgtO1zOp28++67bNiwgfPOO4/du3czcuRITjvtNNLT0wGIRCLs2bOn25/V060G7HY7xhiqqqp69LwiIiJ9Ke5PDhQKhUKhGIjx5ptvmqKiIpOYmNhqW9Na35ycHPP666+b6upqU1lZaV5++WUzdOjQ2PbJkyebf/7zn6aqqspUVlaaTz/91EyfPt0A5rLLLjPl5eWxfefPn28+++wzc8kll5jCwkJTUVFh/vSnPzWrvbbZbOZnP/uZ2bJli6mrqzOff/65mTt3brvXMWXKFGOMMYcddli7++Tm5hpjjJkyZYoBzOzZs40xxpx66qlm1apVpq6uzixZssQMGTLEzJkzx6xdu9ZUVlaahQsXGq/XGztPyxrwljXtN954o1m9erWpqakx27dvN48++qhJSkqKbW/4epx11lnmP//5jwkGgyY3N9csWLDAvPbaawYwCxYsMC2NGjXKbNy40dx0001tXvvYsWPjfj8pFAqF4tAMvdMuIiLSCzIyMpgzZw6PPvoodXV1rbZXVlYCYLPZ+Otf/8qgQYOYPXs2p5xyCmPGjOHll1+O7btw4UJ27NjBjBkzmD59Or/+9a8JBoPtfvbYsWM555xzOPPMMznzzDOZPXs2P/vZz2Lbb731Vi699FLmzZvHpEmTeOihh3jhhRc44YQT2jzf3r17CYfDnH/++djtnfvX4c477+THP/4xxx57LDk5ObzyyivccMMNfPe73+WMM87g1FNP5dprr+3w+SKRCNdddx2TJk3isssu46STTuI3v/lNs30SExO55ZZbuPLKK5k0aRIlJSXNtl9//fX8+9//5vHHHycrK4usrCy2b9/O008/zeWXX95s38svv5z33nuPzZs3d+q6RUREelLcnxwoFAqFQjHQYsaMGcYYY84555z97nfyySebYDBoRo4cGVs3ceJEY4wxRx99tAFMZWWlufTSS9s8vq2a9pqammY16/fdd59ZtmyZAYzb7TY1NTXmmGOOaXaeJ554wixcuLDdcl599dWmpqbGVFZWmiVLlpjbb7/djB49Ora9vZr2pu/u33LLLcYY0+y4xx57zLz11lux5QPVtLeMuXPnmr179zb7ehhjzOTJk5vt17Smva3PAUx2drYJBoNmxowZBjBOp9OUlJS0+7VXKBQKhaIvQjXtIiIivcBms3Vov4kTJ1JUVMSOHTti69atW0d5eXnsnfcHH3yQJ598knfffZdbbrmFMWPG7PecW7dupaamJra8e/duhg4dCsC4ceNISkri3Xffpbq6OhaXXnopY8eObfec//u//0tWVhYXX3wxy5Yt49vf/jb/+c9/OPnkk/dbltWrV8fm9+zZQ21tLYWFhc3WNZStIwoKCli8eDE7duygqqqK559/nszMTLxeb2wfv9/f7HM7avfu3bz55ptcccUVAJx11ll4PB5effXVTp9LRESkpyhpFxER6QUbN24kEomQl5fX7XP94he/YNKkSbz55pucdNJJrF27lnPOOafd/Vs2nTfGxJq1JycnA3DGGWcwderUWBxxxBGcf/75+y1HTU0Nf//737n99tuZMmUKH3zwAbfffvt+j2laFmPMfst2ILm5ufz9739n9erVzJ07l+nTp3PNNdcA4Ha7Y/vV19d36HxtefLJJ/nOd75DQkICl19+OS+//HK3ziciItJdStpFRER6QXl5Oe+88w7XXHMNiYmJrbanpaUBVq16Tk4OI0eOjG2bOHEiGRkZrF27NrZu48aN/Pa3v+Wb3/wm//d//9fq3euOWrt2LT6fj8MOO4zNmzc3i6a1/R2xfv16kpKSulSOrpg+fTp2u52bbrqJ5cuXs3HjRoYPH96lcwUCARwOR6v1ixYtora2lquuuoo5c+bw9NNPd7fYIiIi3aKkXUREpJdcc801OBwOVqxYwXnnnce4cePIy8vj2muvZdmyZQAsXryYNWvWsHDhQo466ihmzJjBc889x7/+9S9WrlxJQkICv//975k9ezaHHXYYxx57LDNmzGDdunVdKlNNTQ33338/Dz30EJdeeiljxozhqKOO4sc//jGXXnppm8dMmTKF119/nblz5zJx4kTGjh3LFVdcwRVXXMFf//rXLn99OmvTpk243W6uvfZaRo8ezSWXXMK8efO6dK6tW7cyc+ZMcnNzGTx4cOx1hkgkwjPPPMO9997Lxo0b+fjjj3vyEkRERDpNSbuIiEgvKSwsZNq0aSxdupQHHniAL7/8knfffZeCggKuuuqq2H5nn3025eXlvP/++yxevJgtW7Zw4YUXAhAOhxk8eDDPPfccX331Fa+88gpvvfUW8+fP73K57rjjDu6++25uvfVW1q1bx9tvv80ZZ5zR7F3zpnbs2MHWrVuZP38+y5cvZ9WqVVx//fXMnz+fe+65p8vl6KzVq1dz4403csstt/Dll19y8cUXc+utt3bpXPfffz/hcJi1a9dSWlrKYYcdFtv21FNP4fF4WLBgQU8VXUREpMtsWD3SiYiIiAjw9a9/nSVLlpCTk9NquDgREZG+pqRdREREBKszuyFDhvDss89SXFzMJZdcEu8iiYiIqHm8iIiICMBFF13Etm3bSE9P56c//Wm8iyMiIgKopl1ERERERESk31JNu4iIiIiIiEg/paRdREREREREpJ9S0i4iIiIiIiLSTylpFxEREREREemnlLSLiIiIiIiI9FNK2kVERERERET6KSXtIiIiIiIiIv2UknYRERERERGRfur/AYzGmYvO1scmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==============================================================================\n",
    "#  Prerequisites: Same as before\n",
    "# ==============================================================================\n",
    "# You must have the following available in your environment:\n",
    "# - A trained `model` object (StyleContrastiveEncoder)\n",
    "# - The corresponding `tokenizer`\n",
    "# - The `get_embeddings` function\n",
    "#\n",
    "# ... (StyleContrastiveEncoder class and get_embeddings function definitions here) ...\n",
    "#\n",
    "\n",
    "class StyleAnalyzer:\n",
    "    \"\"\"\n",
    "    An analyzer that uses a trained model and pre-calculated centroids\n",
    "    to characterize the style of new texts.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, tokenizer, centroids_path):\n",
    "        self.model = model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        print(\"Loading Human and GPT-4 style centroids...\")\n",
    "        try:\n",
    "            centroids = torch.load(centroids_path)\n",
    "            self.human_centroid = centroids['human_centroid'].unsqueeze(0)\n",
    "            self.gpt4_centroid = centroids['gpt4_centroid'].unsqueeze(0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading centroids from {centroids_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "        print(\"Style Analyzer is ready.\")\n",
    "\n",
    "    def get_style_scores(self, texts_to_analyze):\n",
    "        \"\"\"\n",
    "        For a list of texts, calculates their similarity to the base Human and GPT-4 styles.\n",
    "        Returns a DataFrame with the scores.\n",
    "        \"\"\"\n",
    "        # Assuming get_embeddings is defined elsewhere\n",
    "        embeddings = get_embeddings(texts_to_analyze, self.model, self.tokenizer)\n",
    "        \n",
    "        sim_to_human = cosine_similarity(embeddings, self.human_centroid.cpu().numpy())\n",
    "        sim_to_gpt4 = cosine_similarity(embeddings, self.gpt4_centroid.cpu().numpy())\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'text': texts_to_analyze,\n",
    "            'human_similarity': sim_to_human.flatten(),\n",
    "            'gpt4_similarity': sim_to_gpt4.flatten()\n",
    "        })\n",
    "        return df\n",
    "\n",
    "\n",
    "def analyze_ai_collection(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    centroids_path,\n",
    "    json_file_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs a style analysis on a generic collection of AI texts from a JSON file.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Starting Style Analysis on AI Collection from: '{json_file_path}'\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # --- 1. Load All AI Texts from JSON File ---\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            ai_collection_texts = json.load(f)\n",
    "        if not isinstance(ai_collection_texts, list) or not all(isinstance(i, str) for i in ai_collection_texts):\n",
    "             print(\"Error: JSON file must contain a flat list of strings. Exiting.\")\n",
    "             return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading AI texts from {json_file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Initialize the Analyzer ---\n",
    "    analyzer = StyleAnalyzer(model, tokenizer, centroids_path)\n",
    "\n",
    "    # --- 3. Get Style Scores for the Collection ---\n",
    "    print(f\"\\nAnalyzing {len(ai_collection_texts)} texts from the collection...\")\n",
    "    style_scores_df = analyzer.get_style_scores(ai_collection_texts)\n",
    "\n",
    "    # --- 4. Calculate and Report the Style Profile ---\n",
    "    print(\"\\n--- Style Profile for the Collection ---\")\n",
    "    \n",
    "    avg_human_sim = style_scores_df['human_similarity'].mean()\n",
    "    avg_gpt4_sim = style_scores_df['gpt4_similarity'].mean()\n",
    "    \n",
    "    print(f\"Average Similarity to 'Human' Style:      {avg_human_sim:.4f}\")\n",
    "    print(f\"Average Similarity to 'GPT-4' Style:      {avg_gpt4_sim:.4f}\")\n",
    "    \n",
    "    # Determine the overall leaning of the collection\n",
    "    if avg_gpt4_sim > avg_human_sim:\n",
    "        print(\"\\nConclusion: On average, this collection's style is closer to the 'GPT-4' style print.\")\n",
    "    else:\n",
    "        print(\"\\nConclusion: On average, this collection's style is closer to the 'Human' style print.\")\n",
    "        \n",
    "    # --- 5. (Optional) Visualize the Distribution of Scores ---\n",
    "    plt.style.use('dark_background')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(style_scores_df['human_similarity'], color='cyan', kde=True, label='Similarity to Human', alpha=0.6)\n",
    "    sns.histplot(style_scores_df['gpt4_similarity'], color='yellow', kde=True, label='Similarity to GPT-4', alpha=0.6)\n",
    "    plt.title(f'Distribution of Style Similarity Scores for Collection from {json_file_path}', fontsize=14)\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Number of Texts')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#                                EXECUTION\n",
    "# ==============================================================================\n",
    "# Define the path to your JSON dataset and centroids file\n",
    "JSON_DATASET_PATH = 'Yelp_gpt-4-turbo-preview.json'  # <-- Replace with your JSON file path\n",
    "CENTROIDS_PATH = 'centroids.pt'  \n",
    "model = detector.model\n",
    "tokenizer = detector.tokenizer               # <-- Path to your pre-calculated centroids\n",
    "\n",
    "# Run the style analysis on the JSON collection\n",
    "analyze_ai_collection(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    CENTROIDS_PATH,\n",
    "    JSON_DATASET_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Zero-Shot vs. Few-Shot Comparison for: 'Arxiv_gemini-1.0-pro.json'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STAGE 1: ZERO-SHOT EVALUATION ---\n",
      "Using original Human vs. GPT-4 centroids for detection...\n",
      "Zero-shot detector (Human vs. GPT-4) is ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 11/11 [00:03<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STAGE 2: FEW-SHOT EVALUATION ---\n",
      "Using 100 samples to adapt the detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 4/4 [00:01<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specialized few-shot detector is ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "                 PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "AI Text Collection: 'Arxiv_gemini-1.0-pro.json'\n",
      "------------------------------------------------------------\n",
      "Metric: AI Detection Rate (Recall)\n",
      "\n",
      "Zero-Shot Performance (No Adaptation):   59.71%\n",
      "Few-Shot Performance (100-shot Adaptation): 70.00%\n",
      "------------------------------------------------------------\n",
      "Absolute Improvement from Adaptation: +10.29%\n",
      "Relative Improvement from Adaptation: +17.22%\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ==============================================================================\n",
    "#  Prerequisites: Your classes and functions must be defined\n",
    "# ==============================================================================\n",
    "# You must have the following available in your environment:\n",
    "# - A trained `model` object (StyleContrastiveEncoder)\n",
    "# - The corresponding `tokenizer`\n",
    "# - The `get_embeddings` function\n",
    "# - The `FewShotDetector` class and a generic `ZeroShotDetector` class\n",
    "\n",
    "class ZeroShotDetector:\n",
    "    \"\"\"A classifier that uses pre-loaded, fixed centroids for detection.\"\"\"\n",
    "    def __init__(self, model, tokenizer, centroids_path):\n",
    "        self.model = model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        try:\n",
    "            centroids = torch.load(centroids_path)\n",
    "            self.human_centroid = centroids['human_centroid'].unsqueeze(0)\n",
    "            self.gpt4_centroid = centroids['gpt4_centroid'].unsqueeze(0)\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Error loading centroids from {centroids_path}: {e}\")\n",
    "        print(\"Zero-shot detector (Human vs. GPT-4) is ready.\")\n",
    "\n",
    "    def predict(self, texts_to_classify):\n",
    "        embeddings = get_embeddings(texts_to_classify, self.model, self.tokenizer)\n",
    "        sim_to_human = cosine_similarity(embeddings, self.human_centroid.cpu().numpy())\n",
    "        sim_to_gpt4 = cosine_similarity(embeddings, self.gpt4_centroid.cpu().numpy())\n",
    "        return (sim_to_gpt4 > sim_to_human).astype(int).flatten()\n",
    "\n",
    "class FewShotDetector:\n",
    "    \"\"\"A classifier that adapts to a new AI style using a small support set.\"\"\"\n",
    "    def __init__(self, model, tokenizer, human_centroid, ai_support_texts):\n",
    "        self.model = model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.human_centroid = human_centroid\n",
    "        ai_embeddings = get_embeddings(ai_support_texts, self.model, self.tokenizer)\n",
    "        self.ai_collection_centroid = np.mean(ai_embeddings, axis=0, keepdims=True)\n",
    "        print(\"Specialized few-shot detector is ready.\")\n",
    "\n",
    "    def predict(self, texts_to_classify):\n",
    "        embeddings = get_embeddings(texts_to_classify, self.model, self.tokenizer)\n",
    "        sim_to_human = cosine_similarity(embeddings, self.human_centroid)\n",
    "        sim_to_ai_collection = cosine_similarity(embeddings, self.ai_collection_centroid)\n",
    "        return (sim_to_ai_collection > sim_to_human).astype(int).flatten()\n",
    "\n",
    "def run_comparison_evaluation(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    centroids_path,\n",
    "    json_file_path,\n",
    "    num_support_samples=25\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs both a zero-shot and a few-shot evaluation and compares the results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Starting Zero-Shot vs. Few-Shot Comparison for: '{json_file_path}'\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # --- 1. Load Data ---\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            ai_collection_texts = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading AI texts: {e}\"); return\n",
    "\n",
    "    human_texts_for_query = load_dataset(\"liamdugan/raid\", split='train').filter(\n",
    "        lambda x: x['model'] == 'human'\n",
    "    )['generation']\n",
    "    random.shuffle(human_texts_for_query)\n",
    "    \n",
    "    # --- 2. Zero-Shot Evaluation ---\n",
    "    print(\"\\n--- STAGE 1: ZERO-SHOT EVALUATION ---\")\n",
    "    print(\"Using original Human vs. GPT-4 centroids for detection...\")\n",
    "    zero_shot_detector = ZeroShotDetector(model, tokenizer, centroids_path)\n",
    "    zero_shot_predictions = zero_shot_detector.predict(ai_collection_texts)\n",
    "    zero_shot_recall = np.mean(zero_shot_predictions)\n",
    "\n",
    "    # --- 3. Few-Shot Evaluation ---\n",
    "    print(\"\\n--- STAGE 2: FEW-SHOT EVALUATION ---\")\n",
    "    print(f\"Using {num_support_samples} samples to adapt the detector...\")\n",
    "    \n",
    "    # Load human centroid for the few-shot detector\n",
    "    centroids = torch.load(centroids_path, map_location='cpu')\n",
    "    human_centroid = centroids['human_centroid'].numpy().reshape(1, -1)\n",
    "\n",
    "    # Split AI data for few-shot learning\n",
    "    random.shuffle(ai_collection_texts)\n",
    "    ai_support_texts = ai_collection_texts[:num_support_samples]\n",
    "    ai_query_texts = ai_collection_texts[num_support_samples:]\n",
    "\n",
    "    # Create the adapted detector\n",
    "    few_shot_detector = FewShotDetector(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        human_centroid=human_centroid,\n",
    "        ai_support_texts=ai_support_texts\n",
    "    )\n",
    "    \n",
    "    # Test on the unseen AI query set\n",
    "    few_shot_predictions = few_shot_detector.predict(ai_query_texts)\n",
    "    few_shot_recall = np.mean(few_shot_predictions)\n",
    "\n",
    "    # --- 4. Final Comparison Report ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"                 PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"AI Text Collection: '{json_file_path}'\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Metric: AI Detection Rate (Recall)\\n\")\n",
    "    print(f\"Zero-Shot Performance (No Adaptation):   {zero_shot_recall:.2%}\")\n",
    "    print(f\"Few-Shot Performance ({num_support_samples}-shot Adaptation): {few_shot_recall:.2%}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    improvement = few_shot_recall - zero_shot_recall\n",
    "    print(f\"Absolute Improvement from Adaptation: +{improvement:.2%}\")\n",
    "    if zero_shot_recall > 0:\n",
    "        relative_improvement = improvement / zero_shot_recall\n",
    "        print(f\"Relative Improvement from Adaptation: +{relative_improvement:.2%}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#                                EXECUTION\n",
    "# ==============================================================================\n",
    "# Define the paths for your model, centroids, and the new JSON dataset\n",
    "# MODEL_PATH = 'best_style_model.pt' # This should be loaded into the `model` object\n",
    "CENTROIDS_PATH = 'centroids.pt'\n",
    "JSON_DATASET_PATH = 'Arxiv_gemini-1.0-pro.json'\n",
    "\n",
    "# Assuming `model`, `tokenizer`, and `get_embeddings` are already available\n",
    "# Run the comparison\n",
    "run_comparison_evaluation(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    CENTROIDS_PATH,\n",
    "    JSON_DATASET_PATH,\n",
    "    num_support_samples=100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RishiSurge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
